Setting up connection 0
***********************************************************
Training FMNIST
Model: Dense([60000, 1, 128]) => Dense([60000, 1, 128]) => Dense([60000, 1, 10]) => MultiOutput([60000, 10]) => 
Train Examples: 60000
Batch Size: 2000
Num Epochs: 10
Learning Rate: 0.4 to 0.4 over 10 epochs
Clipping Factor: 4
Sigma: 4
***********************************************************
Epoch 1.1: Loss = 2.39726
Epoch 1.2: Loss = 2.17714
Epoch 1.3: Loss = 1.98143
Epoch 1.4: Loss = 1.8334
Epoch 1.5: Loss = 1.66592
Epoch 1.6: Loss = 1.52463
Epoch 1.7: Loss = 1.424
Epoch 1.8: Loss = 1.33502
Epoch 1.9: Loss = 1.24956
Epoch 1.10: Loss = 1.20282
Epoch 1.11: Loss = 1.16275
Epoch 1.12: Loss = 1.07901
Epoch 1.13: Loss = 1.04303
Epoch 1.14: Loss = 1.05806
Epoch 1.15: Loss = 0.969391
Epoch 1.16: Loss = 1.03116
Epoch 1.17: Loss = 0.878204
Epoch 1.18: Loss = 0.94664
Epoch 1.19: Loss = 0.975555
Epoch 1.20: Loss = 0.97168
Epoch 1.21: Loss = 0.935898
Epoch 1.22: Loss = 1.00757
Epoch 1.23: Loss = 0.908783
Epoch 1.24: Loss = 0.95195
Epoch 1.25: Loss = 0.852737
Epoch 1.26: Loss = 0.876144
Epoch 1.27: Loss = 0.820007
Epoch 1.28: Loss = 0.814804
Epoch 1.29: Loss = 0.920273
Epoch 1.30: Loss = 0.777924
TRAIN LOSS = 1.19244
TRAIN ACC = 58.11 % (34868/60000)
Loss = 0.84169
Loss = 0.914658
Loss = 0.862488
Loss = 0.8909
Loss = 0.86058
TEST LOSS = 0.874063
TEST ACC = 348.68 % (6714/10000)
Reducing learning rate to 0.399994
Epoch 2.1: Loss = 0.857727
Epoch 2.2: Loss = 0.829941
Epoch 2.3: Loss = 0.886642
Epoch 2.4: Loss = 0.829956
Epoch 2.5: Loss = 0.847
Epoch 2.6: Loss = 0.841614
Epoch 2.7: Loss = 0.875778
Epoch 2.8: Loss = 0.856812
Epoch 2.9: Loss = 0.843582
Epoch 2.10: Loss = 0.834717
Epoch 2.11: Loss = 0.815475
Epoch 2.12: Loss = 0.864258
Epoch 2.13: Loss = 0.821442
Epoch 2.14: Loss = 0.771774
Epoch 2.15: Loss = 0.76915
Epoch 2.16: Loss = 0.723053
Epoch 2.17: Loss = 0.691315
Epoch 2.18: Loss = 0.685822
Epoch 2.19: Loss = 0.790421
Epoch 2.20: Loss = 0.715607
Epoch 2.21: Loss = 0.783447
Epoch 2.22: Loss = 0.751923
Epoch 2.23: Loss = 0.959717
Epoch 2.24: Loss = 0.775024
Epoch 2.25: Loss = 0.817749
Epoch 2.26: Loss = 0.735641
Epoch 2.27: Loss = 0.763901
Epoch 2.28: Loss = 0.736069
Epoch 2.29: Loss = 0.831223
Epoch 2.30: Loss = 0.76207
TRAIN LOSS = 0.802307
TRAIN ACC = 71.9986 % (43201/60000)
Loss = 0.822266
Loss = 0.914734
Loss = 0.859818
Loss = 0.864838
Loss = 0.865219
TEST LOSS = 0.865375
TEST ACC = 432.01 % (7194/10000)
Reducing learning rate to 0.399994
Epoch 3.1: Loss = 0.835114
Epoch 3.2: Loss = 0.90094
Epoch 3.3: Loss = 0.826813
Epoch 3.4: Loss = 0.793503
Epoch 3.5: Loss = 0.83847
Epoch 3.6: Loss = 0.779434
Epoch 3.7: Loss = 0.833466
Epoch 3.8: Loss = 0.823059
Epoch 3.9: Loss = 0.733444
Epoch 3.10: Loss = 0.722183
Epoch 3.11: Loss = 0.847458
Epoch 3.12: Loss = 0.749863
Epoch 3.13: Loss = 0.72522
Epoch 3.14: Loss = 0.675186
Epoch 3.15: Loss = 0.687042
Epoch 3.16: Loss = 0.671463
Epoch 3.17: Loss = 0.712189
Epoch 3.18: Loss = 0.702454
Epoch 3.19: Loss = 0.780792
Epoch 3.20: Loss = 0.714127
Epoch 3.21: Loss = 0.829895
Epoch 3.22: Loss = 0.693649
Epoch 3.23: Loss = 0.795807
Epoch 3.24: Loss = 0.603195
Epoch 3.25: Loss = 0.741394
Epoch 3.26: Loss = 0.685516
Epoch 3.27: Loss = 0.68483
Epoch 3.28: Loss = 0.705795
Epoch 3.29: Loss = 0.811249
Epoch 3.30: Loss = 0.748032
TRAIN LOSS = 0.755066
TRAIN ACC = 75.2838 % (45172/60000)
Loss = 0.718643
Loss = 0.829926
Loss = 0.77446
Loss = 0.765198
Loss = 0.766129
TEST LOSS = 0.770871
TEST ACC = 451.72 % (7570/10000)
Reducing learning rate to 0.399994
Epoch 4.1: Loss = 0.778137
Epoch 4.2: Loss = 0.750305
Epoch 4.3: Loss = 0.915985
Epoch 4.4: Loss = 0.818146
Epoch 4.5: Loss = 0.801163
Epoch 4.6: Loss = 0.747314
Epoch 4.7: Loss = 0.738586
Epoch 4.8: Loss = 0.729691
Epoch 4.9: Loss = 0.737198
Epoch 4.10: Loss = 0.706085
Epoch 4.11: Loss = 0.821777
Epoch 4.12: Loss = 0.740494
Epoch 4.13: Loss = 0.895584
Epoch 4.14: Loss = 0.839081
Epoch 4.15: Loss = 0.758957
Epoch 4.16: Loss = 0.668381
Epoch 4.17: Loss = 0.722107
Epoch 4.18: Loss = 0.690155
Epoch 4.19: Loss = 0.698151
Epoch 4.20: Loss = 0.718109
Epoch 4.21: Loss = 0.725739
Epoch 4.22: Loss = 0.662766
Epoch 4.23: Loss = 0.707748
Epoch 4.24: Loss = 0.729294
Epoch 4.25: Loss = 0.77832
Epoch 4.26: Loss = 0.704147
Epoch 4.27: Loss = 0.784195
Epoch 4.28: Loss = 0.783615
Epoch 4.29: Loss = 0.829926
Epoch 4.30: Loss = 0.77626
TRAIN LOSS = 0.758591
TRAIN ACC = 76.5808 % (45950/60000)
Loss = 0.834351
Loss = 0.946808
Loss = 0.919907
Loss = 0.899643
Loss = 0.883286
TEST LOSS = 0.896798
TEST ACC = 459.499 % (7519/10000)
Reducing learning rate to 0.399994
Epoch 5.1: Loss = 0.870834
Epoch 5.2: Loss = 0.828552
Epoch 5.3: Loss = 0.742767
Epoch 5.4: Loss = 0.693817
Epoch 5.5: Loss = 0.694214
Epoch 5.6: Loss = 0.803772
Epoch 5.7: Loss = 0.769958
Epoch 5.8: Loss = 0.761673
Epoch 5.9: Loss = 0.715286
Epoch 5.10: Loss = 0.797577
Epoch 5.11: Loss = 0.754456
Epoch 5.12: Loss = 0.688416
Epoch 5.13: Loss = 0.732086
Epoch 5.14: Loss = 0.74855
Epoch 5.15: Loss = 0.688126
Epoch 5.16: Loss = 0.786011
Epoch 5.17: Loss = 0.712845
Epoch 5.18: Loss = 0.63176
Epoch 5.19: Loss = 0.720428
Epoch 5.20: Loss = 0.606461
Epoch 5.21: Loss = 0.683533
Epoch 5.22: Loss = 0.649094
Epoch 5.23: Loss = 0.678787
Epoch 5.24: Loss = 0.845856
Epoch 5.25: Loss = 0.766296
Epoch 5.26: Loss = 0.763962
Epoch 5.27: Loss = 0.693344
Epoch 5.28: Loss = 0.722702
Epoch 5.29: Loss = 0.696152
Epoch 5.30: Loss = 0.727127
TRAIN LOSS = 0.732498
TRAIN ACC = 77.9221 % (46755/60000)
Loss = 0.725769
Loss = 0.849075
Loss = 0.819427
Loss = 0.804794
Loss = 0.788361
TEST LOSS = 0.797485
TEST ACC = 467.549 % (7776/10000)
Reducing learning rate to 0.399994
Epoch 6.1: Loss = 0.755478
Epoch 6.2: Loss = 0.746826
Epoch 6.3: Loss = 0.718796
Epoch 6.4: Loss = 0.693939
Epoch 6.5: Loss = 0.652649
Epoch 6.6: Loss = 0.695038
Epoch 6.7: Loss = 0.611282
Epoch 6.8: Loss = 0.625137
Epoch 6.9: Loss = 0.66127
Epoch 6.10: Loss = 0.678192
Epoch 6.11: Loss = 0.706833
Epoch 6.12: Loss = 0.648865
Epoch 6.13: Loss = 0.648743
Epoch 6.14: Loss = 0.724442
Epoch 6.15: Loss = 0.755325
Epoch 6.16: Loss = 0.738037
Epoch 6.17: Loss = 0.845901
Epoch 6.18: Loss = 0.679306
Epoch 6.19: Loss = 0.787872
Epoch 6.20: Loss = 0.668304
Epoch 6.21: Loss = 0.685867
Epoch 6.22: Loss = 0.615768
Epoch 6.23: Loss = 0.682068
Epoch 6.24: Loss = 0.672928
Epoch 6.25: Loss = 0.746094
Epoch 6.26: Loss = 0.635376
Epoch 6.27: Loss = 0.740387
Epoch 6.28: Loss = 0.671753
Epoch 6.29: Loss = 0.624268
Epoch 6.30: Loss = 0.727753
TRAIN LOSS = 0.694824
TRAIN ACC = 79.3777 % (47629/60000)
Loss = 0.672241
Loss = 0.796143
Loss = 0.783051
Loss = 0.751114
Loss = 0.751038
TEST LOSS = 0.750717
TEST ACC = 476.289 % (7850/10000)
Reducing learning rate to 0.399994
Epoch 7.1: Loss = 0.679169
Epoch 7.2: Loss = 0.670547
Epoch 7.3: Loss = 0.727737
Epoch 7.4: Loss = 0.708603
Epoch 7.5: Loss = 0.675171
Epoch 7.6: Loss = 0.724594
Epoch 7.7: Loss = 0.746384
Epoch 7.8: Loss = 0.710022
Epoch 7.9: Loss = 0.778412
Epoch 7.10: Loss = 0.644684
Epoch 7.11: Loss = 0.664795
Epoch 7.12: Loss = 0.691406
Epoch 7.13: Loss = 0.606781
Epoch 7.14: Loss = 0.651672
Epoch 7.15: Loss = 0.69664
Epoch 7.16: Loss = 0.73468
Epoch 7.17: Loss = 0.663101
Epoch 7.18: Loss = 0.659836
Epoch 7.19: Loss = 0.703415
Epoch 7.20: Loss = 0.751083
Epoch 7.21: Loss = 0.71637
Epoch 7.22: Loss = 0.723724
Epoch 7.23: Loss = 0.718918
Epoch 7.24: Loss = 0.746323
Epoch 7.25: Loss = 0.76059
Epoch 7.26: Loss = 0.688934
Epoch 7.27: Loss = 0.780624
Epoch 7.28: Loss = 0.649704
Epoch 7.29: Loss = 0.77739
Epoch 7.30: Loss = 0.655472
TRAIN LOSS = 0.703568
TRAIN ACC = 79.689 % (47816/60000)
Loss = 0.71936
Loss = 0.829163
Loss = 0.84465
Loss = 0.775146
Loss = 0.782211
TEST LOSS = 0.790106
TEST ACC = 478.159 % (7807/10000)
Reducing learning rate to 0.399994
Epoch 8.1: Loss = 0.817215
Epoch 8.2: Loss = 0.712173
Epoch 8.3: Loss = 0.76564
Epoch 8.4: Loss = 0.667648
Epoch 8.5: Loss = 0.636871
Epoch 8.6: Loss = 0.697037
Epoch 8.7: Loss = 0.745819
Epoch 8.8: Loss = 0.780777
Epoch 8.9: Loss = 0.787689
Epoch 8.10: Loss = 0.750107
Epoch 8.11: Loss = 0.651947
Epoch 8.12: Loss = 0.762039
Epoch 8.13: Loss = 0.701416
Epoch 8.14: Loss = 0.743881
Epoch 8.15: Loss = 0.821609
Epoch 8.16: Loss = 0.741867
Epoch 8.17: Loss = 0.778824
Epoch 8.18: Loss = 0.708969
Epoch 8.19: Loss = 0.739029
Epoch 8.20: Loss = 0.705231
Epoch 8.21: Loss = 0.672607
Epoch 8.22: Loss = 0.645569
Epoch 8.23: Loss = 0.693024
Epoch 8.24: Loss = 0.833023
Epoch 8.25: Loss = 0.65535
Epoch 8.26: Loss = 0.736694
Epoch 8.27: Loss = 0.690277
Epoch 8.28: Loss = 0.690811
Epoch 8.29: Loss = 0.610016
Epoch 8.30: Loss = 0.641876
TRAIN LOSS = 0.719528
TRAIN ACC = 79.7501 % (47852/60000)
Loss = 0.649811
Loss = 0.758606
Loss = 0.75206
Loss = 0.692261
Loss = 0.701447
TEST LOSS = 0.710837
TEST ACC = 478.519 % (7967/10000)
Reducing learning rate to 0.399994
Epoch 9.1: Loss = 0.640732
Epoch 9.2: Loss = 0.676682
Epoch 9.3: Loss = 0.710205
Epoch 9.4: Loss = 0.75798
Epoch 9.5: Loss = 0.737396
Epoch 9.6: Loss = 0.731781
Epoch 9.7: Loss = 0.671082
Epoch 9.8: Loss = 0.760468
Epoch 9.9: Loss = 0.76622
Epoch 9.10: Loss = 0.747726
Epoch 9.11: Loss = 0.752045
Epoch 9.12: Loss = 0.717026
Epoch 9.13: Loss = 0.741852
Epoch 9.14: Loss = 0.770111
Epoch 9.15: Loss = 0.675522
Epoch 9.16: Loss = 0.667603
Epoch 9.17: Loss = 0.636276
Epoch 9.18: Loss = 0.63446
Epoch 9.19: Loss = 0.729004
Epoch 9.20: Loss = 0.678726
Epoch 9.21: Loss = 0.630478
Epoch 9.22: Loss = 0.75795
Epoch 9.23: Loss = 0.582397
Epoch 9.24: Loss = 0.738617
Epoch 9.25: Loss = 0.651886
Epoch 9.26: Loss = 0.774918
Epoch 9.27: Loss = 0.639328
Epoch 9.28: Loss = 0.696854
Epoch 9.29: Loss = 0.632919
Epoch 9.30: Loss = 0.647369
TRAIN LOSS = 0.698532
TRAIN ACC = 80.3894 % (48235/60000)
Loss = 0.634109
Loss = 0.760742
Loss = 0.747787
Loss = 0.716537
Loss = 0.69397
TEST LOSS = 0.710629
TEST ACC = 482.349 % (8023/10000)
Reducing learning rate to 0.399994
Epoch 10.1: Loss = 0.646667
Epoch 10.2: Loss = 0.696579
Epoch 10.3: Loss = 0.699341
Epoch 10.4: Loss = 0.748154
Epoch 10.5: Loss = 0.707672
Epoch 10.6: Loss = 0.765579
Epoch 10.7: Loss = 0.699753
Epoch 10.8: Loss = 0.775391
Epoch 10.9: Loss = 0.780807
Epoch 10.10: Loss = 0.775452
Epoch 10.11: Loss = 0.811172
Epoch 10.12: Loss = 0.713699
Epoch 10.13: Loss = 0.655289
Epoch 10.14: Loss = 0.653397
Epoch 10.15: Loss = 0.682159
Epoch 10.16: Loss = 0.793503
Epoch 10.17: Loss = 0.738373
Epoch 10.18: Loss = 0.730804
Epoch 10.19: Loss = 0.71019
Epoch 10.20: Loss = 0.652039
Epoch 10.21: Loss = 0.625381
Epoch 10.22: Loss = 0.705002
Epoch 10.23: Loss = 0.712402
Epoch 10.24: Loss = 0.681259
Epoch 10.25: Loss = 0.70813
Epoch 10.26: Loss = 0.745468
Epoch 10.27: Loss = 0.689865
Epoch 10.28: Loss = 0.721878
Epoch 10.29: Loss = 0.672607
Epoch 10.30: Loss = 0.663223
TRAIN LOSS = 0.712051
TRAIN ACC = 80.1941 % (48118/60000)
Loss = 0.642227
Loss = 0.768524
Loss = 0.737549
Loss = 0.682739
Loss = 0.686447
TEST LOSS = 0.703497
TEST ACC = 481.18 % (7986/10000)
