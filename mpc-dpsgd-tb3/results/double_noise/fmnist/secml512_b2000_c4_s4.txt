Setting up connection 0
***********************************************************
Training FMNIST
Model: Dense([60000, 1, 512]) => Dense([60000, 1, 512]) => Dense([60000, 1, 10]) => MultiOutput([60000, 10]) => 
Train Examples: 60000
Batch Size: 2000
Num Epochs: 10
Learning Rate: 0.4 to 0.4 over 10 epochs
Clipping Factor: 4
Sigma: 4
***********************************************************
Epoch 1.1: Loss = 2.32043
Epoch 1.2: Loss = 2.04123
Epoch 1.3: Loss = 1.83926
Epoch 1.4: Loss = 1.64778
Epoch 1.5: Loss = 1.47356
Epoch 1.6: Loss = 1.36205
Epoch 1.7: Loss = 1.25389
Epoch 1.8: Loss = 1.22989
Epoch 1.9: Loss = 1.10176
Epoch 1.10: Loss = 1.04868
Epoch 1.11: Loss = 0.978485
Epoch 1.12: Loss = 1.00821
Epoch 1.13: Loss = 0.956146
Epoch 1.14: Loss = 0.982712
Epoch 1.15: Loss = 0.930069
Epoch 1.16: Loss = 0.922913
Epoch 1.17: Loss = 0.966904
Epoch 1.18: Loss = 0.872284
Epoch 1.19: Loss = 0.923569
Epoch 1.20: Loss = 0.838654
Epoch 1.21: Loss = 0.88504
Epoch 1.22: Loss = 0.790207
Epoch 1.23: Loss = 0.803253
Epoch 1.24: Loss = 0.770325
Epoch 1.25: Loss = 0.858765
Epoch 1.26: Loss = 0.776688
Epoch 1.27: Loss = 0.896576
Epoch 1.28: Loss = 0.781372
Epoch 1.29: Loss = 0.792725
Epoch 1.30: Loss = 0.759384
TRAIN LOSS = 1.09377
TRAIN ACC = 63.5422 % (38127/60000)
Loss = 0.840714
Loss = 0.905777
Loss = 0.864014
Loss = 0.904434
Loss = 0.850235
TEST LOSS = 0.873034
TEST ACC = 381.27 % (6985/10000)
Reducing learning rate to 0.399994
Epoch 2.1: Loss = 0.880386
Epoch 2.2: Loss = 0.716385
Epoch 2.3: Loss = 0.913559
Epoch 2.4: Loss = 0.779694
Epoch 2.5: Loss = 0.819824
Epoch 2.6: Loss = 0.717651
Epoch 2.7: Loss = 0.838165
Epoch 2.8: Loss = 0.691177
Epoch 2.9: Loss = 0.838577
Epoch 2.10: Loss = 0.709473
Epoch 2.11: Loss = 0.882568
Epoch 2.12: Loss = 0.741455
Epoch 2.13: Loss = 0.785782
Epoch 2.14: Loss = 0.668289
Epoch 2.15: Loss = 0.734634
Epoch 2.16: Loss = 0.706451
Epoch 2.17: Loss = 0.720978
Epoch 2.18: Loss = 0.662598
Epoch 2.19: Loss = 0.718719
Epoch 2.20: Loss = 0.766129
Epoch 2.21: Loss = 0.789902
Epoch 2.22: Loss = 0.773331
Epoch 2.23: Loss = 0.799591
Epoch 2.24: Loss = 0.862549
Epoch 2.25: Loss = 0.797791
Epoch 2.26: Loss = 0.879135
Epoch 2.27: Loss = 0.944641
Epoch 2.28: Loss = 0.880905
Epoch 2.29: Loss = 0.741959
Epoch 2.30: Loss = 0.749054
TRAIN LOSS = 0.783737
TRAIN ACC = 74.2279 % (44539/60000)
Loss = 0.789261
Loss = 0.85849
Loss = 0.837219
Loss = 0.837067
Loss = 0.795654
TEST LOSS = 0.823538
TEST ACC = 445.389 % (7339/10000)
Reducing learning rate to 0.399994
Epoch 3.1: Loss = 0.808456
Epoch 3.2: Loss = 0.97496
Epoch 3.3: Loss = 0.825653
Epoch 3.4: Loss = 0.740051
Epoch 3.5: Loss = 0.75737
Epoch 3.6: Loss = 0.942734
Epoch 3.7: Loss = 0.844177
Epoch 3.8: Loss = 0.961884
Epoch 3.9: Loss = 0.810181
Epoch 3.10: Loss = 0.765182
Epoch 3.11: Loss = 0.643463
Epoch 3.12: Loss = 0.795319
Epoch 3.13: Loss = 0.847549
Epoch 3.14: Loss = 0.737564
Epoch 3.15: Loss = 0.733383
Epoch 3.16: Loss = 0.783264
Epoch 3.17: Loss = 0.775848
Epoch 3.18: Loss = 0.807846
Epoch 3.19: Loss = 0.884705
Epoch 3.20: Loss = 0.867706
Epoch 3.21: Loss = 0.73111
Epoch 3.22: Loss = 0.694397
Epoch 3.23: Loss = 0.718933
Epoch 3.24: Loss = 0.627594
Epoch 3.25: Loss = 0.730942
Epoch 3.26: Loss = 0.689194
Epoch 3.27: Loss = 0.925018
Epoch 3.28: Loss = 0.711548
Epoch 3.29: Loss = 0.779236
Epoch 3.30: Loss = 0.792587
TRAIN LOSS = 0.790283
TRAIN ACC = 75.9399 % (45566/60000)
Loss = 0.75589
Loss = 0.853424
Loss = 0.817581
Loss = 0.815918
Loss = 0.789932
TEST LOSS = 0.806549
TEST ACC = 455.659 % (7603/10000)
Reducing learning rate to 0.399994
Epoch 4.1: Loss = 0.810501
Epoch 4.2: Loss = 0.815414
Epoch 4.3: Loss = 0.903137
Epoch 4.4: Loss = 0.898697
Epoch 4.5: Loss = 0.808472
Epoch 4.6: Loss = 0.694168
Epoch 4.7: Loss = 0.810471
Epoch 4.8: Loss = 0.769409
Epoch 4.9: Loss = 0.939438
Epoch 4.10: Loss = 0.744034
Epoch 4.11: Loss = 0.801712
Epoch 4.12: Loss = 0.714249
Epoch 4.13: Loss = 0.854431
Epoch 4.14: Loss = 0.707214
Epoch 4.15: Loss = 0.811172
Epoch 4.16: Loss = 0.666
Epoch 4.17: Loss = 0.791077
Epoch 4.18: Loss = 0.638168
Epoch 4.19: Loss = 0.780624
Epoch 4.20: Loss = 0.681381
Epoch 4.21: Loss = 0.814911
Epoch 4.22: Loss = 0.715332
Epoch 4.23: Loss = 0.747314
Epoch 4.24: Loss = 0.734253
Epoch 4.25: Loss = 0.835495
Epoch 4.26: Loss = 0.793289
Epoch 4.27: Loss = 0.805969
Epoch 4.28: Loss = 0.735519
Epoch 4.29: Loss = 0.674469
Epoch 4.30: Loss = 0.709167
TRAIN LOSS = 0.773529
TRAIN ACC = 77.6245 % (46577/60000)
Loss = 0.725281
Loss = 0.85083
Loss = 0.805267
Loss = 0.817017
Loss = 0.795624
TEST LOSS = 0.798803
TEST ACC = 465.77 % (7746/10000)
Reducing learning rate to 0.399994
Epoch 5.1: Loss = 0.815536
Epoch 5.2: Loss = 0.788574
Epoch 5.3: Loss = 0.769623
Epoch 5.4: Loss = 0.804153
Epoch 5.5: Loss = 0.788284
Epoch 5.6: Loss = 0.74437
Epoch 5.7: Loss = 0.701645
Epoch 5.8: Loss = 0.887634
Epoch 5.9: Loss = 1.14296
Epoch 5.10: Loss = 0.888885
Epoch 5.11: Loss = 0.669632
Epoch 5.12: Loss = 0.821533
Epoch 5.13: Loss = 0.808975
Epoch 5.14: Loss = 0.815186
Epoch 5.15: Loss = 0.749008
Epoch 5.16: Loss = 0.74675
Epoch 5.17: Loss = 0.791122
Epoch 5.18: Loss = 0.878281
Epoch 5.19: Loss = 0.694305
Epoch 5.20: Loss = 0.917282
Epoch 5.21: Loss = 0.691345
Epoch 5.22: Loss = 0.764511
Epoch 5.23: Loss = 0.956619
Epoch 5.24: Loss = 0.828812
Epoch 5.25: Loss = 0.817581
Epoch 5.26: Loss = 0.835144
Epoch 5.27: Loss = 0.956161
Epoch 5.28: Loss = 0.717453
Epoch 5.29: Loss = 0.669342
Epoch 5.30: Loss = 0.764389
TRAIN LOSS = 0.807526
TRAIN ACC = 77.9922 % (46798/60000)
Loss = 0.743073
Loss = 0.832535
Loss = 0.79422
Loss = 0.784286
Loss = 0.764816
TEST LOSS = 0.783786
TEST ACC = 467.979 % (7718/10000)
Reducing learning rate to 0.399994
Epoch 6.1: Loss = 0.759918
Epoch 6.2: Loss = 0.865372
Epoch 6.3: Loss = 0.927643
Epoch 6.4: Loss = 0.663101
Epoch 6.5: Loss = 0.594406
Epoch 6.6: Loss = 0.756302
Epoch 6.7: Loss = 0.770569
Epoch 6.8: Loss = 1.03484
Epoch 6.9: Loss = 0.747787
Epoch 6.10: Loss = 0.704895
Epoch 6.11: Loss = 0.770721
Epoch 6.12: Loss = 0.712006
Epoch 6.13: Loss = 0.673645
Epoch 6.14: Loss = 0.957764
Epoch 6.15: Loss = 1.09308
Epoch 6.16: Loss = 0.757706
Epoch 6.17: Loss = 0.766739
Epoch 6.18: Loss = 0.820282
Epoch 6.19: Loss = 0.845169
Epoch 6.20: Loss = 0.79924
Epoch 6.21: Loss = 1.034
Epoch 6.22: Loss = 0.805634
Epoch 6.23: Loss = 0.750946
Epoch 6.24: Loss = 0.761566
Epoch 6.25: Loss = 0.826736
Epoch 6.26: Loss = 0.896439
Epoch 6.27: Loss = 0.873062
Epoch 6.28: Loss = 0.762817
Epoch 6.29: Loss = 0.905029
Epoch 6.30: Loss = 0.892883
TRAIN LOSS = 0.817688
TRAIN ACC = 78.4668 % (47082/60000)
Loss = 0.800171
Loss = 0.884811
Loss = 0.87027
Loss = 0.861252
Loss = 0.816101
TEST LOSS = 0.846521
TEST ACC = 470.819 % (7721/10000)
Reducing learning rate to 0.399994
Epoch 7.1: Loss = 0.845978
Epoch 7.2: Loss = 0.90094
Epoch 7.3: Loss = 0.866821
Epoch 7.4: Loss = 0.949539
Epoch 7.5: Loss = 0.767014
Epoch 7.6: Loss = 0.70047
Epoch 7.7: Loss = 0.702972
Epoch 7.8: Loss = 0.750671
Epoch 7.9: Loss = 0.767395
Epoch 7.10: Loss = 1.13808
Epoch 7.11: Loss = 0.716141
Epoch 7.12: Loss = 0.744232
Epoch 7.13: Loss = 0.742752
Epoch 7.14: Loss = 1.00409
Epoch 7.15: Loss = 0.784149
Epoch 7.16: Loss = 0.914398
Epoch 7.17: Loss = 0.812622
Epoch 7.18: Loss = 0.779053
Epoch 7.19: Loss = 0.755615
Epoch 7.20: Loss = 0.683807
Epoch 7.21: Loss = 0.743042
Epoch 7.22: Loss = 0.844757
Epoch 7.23: Loss = 0.993637
Epoch 7.24: Loss = 0.960114
Epoch 7.25: Loss = 0.771393
Epoch 7.26: Loss = 0.723145
Epoch 7.27: Loss = 0.755127
Epoch 7.28: Loss = 0.734573
Epoch 7.29: Loss = 0.642883
Epoch 7.30: Loss = 0.740677
TRAIN LOSS = 0.807892
TRAIN ACC = 79.1794 % (47510/60000)
Loss = 0.73381
Loss = 0.860825
Loss = 0.825821
Loss = 0.823471
Loss = 0.778275
TEST LOSS = 0.80444
TEST ACC = 475.099 % (7900/10000)
Reducing learning rate to 0.399994
Epoch 8.1: Loss = 0.756302
Epoch 8.2: Loss = 0.822266
Epoch 8.3: Loss = 0.742142
Epoch 8.4: Loss = 0.699707
Epoch 8.5: Loss = 0.750168
Epoch 8.6: Loss = 0.716782
Epoch 8.7: Loss = 0.95343
Epoch 8.8: Loss = 0.737518
Epoch 8.9: Loss = 0.956573
Epoch 8.10: Loss = 0.675613
Epoch 8.11: Loss = 0.703827
Epoch 8.12: Loss = 0.675064
Epoch 8.13: Loss = 0.733124
Epoch 8.14: Loss = 0.79216
Epoch 8.15: Loss = 0.813919
Epoch 8.16: Loss = 0.956863
Epoch 8.17: Loss = 0.720352
Epoch 8.18: Loss = 0.749893
Epoch 8.19: Loss = 0.756546
Epoch 8.20: Loss = 1.12517
Epoch 8.21: Loss = 0.820526
Epoch 8.22: Loss = 1.0862
Epoch 8.23: Loss = 0.801682
Epoch 8.24: Loss = 0.812469
Epoch 8.25: Loss = 0.777695
Epoch 8.26: Loss = 0.817825
Epoch 8.27: Loss = 0.861099
Epoch 8.28: Loss = 0.882706
Epoch 8.29: Loss = 0.756805
Epoch 8.30: Loss = 0.933395
TRAIN LOSS = 0.812943
TRAIN ACC = 79.8813 % (47931/60000)
Loss = 0.858353
Loss = 0.935577
Loss = 0.962967
Loss = 0.904938
Loss = 0.875031
TEST LOSS = 0.907373
TEST ACC = 479.309 % (7838/10000)
Reducing learning rate to 0.399994
Epoch 9.1: Loss = 0.941193
Epoch 9.2: Loss = 0.758896
Epoch 9.3: Loss = 0.708984
Epoch 9.4: Loss = 0.839783
Epoch 9.5: Loss = 0.878403
Epoch 9.6: Loss = 0.918121
Epoch 9.7: Loss = 0.725342
Epoch 9.8: Loss = 0.905106
Epoch 9.9: Loss = 0.711411
Epoch 9.10: Loss = 0.867523
Epoch 9.11: Loss = 0.781906
Epoch 9.12: Loss = 0.845505
Epoch 9.13: Loss = 0.818619
Epoch 9.14: Loss = 0.802414
Epoch 9.15: Loss = 0.897049
Epoch 9.16: Loss = 0.849655
Epoch 9.17: Loss = 0.972397
Epoch 9.18: Loss = 0.808884
Epoch 9.19: Loss = 0.883972
Epoch 9.20: Loss = 0.944504
Epoch 9.21: Loss = 0.784927
Epoch 9.22: Loss = 0.803284
Epoch 9.23: Loss = 0.865341
Epoch 9.24: Loss = 0.721771
Epoch 9.25: Loss = 1.03613
Epoch 9.26: Loss = 0.761871
Epoch 9.27: Loss = 0.734482
Epoch 9.28: Loss = 0.743698
Epoch 9.29: Loss = 0.689758
Epoch 9.30: Loss = 0.741577
TRAIN LOSS = 0.824768
TRAIN ACC = 80.0217 % (48015/60000)
Loss = 0.686371
Loss = 0.770905
Loss = 0.755997
Loss = 0.753647
Loss = 0.710144
TEST LOSS = 0.735412
TEST ACC = 480.15 % (8040/10000)
Reducing learning rate to 0.399994
Epoch 10.1: Loss = 0.661865
Epoch 10.2: Loss = 0.817337
Epoch 10.3: Loss = 0.748291
Epoch 10.4: Loss = 1.06201
Epoch 10.5: Loss = 0.747757
Epoch 10.6: Loss = 0.919083
Epoch 10.7: Loss = 0.731583
Epoch 10.8: Loss = 0.861984
Epoch 10.9: Loss = 0.762833
Epoch 10.10: Loss = 1.09172
Epoch 10.11: Loss = 0.791565
Epoch 10.12: Loss = 0.844345
Epoch 10.13: Loss = 0.722534
Epoch 10.14: Loss = 0.92308
Epoch 10.15: Loss = 0.739029
Epoch 10.16: Loss = 0.746597
Epoch 10.17: Loss = 0.665726
Epoch 10.18: Loss = 0.807831
Epoch 10.19: Loss = 0.748489
Epoch 10.20: Loss = 0.940033
Epoch 10.21: Loss = 0.743301
Epoch 10.22: Loss = 0.671173
Epoch 10.23: Loss = 0.729477
Epoch 10.24: Loss = 0.733444
Epoch 10.25: Loss = 0.821182
Epoch 10.26: Loss = 0.873337
Epoch 10.27: Loss = 0.768784
Epoch 10.28: Loss = 0.815842
Epoch 10.29: Loss = 0.726089
Epoch 10.30: Loss = 0.903641
TRAIN LOSS = 0.804016
TRAIN ACC = 80.4382 % (48265/60000)
Loss = 0.856171
Loss = 0.927521
Loss = 0.917419
Loss = 0.900299
Loss = 0.84726
TEST LOSS = 0.889734
TEST ACC = 482.649 % (7811/10000)
