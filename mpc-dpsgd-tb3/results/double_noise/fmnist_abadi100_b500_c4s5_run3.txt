Setting up connection 0
***********************************************************
Training MNIST
Model: Dense([60000, 1, 100]) => Dense([60000, 1, 10]) => MultiOutput([60000, 10]) => 
Train Examples: 60000
Batch Size: 500
Num Epochs: 10
Learning Rate: 0.1 to 0.1 over 10 epochs
Clipping Factor: 4
Sigma: 1
***********************************************************
Epoch 1.1: Loss = 2.45282
Epoch 1.2: Loss = 2.33344
Epoch 1.3: Loss = 2.31204
Epoch 1.4: Loss = 2.18649
Epoch 1.5: Loss = 2.12416
Epoch 1.6: Loss = 2.08403
Epoch 1.7: Loss = 2.02751
Epoch 1.8: Loss = 1.97559
Epoch 1.9: Loss = 1.92159
Epoch 1.10: Loss = 1.83086
Epoch 1.11: Loss = 1.8571
Epoch 1.12: Loss = 1.79036
Epoch 1.13: Loss = 1.77124
Epoch 1.14: Loss = 1.69276
Epoch 1.15: Loss = 1.66521
Epoch 1.16: Loss = 1.67403
Epoch 1.17: Loss = 1.62743
Epoch 1.18: Loss = 1.60823
Epoch 1.19: Loss = 1.55136
Epoch 1.20: Loss = 1.5643
Epoch 1.21: Loss = 1.49368
Epoch 1.22: Loss = 1.46057
Epoch 1.23: Loss = 1.42989
Epoch 1.24: Loss = 1.47827
Epoch 1.25: Loss = 1.41223
Epoch 1.26: Loss = 1.37044
Epoch 1.27: Loss = 1.31602
Epoch 1.28: Loss = 1.30685
Epoch 1.29: Loss = 1.32251
Epoch 1.30: Loss = 1.2944
Epoch 1.31: Loss = 1.30122
Epoch 1.32: Loss = 1.27969
Epoch 1.33: Loss = 1.19806
Epoch 1.34: Loss = 1.26012
Epoch 1.35: Loss = 1.29308
Epoch 1.36: Loss = 1.26355
Epoch 1.37: Loss = 1.20847
Epoch 1.38: Loss = 1.1871
Epoch 1.39: Loss = 1.16574
Epoch 1.40: Loss = 1.15703
Epoch 1.41: Loss = 1.1754
Epoch 1.42: Loss = 1.10728
Epoch 1.43: Loss = 1.10606
Epoch 1.44: Loss = 1.04738
Epoch 1.45: Loss = 1.06297
Epoch 1.46: Loss = 1.10965
Epoch 1.47: Loss = 1.08168
Epoch 1.48: Loss = 1.02592
Epoch 1.49: Loss = 1.08943
Epoch 1.50: Loss = 1.03595
Epoch 1.51: Loss = 1.02655
Epoch 1.52: Loss = 1.09468
Epoch 1.53: Loss = 1.10493
Epoch 1.54: Loss = 0.993362
Epoch 1.55: Loss = 1.07697
Epoch 1.56: Loss = 1.06418
Epoch 1.57: Loss = 1.06413
Epoch 1.58: Loss = 1.04143
Epoch 1.59: Loss = 1.03857
Epoch 1.60: Loss = 1.02977
Epoch 1.61: Loss = 0.948746
Epoch 1.62: Loss = 1.04013
Epoch 1.63: Loss = 0.910812
Epoch 1.64: Loss = 0.93782
Epoch 1.65: Loss = 0.965073
Epoch 1.66: Loss = 1.00194
Epoch 1.67: Loss = 0.91832
Epoch 1.68: Loss = 1.03683
Epoch 1.69: Loss = 0.962662
Epoch 1.70: Loss = 0.960403
Epoch 1.71: Loss = 0.868851
Epoch 1.72: Loss = 0.90239
Epoch 1.73: Loss = 0.943863
Epoch 1.74: Loss = 0.972366
Epoch 1.75: Loss = 0.92392
Epoch 1.76: Loss = 0.905823
Epoch 1.77: Loss = 0.871719
Epoch 1.78: Loss = 0.916122
Epoch 1.79: Loss = 0.829056
Epoch 1.80: Loss = 0.870193
Epoch 1.81: Loss = 0.863403
Epoch 1.82: Loss = 0.894989
Epoch 1.83: Loss = 0.922058
Epoch 1.84: Loss = 0.907776
Epoch 1.85: Loss = 0.86409
Epoch 1.86: Loss = 0.92395
Epoch 1.87: Loss = 0.922729
Epoch 1.88: Loss = 0.793289
Epoch 1.89: Loss = 0.951401
Epoch 1.90: Loss = 0.854523
Epoch 1.91: Loss = 0.890381
Epoch 1.92: Loss = 0.885391
Epoch 1.93: Loss = 0.906235
Epoch 1.94: Loss = 0.869339
Epoch 1.95: Loss = 0.882462
Epoch 1.96: Loss = 0.812988
Epoch 1.97: Loss = 0.719223
Epoch 1.98: Loss = 0.844772
Epoch 1.99: Loss = 0.858795
Epoch 1.100: Loss = 0.83699
Epoch 1.101: Loss = 0.914215
Epoch 1.102: Loss = 0.90451
Epoch 1.103: Loss = 0.868896
Epoch 1.104: Loss = 0.870499
Epoch 1.105: Loss = 0.791
Epoch 1.106: Loss = 0.960648
Epoch 1.107: Loss = 0.829178
Epoch 1.108: Loss = 0.867523
Epoch 1.109: Loss = 0.855194
Epoch 1.110: Loss = 0.875229
Epoch 1.111: Loss = 0.78746
Epoch 1.112: Loss = 0.770706
Epoch 1.113: Loss = 0.8013
Epoch 1.114: Loss = 0.838364
Epoch 1.115: Loss = 0.837219
Epoch 1.116: Loss = 0.728729
Epoch 1.117: Loss = 0.869873
Epoch 1.118: Loss = 0.790314
Epoch 1.119: Loss = 0.790588
Epoch 1.120: Loss = 0.80426
TRAIN LOSS = 1.15395
TRAIN ACC = 61.3922 % (36837/60000)
Loss = 0.763458
Loss = 0.866196
Loss = 0.880676
Loss = 0.782059
Loss = 0.77597
Loss = 0.90564
Loss = 0.910385
Loss = 0.865204
Loss = 0.822266
Loss = 0.780304
Loss = 0.87793
Loss = 0.849136
Loss = 0.826492
Loss = 0.850693
Loss = 0.809875
Loss = 0.865723
Loss = 0.793182
Loss = 0.826859
Loss = 0.869659
Loss = 0.833847
TEST LOSS = 0.837777
TEST ACC = 368.37 % (6932/10000)
Reducing learning rate to 0.100006
Epoch 2.1: Loss = 0.856628
Epoch 2.2: Loss = 0.782394
Epoch 2.3: Loss = 0.874237
Epoch 2.4: Loss = 0.721146
Epoch 2.5: Loss = 0.789536
Epoch 2.6: Loss = 0.891693
Epoch 2.7: Loss = 0.812378
Epoch 2.8: Loss = 0.852356
Epoch 2.9: Loss = 0.758621
Epoch 2.10: Loss = 0.683609
Epoch 2.11: Loss = 0.897583
Epoch 2.12: Loss = 0.833633
Epoch 2.13: Loss = 0.826462
Epoch 2.14: Loss = 0.8246
Epoch 2.15: Loss = 0.798035
Epoch 2.16: Loss = 0.91153
Epoch 2.17: Loss = 0.798065
Epoch 2.18: Loss = 0.816132
Epoch 2.19: Loss = 0.823792
Epoch 2.20: Loss = 0.874939
Epoch 2.21: Loss = 0.765366
Epoch 2.22: Loss = 0.725784
Epoch 2.23: Loss = 0.783615
Epoch 2.24: Loss = 0.910202
Epoch 2.25: Loss = 0.802475
Epoch 2.26: Loss = 0.708832
Epoch 2.27: Loss = 0.766449
Epoch 2.28: Loss = 0.796478
Epoch 2.29: Loss = 0.816666
Epoch 2.30: Loss = 0.768082
Epoch 2.31: Loss = 0.821457
Epoch 2.32: Loss = 0.801956
Epoch 2.33: Loss = 0.675873
Epoch 2.34: Loss = 0.839783
Epoch 2.35: Loss = 0.917236
Epoch 2.36: Loss = 0.854919
Epoch 2.37: Loss = 0.831116
Epoch 2.38: Loss = 0.797623
Epoch 2.39: Loss = 0.832016
Epoch 2.40: Loss = 0.812576
Epoch 2.41: Loss = 0.839233
Epoch 2.42: Loss = 0.848862
Epoch 2.43: Loss = 0.778351
Epoch 2.44: Loss = 0.720505
Epoch 2.45: Loss = 0.747818
Epoch 2.46: Loss = 0.867111
Epoch 2.47: Loss = 0.77034
Epoch 2.48: Loss = 0.717072
Epoch 2.49: Loss = 0.845688
Epoch 2.50: Loss = 0.785583
Epoch 2.51: Loss = 0.69429
Epoch 2.52: Loss = 0.849701
Epoch 2.53: Loss = 0.876785
Epoch 2.54: Loss = 0.684189
Epoch 2.55: Loss = 0.825912
Epoch 2.56: Loss = 0.804016
Epoch 2.57: Loss = 0.822708
Epoch 2.58: Loss = 0.755844
Epoch 2.59: Loss = 0.807312
Epoch 2.60: Loss = 0.76825
Epoch 2.61: Loss = 0.705002
Epoch 2.62: Loss = 0.810516
Epoch 2.63: Loss = 0.666382
Epoch 2.64: Loss = 0.705246
Epoch 2.65: Loss = 0.748642
Epoch 2.66: Loss = 0.776047
Epoch 2.67: Loss = 0.745728
Epoch 2.68: Loss = 0.908981
Epoch 2.69: Loss = 0.787216
Epoch 2.70: Loss = 0.790298
Epoch 2.71: Loss = 0.668213
Epoch 2.72: Loss = 0.765213
Epoch 2.73: Loss = 0.823929
Epoch 2.74: Loss = 0.820724
Epoch 2.75: Loss = 0.750275
Epoch 2.76: Loss = 0.753265
Epoch 2.77: Loss = 0.760483
Epoch 2.78: Loss = 0.739136
Epoch 2.79: Loss = 0.718018
Epoch 2.80: Loss = 0.707886
Epoch 2.81: Loss = 0.711975
Epoch 2.82: Loss = 0.712418
Epoch 2.83: Loss = 0.820557
Epoch 2.84: Loss = 0.756638
Epoch 2.85: Loss = 0.743744
Epoch 2.86: Loss = 0.760971
Epoch 2.87: Loss = 0.788773
Epoch 2.88: Loss = 0.695267
Epoch 2.89: Loss = 0.829941
Epoch 2.90: Loss = 0.741714
Epoch 2.91: Loss = 0.805862
Epoch 2.92: Loss = 0.773468
Epoch 2.93: Loss = 0.823166
Epoch 2.94: Loss = 0.752258
Epoch 2.95: Loss = 0.775543
Epoch 2.96: Loss = 0.722504
Epoch 2.97: Loss = 0.648193
Epoch 2.98: Loss = 0.736832
Epoch 2.99: Loss = 0.760513
Epoch 2.100: Loss = 0.759445
Epoch 2.101: Loss = 0.81842
Epoch 2.102: Loss = 0.786621
Epoch 2.103: Loss = 0.752411
Epoch 2.104: Loss = 0.733124
Epoch 2.105: Loss = 0.693329
Epoch 2.106: Loss = 0.870193
Epoch 2.107: Loss = 0.74707
Epoch 2.108: Loss = 0.744064
Epoch 2.109: Loss = 0.770889
Epoch 2.110: Loss = 0.765091
Epoch 2.111: Loss = 0.708359
Epoch 2.112: Loss = 0.677765
Epoch 2.113: Loss = 0.725525
Epoch 2.114: Loss = 0.76889
Epoch 2.115: Loss = 0.764801
Epoch 2.116: Loss = 0.679871
Epoch 2.117: Loss = 0.80983
Epoch 2.118: Loss = 0.734207
Epoch 2.119: Loss = 0.738235
Epoch 2.120: Loss = 0.735641
TRAIN LOSS = 0.779678
TRAIN ACC = 72.789 % (43676/60000)
Loss = 0.711197
Loss = 0.809769
Loss = 0.790024
Loss = 0.714981
Loss = 0.725067
Loss = 0.917053
Loss = 0.889282
Loss = 0.836533
Loss = 0.780258
Loss = 0.713837
Loss = 0.848694
Loss = 0.835205
Loss = 0.76004
Loss = 0.803391
Loss = 0.793381
Loss = 0.797119
Loss = 0.764267
Loss = 0.788208
Loss = 0.833008
Loss = 0.767212
TEST LOSS = 0.793926
TEST ACC = 436.76 % (7325/10000)
Reducing learning rate to 0.100006
Epoch 3.1: Loss = 0.789429
Epoch 3.2: Loss = 0.740082
Epoch 3.3: Loss = 0.807449
Epoch 3.4: Loss = 0.674332
Epoch 3.5: Loss = 0.743332
Epoch 3.6: Loss = 0.842072
Epoch 3.7: Loss = 0.767609
Epoch 3.8: Loss = 0.859711
Epoch 3.9: Loss = 0.694641
Epoch 3.10: Loss = 0.585999
Epoch 3.11: Loss = 0.869781
Epoch 3.12: Loss = 0.777054
Epoch 3.13: Loss = 0.783554
Epoch 3.14: Loss = 0.762894
Epoch 3.15: Loss = 0.754791
Epoch 3.16: Loss = 0.828857
Epoch 3.17: Loss = 0.715851
Epoch 3.18: Loss = 0.780014
Epoch 3.19: Loss = 0.758133
Epoch 3.20: Loss = 0.853897
Epoch 3.21: Loss = 0.708893
Epoch 3.22: Loss = 0.625183
Epoch 3.23: Loss = 0.742355
Epoch 3.24: Loss = 0.855072
Epoch 3.25: Loss = 0.72197
Epoch 3.26: Loss = 0.653412
Epoch 3.27: Loss = 0.694733
Epoch 3.28: Loss = 0.746902
Epoch 3.29: Loss = 0.738586
Epoch 3.30: Loss = 0.714142
Epoch 3.31: Loss = 0.782898
Epoch 3.32: Loss = 0.725067
Epoch 3.33: Loss = 0.604233
Epoch 3.34: Loss = 0.78714
Epoch 3.35: Loss = 0.769119
Epoch 3.36: Loss = 0.811325
Epoch 3.37: Loss = 0.767273
Epoch 3.38: Loss = 0.748947
Epoch 3.39: Loss = 0.793015
Epoch 3.40: Loss = 0.724274
Epoch 3.41: Loss = 0.738327
Epoch 3.42: Loss = 0.756073
Epoch 3.43: Loss = 0.733658
Epoch 3.44: Loss = 0.67421
Epoch 3.45: Loss = 0.704208
Epoch 3.46: Loss = 0.841492
Epoch 3.47: Loss = 0.741043
Epoch 3.48: Loss = 0.653687
Epoch 3.49: Loss = 0.801453
Epoch 3.50: Loss = 0.720139
Epoch 3.51: Loss = 0.636429
Epoch 3.52: Loss = 0.783295
Epoch 3.53: Loss = 0.867615
Epoch 3.54: Loss = 0.635773
Epoch 3.55: Loss = 0.767761
Epoch 3.56: Loss = 0.75824
Epoch 3.57: Loss = 0.786758
Epoch 3.58: Loss = 0.708969
Epoch 3.59: Loss = 0.774323
Epoch 3.60: Loss = 0.742279
Epoch 3.61: Loss = 0.693924
Epoch 3.62: Loss = 0.759933
Epoch 3.63: Loss = 0.619293
Epoch 3.64: Loss = 0.647247
Epoch 3.65: Loss = 0.734436
Epoch 3.66: Loss = 0.71843
Epoch 3.67: Loss = 0.729553
Epoch 3.68: Loss = 0.861053
Epoch 3.69: Loss = 0.754395
Epoch 3.70: Loss = 0.772583
Epoch 3.71: Loss = 0.655167
Epoch 3.72: Loss = 0.756332
Epoch 3.73: Loss = 0.831589
Epoch 3.74: Loss = 0.812057
Epoch 3.75: Loss = 0.704422
Epoch 3.76: Loss = 0.772308
Epoch 3.77: Loss = 0.736267
Epoch 3.78: Loss = 0.739456
Epoch 3.79: Loss = 0.687286
Epoch 3.80: Loss = 0.676086
Epoch 3.81: Loss = 0.692566
Epoch 3.82: Loss = 0.690765
Epoch 3.83: Loss = 0.826645
Epoch 3.84: Loss = 0.718414
Epoch 3.85: Loss = 0.708389
Epoch 3.86: Loss = 0.736923
Epoch 3.87: Loss = 0.766037
Epoch 3.88: Loss = 0.640564
Epoch 3.89: Loss = 0.796005
Epoch 3.90: Loss = 0.720291
Epoch 3.91: Loss = 0.806488
Epoch 3.92: Loss = 0.712357
Epoch 3.93: Loss = 0.797699
Epoch 3.94: Loss = 0.709335
Epoch 3.95: Loss = 0.736496
Epoch 3.96: Loss = 0.702484
Epoch 3.97: Loss = 0.614594
Epoch 3.98: Loss = 0.718124
Epoch 3.99: Loss = 0.749573
Epoch 3.100: Loss = 0.771744
Epoch 3.101: Loss = 0.808182
Epoch 3.102: Loss = 0.756668
Epoch 3.103: Loss = 0.743301
Epoch 3.104: Loss = 0.665115
Epoch 3.105: Loss = 0.644775
Epoch 3.106: Loss = 0.859207
Epoch 3.107: Loss = 0.739365
Epoch 3.108: Loss = 0.781189
Epoch 3.109: Loss = 0.799667
Epoch 3.110: Loss = 0.725662
Epoch 3.111: Loss = 0.687744
Epoch 3.112: Loss = 0.658356
Epoch 3.113: Loss = 0.664215
Epoch 3.114: Loss = 0.738205
Epoch 3.115: Loss = 0.768661
Epoch 3.116: Loss = 0.633163
Epoch 3.117: Loss = 0.784729
Epoch 3.118: Loss = 0.68718
Epoch 3.119: Loss = 0.738754
Epoch 3.120: Loss = 0.688065
TRAIN LOSS = 0.739838
TRAIN ACC = 75.293 % (45178/60000)
Loss = 0.671692
Loss = 0.761765
Loss = 0.704849
Loss = 0.679504
Loss = 0.689041
Loss = 0.815872
Loss = 0.843506
Loss = 0.791382
Loss = 0.74765
Loss = 0.678024
Loss = 0.824371
Loss = 0.832275
Loss = 0.736206
Loss = 0.783356
Loss = 0.741669
Loss = 0.767731
Loss = 0.721924
Loss = 0.732574
Loss = 0.78717
Loss = 0.726166
TEST LOSS = 0.751836
TEST ACC = 451.779 % (7597/10000)
Reducing learning rate to 0.100006
Epoch 4.1: Loss = 0.731293
Epoch 4.2: Loss = 0.714828
Epoch 4.3: Loss = 0.804626
Epoch 4.4: Loss = 0.675705
Epoch 4.5: Loss = 0.730011
Epoch 4.6: Loss = 0.798965
Epoch 4.7: Loss = 0.740997
Epoch 4.8: Loss = 0.849548
Epoch 4.9: Loss = 0.64415
Epoch 4.10: Loss = 0.557083
Epoch 4.11: Loss = 0.848282
Epoch 4.12: Loss = 0.719543
Epoch 4.13: Loss = 0.750717
Epoch 4.14: Loss = 0.748077
Epoch 4.15: Loss = 0.746063
Epoch 4.16: Loss = 0.795273
Epoch 4.17: Loss = 0.683746
Epoch 4.18: Loss = 0.737991
Epoch 4.19: Loss = 0.739059
Epoch 4.20: Loss = 0.831253
Epoch 4.21: Loss = 0.652847
Epoch 4.22: Loss = 0.572571
Epoch 4.23: Loss = 0.688156
Epoch 4.24: Loss = 0.830643
Epoch 4.25: Loss = 0.69693
Epoch 4.26: Loss = 0.610428
Epoch 4.27: Loss = 0.676163
Epoch 4.28: Loss = 0.704697
Epoch 4.29: Loss = 0.749634
Epoch 4.30: Loss = 0.713974
Epoch 4.31: Loss = 0.795319
Epoch 4.32: Loss = 0.706711
Epoch 4.33: Loss = 0.601669
Epoch 4.34: Loss = 0.794083
Epoch 4.35: Loss = 0.732254
Epoch 4.36: Loss = 0.80072
Epoch 4.37: Loss = 0.764618
Epoch 4.38: Loss = 0.714981
Epoch 4.39: Loss = 0.763138
Epoch 4.40: Loss = 0.701401
Epoch 4.41: Loss = 0.722733
Epoch 4.42: Loss = 0.726715
Epoch 4.43: Loss = 0.688507
Epoch 4.44: Loss = 0.624298
Epoch 4.45: Loss = 0.739655
Epoch 4.46: Loss = 0.806778
Epoch 4.47: Loss = 0.713318
Epoch 4.48: Loss = 0.596863
Epoch 4.49: Loss = 0.815201
Epoch 4.50: Loss = 0.703232
Epoch 4.51: Loss = 0.62854
Epoch 4.52: Loss = 0.749191
Epoch 4.53: Loss = 0.828476
Epoch 4.54: Loss = 0.611343
Epoch 4.55: Loss = 0.742447
Epoch 4.56: Loss = 0.71048
Epoch 4.57: Loss = 0.805222
Epoch 4.58: Loss = 0.731842
Epoch 4.59: Loss = 0.773514
Epoch 4.60: Loss = 0.781418
Epoch 4.61: Loss = 0.696503
Epoch 4.62: Loss = 0.808121
Epoch 4.63: Loss = 0.606049
Epoch 4.64: Loss = 0.634277
Epoch 4.65: Loss = 0.714539
Epoch 4.66: Loss = 0.66037
Epoch 4.67: Loss = 0.65535
Epoch 4.68: Loss = 0.894211
Epoch 4.69: Loss = 0.716965
Epoch 4.70: Loss = 0.766724
Epoch 4.71: Loss = 0.619125
Epoch 4.72: Loss = 0.721039
Epoch 4.73: Loss = 0.766144
Epoch 4.74: Loss = 0.723648
Epoch 4.75: Loss = 0.68248
Epoch 4.76: Loss = 0.697357
Epoch 4.77: Loss = 0.691162
Epoch 4.78: Loss = 0.683365
Epoch 4.79: Loss = 0.646667
Epoch 4.80: Loss = 0.649139
Epoch 4.81: Loss = 0.680817
Epoch 4.82: Loss = 0.636475
Epoch 4.83: Loss = 0.760193
Epoch 4.84: Loss = 0.671478
Epoch 4.85: Loss = 0.700821
Epoch 4.86: Loss = 0.724533
Epoch 4.87: Loss = 0.720764
Epoch 4.88: Loss = 0.619751
Epoch 4.89: Loss = 0.773773
Epoch 4.90: Loss = 0.682251
Epoch 4.91: Loss = 0.785599
Epoch 4.92: Loss = 0.695618
Epoch 4.93: Loss = 0.74971
Epoch 4.94: Loss = 0.638687
Epoch 4.95: Loss = 0.704315
Epoch 4.96: Loss = 0.664307
Epoch 4.97: Loss = 0.599091
Epoch 4.98: Loss = 0.697403
Epoch 4.99: Loss = 0.678741
Epoch 4.100: Loss = 0.73999
Epoch 4.101: Loss = 0.76593
Epoch 4.102: Loss = 0.739792
Epoch 4.103: Loss = 0.681992
Epoch 4.104: Loss = 0.604462
Epoch 4.105: Loss = 0.612473
Epoch 4.106: Loss = 0.786636
Epoch 4.107: Loss = 0.7341
Epoch 4.108: Loss = 0.798904
Epoch 4.109: Loss = 0.73909
Epoch 4.110: Loss = 0.691711
Epoch 4.111: Loss = 0.660049
Epoch 4.112: Loss = 0.60936
Epoch 4.113: Loss = 0.654541
Epoch 4.114: Loss = 0.710587
Epoch 4.115: Loss = 0.717972
Epoch 4.116: Loss = 0.628036
Epoch 4.117: Loss = 0.78302
Epoch 4.118: Loss = 0.622803
Epoch 4.119: Loss = 0.712921
Epoch 4.120: Loss = 0.64566
TRAIN LOSS = 0.712311
TRAIN ACC = 77.0828 % (46252/60000)
Loss = 0.60257
Loss = 0.740051
Loss = 0.666626
Loss = 0.645355
Loss = 0.638855
Loss = 0.806412
Loss = 0.831558
Loss = 0.736862
Loss = 0.705063
Loss = 0.639328
Loss = 0.789856
Loss = 0.841187
Loss = 0.706589
Loss = 0.780884
Loss = 0.711594
Loss = 0.760895
Loss = 0.697174
Loss = 0.692886
Loss = 0.778351
Loss = 0.714203
TEST LOSS = 0.724315
TEST ACC = 462.52 % (7723/10000)
Reducing learning rate to 0.100006
Epoch 5.1: Loss = 0.690735
Epoch 5.2: Loss = 0.697418
Epoch 5.3: Loss = 0.769287
Epoch 5.4: Loss = 0.649384
Epoch 5.5: Loss = 0.71254
Epoch 5.6: Loss = 0.744827
Epoch 5.7: Loss = 0.687271
Epoch 5.8: Loss = 0.809769
Epoch 5.9: Loss = 0.591705
Epoch 5.10: Loss = 0.510193
Epoch 5.11: Loss = 0.789734
Epoch 5.12: Loss = 0.664337
Epoch 5.13: Loss = 0.682617
Epoch 5.14: Loss = 0.670944
Epoch 5.15: Loss = 0.713776
Epoch 5.16: Loss = 0.748917
Epoch 5.17: Loss = 0.637512
Epoch 5.18: Loss = 0.721069
Epoch 5.19: Loss = 0.695831
Epoch 5.20: Loss = 0.802338
Epoch 5.21: Loss = 0.621353
Epoch 5.22: Loss = 0.565857
Epoch 5.23: Loss = 0.664886
Epoch 5.24: Loss = 0.827393
Epoch 5.25: Loss = 0.704941
Epoch 5.26: Loss = 0.592438
Epoch 5.27: Loss = 0.653198
Epoch 5.28: Loss = 0.697144
Epoch 5.29: Loss = 0.694092
Epoch 5.30: Loss = 0.698334
Epoch 5.31: Loss = 0.754929
Epoch 5.32: Loss = 0.708664
Epoch 5.33: Loss = 0.57988
Epoch 5.34: Loss = 0.747681
Epoch 5.35: Loss = 0.700165
Epoch 5.36: Loss = 0.775589
Epoch 5.37: Loss = 0.756729
Epoch 5.38: Loss = 0.749634
Epoch 5.39: Loss = 0.784729
Epoch 5.40: Loss = 0.727386
Epoch 5.41: Loss = 0.705444
Epoch 5.42: Loss = 0.733154
Epoch 5.43: Loss = 0.638367
Epoch 5.44: Loss = 0.607224
Epoch 5.45: Loss = 0.703491
Epoch 5.46: Loss = 0.837631
Epoch 5.47: Loss = 0.685425
Epoch 5.48: Loss = 0.59642
Epoch 5.49: Loss = 0.768661
Epoch 5.50: Loss = 0.702881
Epoch 5.51: Loss = 0.567062
Epoch 5.52: Loss = 0.728348
Epoch 5.53: Loss = 0.807236
Epoch 5.54: Loss = 0.579773
Epoch 5.55: Loss = 0.73259
Epoch 5.56: Loss = 0.696136
Epoch 5.57: Loss = 0.773209
Epoch 5.58: Loss = 0.659958
Epoch 5.59: Loss = 0.756073
Epoch 5.60: Loss = 0.716278
Epoch 5.61: Loss = 0.656754
Epoch 5.62: Loss = 0.755585
Epoch 5.63: Loss = 0.577148
Epoch 5.64: Loss = 0.62001
Epoch 5.65: Loss = 0.727524
Epoch 5.66: Loss = 0.641861
Epoch 5.67: Loss = 0.644531
Epoch 5.68: Loss = 0.8862
Epoch 5.69: Loss = 0.691498
Epoch 5.70: Loss = 0.731155
Epoch 5.71: Loss = 0.585266
Epoch 5.72: Loss = 0.698151
Epoch 5.73: Loss = 0.772614
Epoch 5.74: Loss = 0.733063
Epoch 5.75: Loss = 0.6772
Epoch 5.76: Loss = 0.681091
Epoch 5.77: Loss = 0.707031
Epoch 5.78: Loss = 0.692413
Epoch 5.79: Loss = 0.639465
Epoch 5.80: Loss = 0.629166
Epoch 5.81: Loss = 0.67836
Epoch 5.82: Loss = 0.619781
Epoch 5.83: Loss = 0.777115
Epoch 5.84: Loss = 0.680328
Epoch 5.85: Loss = 0.728073
Epoch 5.86: Loss = 0.725067
Epoch 5.87: Loss = 0.716721
Epoch 5.88: Loss = 0.607224
Epoch 5.89: Loss = 0.779495
Epoch 5.90: Loss = 0.680725
Epoch 5.91: Loss = 0.808685
Epoch 5.92: Loss = 0.674454
Epoch 5.93: Loss = 0.703995
Epoch 5.94: Loss = 0.634598
Epoch 5.95: Loss = 0.702499
Epoch 5.96: Loss = 0.665192
Epoch 5.97: Loss = 0.618225
Epoch 5.98: Loss = 0.696594
Epoch 5.99: Loss = 0.704437
Epoch 5.100: Loss = 0.7547
Epoch 5.101: Loss = 0.787567
Epoch 5.102: Loss = 0.766647
Epoch 5.103: Loss = 0.678818
Epoch 5.104: Loss = 0.6147
Epoch 5.105: Loss = 0.632813
Epoch 5.106: Loss = 0.79483
Epoch 5.107: Loss = 0.709122
Epoch 5.108: Loss = 0.82016
Epoch 5.109: Loss = 0.73851
Epoch 5.110: Loss = 0.715576
Epoch 5.111: Loss = 0.681076
Epoch 5.112: Loss = 0.629669
Epoch 5.113: Loss = 0.673859
Epoch 5.114: Loss = 0.741394
Epoch 5.115: Loss = 0.724991
Epoch 5.116: Loss = 0.667709
Epoch 5.117: Loss = 0.795685
Epoch 5.118: Loss = 0.674149
Epoch 5.119: Loss = 0.753098
Epoch 5.120: Loss = 0.682709
TRAIN LOSS = 0.699829
TRAIN ACC = 77.9266 % (46758/60000)
Loss = 0.61528
Loss = 0.738556
Loss = 0.687164
Loss = 0.649231
Loss = 0.686203
Loss = 0.799149
Loss = 0.833374
Loss = 0.754364
Loss = 0.744705
Loss = 0.667679
Loss = 0.83934
Loss = 0.886963
Loss = 0.732101
Loss = 0.788437
Loss = 0.740173
Loss = 0.790588
Loss = 0.705307
Loss = 0.732483
Loss = 0.809479
Loss = 0.717941
TEST LOSS = 0.745926
TEST ACC = 467.58 % (7755/10000)
Reducing learning rate to 0.100006
Epoch 6.1: Loss = 0.712387
Epoch 6.2: Loss = 0.727386
Epoch 6.3: Loss = 0.772781
Epoch 6.4: Loss = 0.637222
Epoch 6.5: Loss = 0.726105
Epoch 6.6: Loss = 0.792633
Epoch 6.7: Loss = 0.689987
Epoch 6.8: Loss = 0.842789
Epoch 6.9: Loss = 0.600021
Epoch 6.10: Loss = 0.520645
Epoch 6.11: Loss = 0.795944
Epoch 6.12: Loss = 0.676376
Epoch 6.13: Loss = 0.688812
Epoch 6.14: Loss = 0.675461
Epoch 6.15: Loss = 0.691177
Epoch 6.16: Loss = 0.748856
Epoch 6.17: Loss = 0.675415
Epoch 6.18: Loss = 0.689835
Epoch 6.19: Loss = 0.670013
Epoch 6.20: Loss = 0.772293
Epoch 6.21: Loss = 0.609726
Epoch 6.22: Loss = 0.560547
Epoch 6.23: Loss = 0.663589
Epoch 6.24: Loss = 0.800201
Epoch 6.25: Loss = 0.664108
Epoch 6.26: Loss = 0.627411
Epoch 6.27: Loss = 0.680618
Epoch 6.28: Loss = 0.704437
Epoch 6.29: Loss = 0.708282
Epoch 6.30: Loss = 0.735596
Epoch 6.31: Loss = 0.763275
Epoch 6.32: Loss = 0.691116
Epoch 6.33: Loss = 0.570633
Epoch 6.34: Loss = 0.759445
Epoch 6.35: Loss = 0.734772
Epoch 6.36: Loss = 0.745102
Epoch 6.37: Loss = 0.733749
Epoch 6.38: Loss = 0.749054
Epoch 6.39: Loss = 0.740784
Epoch 6.40: Loss = 0.735367
Epoch 6.41: Loss = 0.750809
Epoch 6.42: Loss = 0.718521
Epoch 6.43: Loss = 0.65654
Epoch 6.44: Loss = 0.56221
Epoch 6.45: Loss = 0.698334
Epoch 6.46: Loss = 0.82663
Epoch 6.47: Loss = 0.677902
Epoch 6.48: Loss = 0.576752
Epoch 6.49: Loss = 0.761261
Epoch 6.50: Loss = 0.68103
Epoch 6.51: Loss = 0.567886
Epoch 6.52: Loss = 0.706772
Epoch 6.53: Loss = 0.773865
Epoch 6.54: Loss = 0.55838
Epoch 6.55: Loss = 0.690918
Epoch 6.56: Loss = 0.705383
Epoch 6.57: Loss = 0.800186
Epoch 6.58: Loss = 0.657227
Epoch 6.59: Loss = 0.755554
Epoch 6.60: Loss = 0.647156
Epoch 6.61: Loss = 0.657516
Epoch 6.62: Loss = 0.789902
Epoch 6.63: Loss = 0.587128
Epoch 6.64: Loss = 0.595749
Epoch 6.65: Loss = 0.70787
Epoch 6.66: Loss = 0.623566
Epoch 6.67: Loss = 0.639969
Epoch 6.68: Loss = 0.847092
Epoch 6.69: Loss = 0.726913
Epoch 6.70: Loss = 0.741882
Epoch 6.71: Loss = 0.61026
Epoch 6.72: Loss = 0.661911
Epoch 6.73: Loss = 0.787308
Epoch 6.74: Loss = 0.720108
Epoch 6.75: Loss = 0.668106
Epoch 6.76: Loss = 0.700806
Epoch 6.77: Loss = 0.692551
Epoch 6.78: Loss = 0.670593
Epoch 6.79: Loss = 0.641464
Epoch 6.80: Loss = 0.617004
Epoch 6.81: Loss = 0.698135
Epoch 6.82: Loss = 0.633469
Epoch 6.83: Loss = 0.799774
Epoch 6.84: Loss = 0.660599
Epoch 6.85: Loss = 0.75116
Epoch 6.86: Loss = 0.747498
Epoch 6.87: Loss = 0.70372
Epoch 6.88: Loss = 0.633698
Epoch 6.89: Loss = 0.772141
Epoch 6.90: Loss = 0.68541
Epoch 6.91: Loss = 0.778961
Epoch 6.92: Loss = 0.693634
Epoch 6.93: Loss = 0.69989
Epoch 6.94: Loss = 0.657043
Epoch 6.95: Loss = 0.719925
Epoch 6.96: Loss = 0.671738
Epoch 6.97: Loss = 0.621277
Epoch 6.98: Loss = 0.70282
Epoch 6.99: Loss = 0.703232
Epoch 6.100: Loss = 0.788635
Epoch 6.101: Loss = 0.809937
Epoch 6.102: Loss = 0.794495
Epoch 6.103: Loss = 0.653625
Epoch 6.104: Loss = 0.59523
Epoch 6.105: Loss = 0.658417
Epoch 6.106: Loss = 0.784729
Epoch 6.107: Loss = 0.747849
Epoch 6.108: Loss = 0.805725
Epoch 6.109: Loss = 0.765564
Epoch 6.110: Loss = 0.6931
Epoch 6.111: Loss = 0.68541
Epoch 6.112: Loss = 0.667709
Epoch 6.113: Loss = 0.663452
Epoch 6.114: Loss = 0.719894
Epoch 6.115: Loss = 0.699738
Epoch 6.116: Loss = 0.638199
Epoch 6.117: Loss = 0.819153
Epoch 6.118: Loss = 0.649979
Epoch 6.119: Loss = 0.709747
Epoch 6.120: Loss = 0.676559
TRAIN LOSS = 0.699234
TRAIN ACC = 78.5355 % (47123/60000)
Loss = 0.59845
Loss = 0.74469
Loss = 0.649673
Loss = 0.625626
Loss = 0.67247
Loss = 0.806107
Loss = 0.863327
Loss = 0.733871
Loss = 0.674637
Loss = 0.653519
Loss = 0.862061
Loss = 0.867691
Loss = 0.708954
Loss = 0.770523
Loss = 0.681198
Loss = 0.805695
Loss = 0.729156
Loss = 0.731277
Loss = 0.766815
Loss = 0.7164
TEST LOSS = 0.733107
TEST ACC = 471.23 % (7796/10000)
Reducing learning rate to 0.100006
Epoch 7.1: Loss = 0.67244
Epoch 7.2: Loss = 0.717209
Epoch 7.3: Loss = 0.729843
Epoch 7.4: Loss = 0.655914
Epoch 7.5: Loss = 0.714935
Epoch 7.6: Loss = 0.784454
Epoch 7.7: Loss = 0.6633
Epoch 7.8: Loss = 0.862671
Epoch 7.9: Loss = 0.594742
Epoch 7.10: Loss = 0.559174
Epoch 7.11: Loss = 0.828964
Epoch 7.12: Loss = 0.685165
Epoch 7.13: Loss = 0.717697
Epoch 7.14: Loss = 0.687973
Epoch 7.15: Loss = 0.707199
Epoch 7.16: Loss = 0.772842
Epoch 7.17: Loss = 0.706909
Epoch 7.18: Loss = 0.731522
Epoch 7.19: Loss = 0.67952
Epoch 7.20: Loss = 0.769165
Epoch 7.21: Loss = 0.659882
Epoch 7.22: Loss = 0.580109
Epoch 7.23: Loss = 0.673508
Epoch 7.24: Loss = 0.815872
Epoch 7.25: Loss = 0.661774
Epoch 7.26: Loss = 0.616425
Epoch 7.27: Loss = 0.713181
Epoch 7.28: Loss = 0.714798
Epoch 7.29: Loss = 0.729568
Epoch 7.30: Loss = 0.759003
Epoch 7.31: Loss = 0.808716
Epoch 7.32: Loss = 0.691391
Epoch 7.33: Loss = 0.625458
Epoch 7.34: Loss = 0.805313
Epoch 7.35: Loss = 0.761215
Epoch 7.36: Loss = 0.771088
Epoch 7.37: Loss = 0.790619
Epoch 7.38: Loss = 0.799393
Epoch 7.39: Loss = 0.782608
Epoch 7.40: Loss = 0.734406
Epoch 7.41: Loss = 0.767593
Epoch 7.42: Loss = 0.767273
Epoch 7.43: Loss = 0.705704
Epoch 7.44: Loss = 0.614914
Epoch 7.45: Loss = 0.756912
Epoch 7.46: Loss = 0.852859
Epoch 7.47: Loss = 0.695953
Epoch 7.48: Loss = 0.635254
Epoch 7.49: Loss = 0.763611
Epoch 7.50: Loss = 0.715042
Epoch 7.51: Loss = 0.619278
Epoch 7.52: Loss = 0.778534
Epoch 7.53: Loss = 0.820786
Epoch 7.54: Loss = 0.633362
Epoch 7.55: Loss = 0.761185
Epoch 7.56: Loss = 0.763535
Epoch 7.57: Loss = 0.844513
Epoch 7.58: Loss = 0.706207
Epoch 7.59: Loss = 0.830856
Epoch 7.60: Loss = 0.676529
Epoch 7.61: Loss = 0.701889
Epoch 7.62: Loss = 0.822952
Epoch 7.63: Loss = 0.645676
Epoch 7.64: Loss = 0.638565
Epoch 7.65: Loss = 0.791229
Epoch 7.66: Loss = 0.670288
Epoch 7.67: Loss = 0.682831
Epoch 7.68: Loss = 0.914291
Epoch 7.69: Loss = 0.774353
Epoch 7.70: Loss = 0.800308
Epoch 7.71: Loss = 0.628616
Epoch 7.72: Loss = 0.723404
Epoch 7.73: Loss = 0.833755
Epoch 7.74: Loss = 0.811966
Epoch 7.75: Loss = 0.695496
Epoch 7.76: Loss = 0.721237
Epoch 7.77: Loss = 0.726227
Epoch 7.78: Loss = 0.719727
Epoch 7.79: Loss = 0.716888
Epoch 7.80: Loss = 0.629791
Epoch 7.81: Loss = 0.727493
Epoch 7.82: Loss = 0.675415
Epoch 7.83: Loss = 0.837021
Epoch 7.84: Loss = 0.701035
Epoch 7.85: Loss = 0.766449
Epoch 7.86: Loss = 0.758163
Epoch 7.87: Loss = 0.70488
Epoch 7.88: Loss = 0.696396
Epoch 7.89: Loss = 0.819366
Epoch 7.90: Loss = 0.735855
Epoch 7.91: Loss = 0.822845
Epoch 7.92: Loss = 0.739319
Epoch 7.93: Loss = 0.754013
Epoch 7.94: Loss = 0.676086
Epoch 7.95: Loss = 0.744278
Epoch 7.96: Loss = 0.719711
Epoch 7.97: Loss = 0.634613
Epoch 7.98: Loss = 0.733032
Epoch 7.99: Loss = 0.751999
Epoch 7.100: Loss = 0.836166
Epoch 7.101: Loss = 0.838791
Epoch 7.102: Loss = 0.815323
Epoch 7.103: Loss = 0.706482
Epoch 7.104: Loss = 0.615768
Epoch 7.105: Loss = 0.698013
Epoch 7.106: Loss = 0.792465
Epoch 7.107: Loss = 0.799103
Epoch 7.108: Loss = 0.822617
Epoch 7.109: Loss = 0.793137
Epoch 7.110: Loss = 0.759399
Epoch 7.111: Loss = 0.699326
Epoch 7.112: Loss = 0.686417
Epoch 7.113: Loss = 0.69191
Epoch 7.114: Loss = 0.735886
Epoch 7.115: Loss = 0.718628
Epoch 7.116: Loss = 0.712814
Epoch 7.117: Loss = 0.896271
Epoch 7.118: Loss = 0.651794
Epoch 7.119: Loss = 0.796921
Epoch 7.120: Loss = 0.709
TRAIN LOSS = 0.732269
TRAIN ACC = 78.5553 % (47135/60000)
Loss = 0.641586
Loss = 0.853455
Loss = 0.74585
Loss = 0.683899
Loss = 0.750168
Loss = 0.88266
Loss = 0.956207
Loss = 0.808823
Loss = 0.792099
Loss = 0.730026
Loss = 0.936172
Loss = 0.97345
Loss = 0.786484
Loss = 0.836288
Loss = 0.752731
Loss = 0.88382
Loss = 0.77002
Loss = 0.757141
Loss = 0.845581
Loss = 0.80484
TEST LOSS = 0.809565
TEST ACC = 471.349 % (7818/10000)
Reducing learning rate to 0.100006
Epoch 8.1: Loss = 0.727402
Epoch 8.2: Loss = 0.77475
Epoch 8.3: Loss = 0.811752
Epoch 8.4: Loss = 0.69278
Epoch 8.5: Loss = 0.781235
Epoch 8.6: Loss = 0.834641
Epoch 8.7: Loss = 0.729187
Epoch 8.8: Loss = 0.951828
Epoch 8.9: Loss = 0.629822
Epoch 8.10: Loss = 0.594955
Epoch 8.11: Loss = 0.912354
Epoch 8.12: Loss = 0.763092
Epoch 8.13: Loss = 0.751389
Epoch 8.14: Loss = 0.811432
Epoch 8.15: Loss = 0.759476
Epoch 8.16: Loss = 0.841736
Epoch 8.17: Loss = 0.73291
Epoch 8.18: Loss = 0.755859
Epoch 8.19: Loss = 0.714294
Epoch 8.20: Loss = 0.813004
Epoch 8.21: Loss = 0.715881
Epoch 8.22: Loss = 0.58696
Epoch 8.23: Loss = 0.67659
Epoch 8.24: Loss = 0.837677
Epoch 8.25: Loss = 0.694519
Epoch 8.26: Loss = 0.675583
Epoch 8.27: Loss = 0.703354
Epoch 8.28: Loss = 0.790161
Epoch 8.29: Loss = 0.722961
Epoch 8.30: Loss = 0.822266
Epoch 8.31: Loss = 0.809937
Epoch 8.32: Loss = 0.73111
Epoch 8.33: Loss = 0.658356
Epoch 8.34: Loss = 0.859589
Epoch 8.35: Loss = 0.750748
Epoch 8.36: Loss = 0.837906
Epoch 8.37: Loss = 0.829178
Epoch 8.38: Loss = 0.829666
Epoch 8.39: Loss = 0.79747
Epoch 8.40: Loss = 0.759857
Epoch 8.41: Loss = 0.784317
Epoch 8.42: Loss = 0.798645
Epoch 8.43: Loss = 0.715485
Epoch 8.44: Loss = 0.590363
Epoch 8.45: Loss = 0.799988
Epoch 8.46: Loss = 0.893234
Epoch 8.47: Loss = 0.728958
Epoch 8.48: Loss = 0.63768
Epoch 8.49: Loss = 0.81015
Epoch 8.50: Loss = 0.754623
Epoch 8.51: Loss = 0.615005
Epoch 8.52: Loss = 0.822052
Epoch 8.53: Loss = 0.831833
Epoch 8.54: Loss = 0.629807
Epoch 8.55: Loss = 0.802597
Epoch 8.56: Loss = 0.762756
Epoch 8.57: Loss = 0.877136
Epoch 8.58: Loss = 0.717712
Epoch 8.59: Loss = 0.844955
Epoch 8.60: Loss = 0.725769
Epoch 8.61: Loss = 0.740799
Epoch 8.62: Loss = 0.83255
Epoch 8.63: Loss = 0.646454
Epoch 8.64: Loss = 0.6763
Epoch 8.65: Loss = 0.787949
Epoch 8.66: Loss = 0.692673
Epoch 8.67: Loss = 0.684753
Epoch 8.68: Loss = 0.962616
Epoch 8.69: Loss = 0.788239
Epoch 8.70: Loss = 0.790466
Epoch 8.71: Loss = 0.641205
Epoch 8.72: Loss = 0.746216
Epoch 8.73: Loss = 0.863235
Epoch 8.74: Loss = 0.833344
Epoch 8.75: Loss = 0.714493
Epoch 8.76: Loss = 0.750397
Epoch 8.77: Loss = 0.737732
Epoch 8.78: Loss = 0.753235
Epoch 8.79: Loss = 0.734253
Epoch 8.80: Loss = 0.648926
Epoch 8.81: Loss = 0.750961
Epoch 8.82: Loss = 0.720001
Epoch 8.83: Loss = 0.827103
Epoch 8.84: Loss = 0.671188
Epoch 8.85: Loss = 0.776886
Epoch 8.86: Loss = 0.789459
Epoch 8.87: Loss = 0.679459
Epoch 8.88: Loss = 0.711349
Epoch 8.89: Loss = 0.816605
Epoch 8.90: Loss = 0.76297
Epoch 8.91: Loss = 0.868011
Epoch 8.92: Loss = 0.765503
Epoch 8.93: Loss = 0.749146
Epoch 8.94: Loss = 0.722794
Epoch 8.95: Loss = 0.736801
Epoch 8.96: Loss = 0.734665
Epoch 8.97: Loss = 0.66803
Epoch 8.98: Loss = 0.750534
Epoch 8.99: Loss = 0.735672
Epoch 8.100: Loss = 0.850189
Epoch 8.101: Loss = 0.808945
Epoch 8.102: Loss = 0.823868
Epoch 8.103: Loss = 0.70224
Epoch 8.104: Loss = 0.604813
Epoch 8.105: Loss = 0.734741
Epoch 8.106: Loss = 0.816116
Epoch 8.107: Loss = 0.800171
Epoch 8.108: Loss = 0.885498
Epoch 8.109: Loss = 0.809647
Epoch 8.110: Loss = 0.74791
Epoch 8.111: Loss = 0.733551
Epoch 8.112: Loss = 0.73111
Epoch 8.113: Loss = 0.683792
Epoch 8.114: Loss = 0.764236
Epoch 8.115: Loss = 0.738586
Epoch 8.116: Loss = 0.719742
Epoch 8.117: Loss = 0.872879
Epoch 8.118: Loss = 0.69342
Epoch 8.119: Loss = 0.755936
Epoch 8.120: Loss = 0.726913
TRAIN LOSS = 0.757385
TRAIN ACC = 78.5477 % (47131/60000)
Loss = 0.663437
Loss = 0.876129
Loss = 0.727783
Loss = 0.701218
Loss = 0.756485
Loss = 0.869659
Loss = 0.991943
Loss = 0.801636
Loss = 0.786346
Loss = 0.732224
Loss = 0.997681
Loss = 0.969055
Loss = 0.784546
Loss = 0.825989
Loss = 0.746414
Loss = 0.867966
Loss = 0.771988
Loss = 0.745209
Loss = 0.819092
Loss = 0.759445
TEST LOSS = 0.809712
TEST ACC = 471.309 % (7796/10000)
Reducing learning rate to 0.100006
Epoch 9.1: Loss = 0.76741
Epoch 9.2: Loss = 0.778046
Epoch 9.3: Loss = 0.798203
Epoch 9.4: Loss = 0.70282
Epoch 9.5: Loss = 0.799225
Epoch 9.6: Loss = 0.844467
Epoch 9.7: Loss = 0.705338
Epoch 9.8: Loss = 0.941422
Epoch 9.9: Loss = 0.666183
Epoch 9.10: Loss = 0.564789
Epoch 9.11: Loss = 0.894592
Epoch 9.12: Loss = 0.748627
Epoch 9.13: Loss = 0.770874
Epoch 9.14: Loss = 0.753647
Epoch 9.15: Loss = 0.759277
Epoch 9.16: Loss = 0.824295
Epoch 9.17: Loss = 0.749405
Epoch 9.18: Loss = 0.783432
Epoch 9.19: Loss = 0.742188
Epoch 9.20: Loss = 0.840942
Epoch 9.21: Loss = 0.684448
Epoch 9.22: Loss = 0.640518
Epoch 9.23: Loss = 0.68306
Epoch 9.24: Loss = 0.816711
Epoch 9.25: Loss = 0.729752
Epoch 9.26: Loss = 0.650726
Epoch 9.27: Loss = 0.680115
Epoch 9.28: Loss = 0.782059
Epoch 9.29: Loss = 0.736053
Epoch 9.30: Loss = 0.80748
Epoch 9.31: Loss = 0.802521
Epoch 9.32: Loss = 0.754196
Epoch 9.33: Loss = 0.668365
Epoch 9.34: Loss = 0.832687
Epoch 9.35: Loss = 0.80751
Epoch 9.36: Loss = 0.829269
Epoch 9.37: Loss = 0.88855
Epoch 9.38: Loss = 0.817398
Epoch 9.39: Loss = 0.791946
Epoch 9.40: Loss = 0.735931
Epoch 9.41: Loss = 0.742981
Epoch 9.42: Loss = 0.772186
Epoch 9.43: Loss = 0.732071
Epoch 9.44: Loss = 0.627029
Epoch 9.45: Loss = 0.797104
Epoch 9.46: Loss = 0.93512
Epoch 9.47: Loss = 0.721252
Epoch 9.48: Loss = 0.640625
Epoch 9.49: Loss = 0.765381
Epoch 9.50: Loss = 0.773941
Epoch 9.51: Loss = 0.601196
Epoch 9.52: Loss = 0.822052
Epoch 9.53: Loss = 0.838226
Epoch 9.54: Loss = 0.619553
Epoch 9.55: Loss = 0.805222
Epoch 9.56: Loss = 0.762863
Epoch 9.57: Loss = 0.887161
Epoch 9.58: Loss = 0.718475
Epoch 9.59: Loss = 0.838348
Epoch 9.60: Loss = 0.716415
Epoch 9.61: Loss = 0.675995
Epoch 9.62: Loss = 0.783997
Epoch 9.63: Loss = 0.644775
Epoch 9.64: Loss = 0.699677
Epoch 9.65: Loss = 0.803162
Epoch 9.66: Loss = 0.664841
Epoch 9.67: Loss = 0.711578
Epoch 9.68: Loss = 0.97197
Epoch 9.69: Loss = 0.797577
Epoch 9.70: Loss = 0.826874
Epoch 9.71: Loss = 0.644547
Epoch 9.72: Loss = 0.743317
Epoch 9.73: Loss = 0.834061
Epoch 9.74: Loss = 0.847946
Epoch 9.75: Loss = 0.700867
Epoch 9.76: Loss = 0.747849
Epoch 9.77: Loss = 0.749115
Epoch 9.78: Loss = 0.792969
Epoch 9.79: Loss = 0.723663
Epoch 9.80: Loss = 0.637283
Epoch 9.81: Loss = 0.748566
Epoch 9.82: Loss = 0.786652
Epoch 9.83: Loss = 0.857086
Epoch 9.84: Loss = 0.68129
Epoch 9.85: Loss = 0.78183
Epoch 9.86: Loss = 0.799255
Epoch 9.87: Loss = 0.723846
Epoch 9.88: Loss = 0.719849
Epoch 9.89: Loss = 0.820816
Epoch 9.90: Loss = 0.741135
Epoch 9.91: Loss = 0.844986
Epoch 9.92: Loss = 0.759109
Epoch 9.93: Loss = 0.782013
Epoch 9.94: Loss = 0.752228
Epoch 9.95: Loss = 0.760132
Epoch 9.96: Loss = 0.739426
Epoch 9.97: Loss = 0.66095
Epoch 9.98: Loss = 0.772522
Epoch 9.99: Loss = 0.75827
Epoch 9.100: Loss = 0.877411
Epoch 9.101: Loss = 0.871246
Epoch 9.102: Loss = 0.863678
Epoch 9.103: Loss = 0.703445
Epoch 9.104: Loss = 0.622864
Epoch 9.105: Loss = 0.738342
Epoch 9.106: Loss = 0.873749
Epoch 9.107: Loss = 0.867432
Epoch 9.108: Loss = 0.921143
Epoch 9.109: Loss = 0.843689
Epoch 9.110: Loss = 0.754471
Epoch 9.111: Loss = 0.759735
Epoch 9.112: Loss = 0.738998
Epoch 9.113: Loss = 0.736359
Epoch 9.114: Loss = 0.752869
Epoch 9.115: Loss = 0.79422
Epoch 9.116: Loss = 0.735107
Epoch 9.117: Loss = 0.926178
Epoch 9.118: Loss = 0.745026
Epoch 9.119: Loss = 0.708527
Epoch 9.120: Loss = 0.742386
TRAIN LOSS = 0.764679
TRAIN ACC = 78.6102 % (47169/60000)
Loss = 0.672073
Loss = 0.899139
Loss = 0.726471
Loss = 0.698166
Loss = 0.789337
Loss = 0.902908
Loss = 1.03998
Loss = 0.794449
Loss = 0.786972
Loss = 0.715073
Loss = 0.967392
Loss = 1.00406
Loss = 0.840683
Loss = 0.876999
Loss = 0.806427
Loss = 0.844482
Loss = 0.729797
Loss = 0.803024
Loss = 0.856735
Loss = 0.783417
TEST LOSS = 0.826879
TEST ACC = 471.689 % (7802/10000)
Reducing learning rate to 0.100006
Epoch 10.1: Loss = 0.743729
Epoch 10.2: Loss = 0.794464
Epoch 10.3: Loss = 0.847641
Epoch 10.4: Loss = 0.747772
Epoch 10.5: Loss = 0.819168
Epoch 10.6: Loss = 0.924744
Epoch 10.7: Loss = 0.731155
Epoch 10.8: Loss = 0.957062
Epoch 10.9: Loss = 0.655502
Epoch 10.10: Loss = 0.578629
Epoch 10.11: Loss = 0.875824
Epoch 10.12: Loss = 0.771545
Epoch 10.13: Loss = 0.796524
Epoch 10.14: Loss = 0.773026
Epoch 10.15: Loss = 0.827789
Epoch 10.16: Loss = 0.836929
Epoch 10.17: Loss = 0.73613
Epoch 10.18: Loss = 0.811188
Epoch 10.19: Loss = 0.807327
Epoch 10.20: Loss = 0.860367
Epoch 10.21: Loss = 0.715546
Epoch 10.22: Loss = 0.652847
Epoch 10.23: Loss = 0.709396
Epoch 10.24: Loss = 0.893158
Epoch 10.25: Loss = 0.728195
Epoch 10.26: Loss = 0.655869
Epoch 10.27: Loss = 0.717972
Epoch 10.28: Loss = 0.800018
Epoch 10.29: Loss = 0.806641
Epoch 10.30: Loss = 0.838852
Epoch 10.31: Loss = 0.862808
Epoch 10.32: Loss = 0.766281
Epoch 10.33: Loss = 0.706085
Epoch 10.34: Loss = 0.848389
Epoch 10.35: Loss = 0.853989
Epoch 10.36: Loss = 0.876709
Epoch 10.37: Loss = 0.929321
Epoch 10.38: Loss = 0.860809
Epoch 10.39: Loss = 0.816589
Epoch 10.40: Loss = 0.732651
Epoch 10.41: Loss = 0.800797
Epoch 10.42: Loss = 0.791931
Epoch 10.43: Loss = 0.783188
Epoch 10.44: Loss = 0.63797
Epoch 10.45: Loss = 0.770508
Epoch 10.46: Loss = 0.960892
Epoch 10.47: Loss = 0.729736
Epoch 10.48: Loss = 0.636612
Epoch 10.49: Loss = 0.781418
Epoch 10.50: Loss = 0.833511
Epoch 10.51: Loss = 0.619507
Epoch 10.52: Loss = 0.874313
Epoch 10.53: Loss = 0.838608
Epoch 10.54: Loss = 0.641708
Epoch 10.55: Loss = 0.761185
Epoch 10.56: Loss = 0.802704
Epoch 10.57: Loss = 0.925552
Epoch 10.58: Loss = 0.711121
Epoch 10.59: Loss = 0.858704
Epoch 10.60: Loss = 0.789307
Epoch 10.61: Loss = 0.715622
Epoch 10.62: Loss = 0.770752
Epoch 10.63: Loss = 0.670898
Epoch 10.64: Loss = 0.691101
Epoch 10.65: Loss = 0.841263
Epoch 10.66: Loss = 0.703781
Epoch 10.67: Loss = 0.732986
Epoch 10.68: Loss = 1.04442
Epoch 10.69: Loss = 0.779388
Epoch 10.70: Loss = 0.811798
Epoch 10.71: Loss = 0.704041
Epoch 10.72: Loss = 0.742508
Epoch 10.73: Loss = 0.853363
Epoch 10.74: Loss = 0.844528
Epoch 10.75: Loss = 0.727173
Epoch 10.76: Loss = 0.774811
Epoch 10.77: Loss = 0.763657
Epoch 10.78: Loss = 0.824539
Epoch 10.79: Loss = 0.747696
Epoch 10.80: Loss = 0.671738
Epoch 10.81: Loss = 0.750641
Epoch 10.82: Loss = 0.778168
Epoch 10.83: Loss = 0.850784
Epoch 10.84: Loss = 0.712967
Epoch 10.85: Loss = 0.802658
Epoch 10.86: Loss = 0.792725
Epoch 10.87: Loss = 0.768677
Epoch 10.88: Loss = 0.731461
Epoch 10.89: Loss = 0.835938
Epoch 10.90: Loss = 0.75856
Epoch 10.91: Loss = 0.893066
Epoch 10.92: Loss = 0.765686
Epoch 10.93: Loss = 0.848572
Epoch 10.94: Loss = 0.793701
Epoch 10.95: Loss = 0.77536
Epoch 10.96: Loss = 0.748856
Epoch 10.97: Loss = 0.686935
Epoch 10.98: Loss = 0.778122
Epoch 10.99: Loss = 0.761002
Epoch 10.100: Loss = 0.861328
Epoch 10.101: Loss = 0.880951
Epoch 10.102: Loss = 0.838043
Epoch 10.103: Loss = 0.711884
Epoch 10.104: Loss = 0.616241
Epoch 10.105: Loss = 0.730377
Epoch 10.106: Loss = 0.858948
Epoch 10.107: Loss = 0.886292
Epoch 10.108: Loss = 0.918381
Epoch 10.109: Loss = 0.842117
Epoch 10.110: Loss = 0.750946
Epoch 10.111: Loss = 0.762451
Epoch 10.112: Loss = 0.739899
Epoch 10.113: Loss = 0.773071
Epoch 10.114: Loss = 0.800354
Epoch 10.115: Loss = 0.775391
Epoch 10.116: Loss = 0.74617
Epoch 10.117: Loss = 0.919189
Epoch 10.118: Loss = 0.776291
Epoch 10.119: Loss = 0.73143
Epoch 10.120: Loss = 0.768585
TRAIN LOSS = 0.784653
TRAIN ACC = 78.7918 % (47277/60000)
Loss = 0.637115
Loss = 0.878845
Loss = 0.71936
Loss = 0.70517
Loss = 0.791931
Loss = 0.937012
Loss = 1.01332
Loss = 0.792648
Loss = 0.794296
Loss = 0.715302
Loss = 0.984833
Loss = 1.03369
Loss = 0.819656
Loss = 0.884064
Loss = 0.78627
Loss = 0.868958
Loss = 0.781509
Loss = 0.797241
Loss = 0.832123
Loss = 0.793793
TEST LOSS = 0.828357
TEST ACC = 472.769 % (7846/10000)
