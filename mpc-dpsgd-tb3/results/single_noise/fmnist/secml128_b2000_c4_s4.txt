Setting up connection 0
***********************************************************
Training FMNIST
Model: Dense([60000, 1, 128]) => Dense([60000, 1, 128]) => Dense([60000, 1, 10]) => MultiOutput([60000, 10]) => 
Train Examples: 60000
Batch Size: 2000
Num Epochs: 10
Learning Rate: 0.4 to 0.4 over 10 epochs
Clipping Factor: 4
Sigma: 4
***********************************************************
Epoch 1.1: Loss = 2.44305
Epoch 1.2: Loss = 2.14838
Epoch 1.3: Loss = 1.98138
Epoch 1.4: Loss = 1.81612
Epoch 1.5: Loss = 1.66531
Epoch 1.6: Loss = 1.53271
Epoch 1.7: Loss = 1.45802
Epoch 1.8: Loss = 1.31572
Epoch 1.9: Loss = 1.27058
Epoch 1.10: Loss = 1.16438
Epoch 1.11: Loss = 1.13489
Epoch 1.12: Loss = 1.1071
Epoch 1.13: Loss = 1.02444
Epoch 1.14: Loss = 1.05522
Epoch 1.15: Loss = 0.977051
Epoch 1.16: Loss = 0.985107
Epoch 1.17: Loss = 0.955261
Epoch 1.18: Loss = 0.932037
Epoch 1.19: Loss = 0.91954
Epoch 1.20: Loss = 1.04868
Epoch 1.21: Loss = 0.924973
Epoch 1.22: Loss = 1.03024
Epoch 1.23: Loss = 0.883392
Epoch 1.24: Loss = 0.863571
Epoch 1.25: Loss = 0.885895
Epoch 1.26: Loss = 0.888657
Epoch 1.27: Loss = 0.859329
Epoch 1.28: Loss = 0.863052
Epoch 1.29: Loss = 0.843536
Epoch 1.30: Loss = 0.86525
TRAIN LOSS = 1.19478
TRAIN ACC = 59.9014 % (35943/60000)
Loss = 0.806213
Loss = 0.87085
Loss = 0.813843
Loss = 0.819733
Loss = 0.82991
TEST LOSS = 0.82811
TEST ACC = 359.43 % (7100/10000)
Reducing learning rate to 0.399994
Epoch 2.1: Loss = 0.796829
Epoch 2.2: Loss = 0.871155
Epoch 2.3: Loss = 0.763947
Epoch 2.4: Loss = 0.825928
Epoch 2.5: Loss = 0.79248
Epoch 2.6: Loss = 0.838181
Epoch 2.7: Loss = 0.834244
Epoch 2.8: Loss = 0.793793
Epoch 2.9: Loss = 0.756958
Epoch 2.10: Loss = 0.785416
Epoch 2.11: Loss = 0.75322
Epoch 2.12: Loss = 0.774734
Epoch 2.13: Loss = 0.784866
Epoch 2.14: Loss = 0.744888
Epoch 2.15: Loss = 0.74263
Epoch 2.16: Loss = 0.768646
Epoch 2.17: Loss = 0.724289
Epoch 2.18: Loss = 0.783234
Epoch 2.19: Loss = 0.733032
Epoch 2.20: Loss = 0.780182
Epoch 2.21: Loss = 0.804291
Epoch 2.22: Loss = 0.810623
Epoch 2.23: Loss = 0.818802
Epoch 2.24: Loss = 0.731674
Epoch 2.25: Loss = 0.748566
Epoch 2.26: Loss = 0.71196
Epoch 2.27: Loss = 0.767593
Epoch 2.28: Loss = 0.858917
Epoch 2.29: Loss = 0.730698
Epoch 2.30: Loss = 0.725082
TRAIN LOSS = 0.778564
TRAIN ACC = 72.5037 % (43504/60000)
Loss = 0.675842
Loss = 0.748413
Loss = 0.706375
Loss = 0.697876
Loss = 0.7061
TEST LOSS = 0.706921
TEST ACC = 435.039 % (7490/10000)
Reducing learning rate to 0.399994
Epoch 3.1: Loss = 0.617966
Epoch 3.2: Loss = 0.861923
Epoch 3.3: Loss = 0.861984
Epoch 3.4: Loss = 0.725616
Epoch 3.5: Loss = 0.721039
Epoch 3.6: Loss = 0.694351
Epoch 3.7: Loss = 0.756073
Epoch 3.8: Loss = 0.737656
Epoch 3.9: Loss = 0.772278
Epoch 3.10: Loss = 0.760208
Epoch 3.11: Loss = 0.730347
Epoch 3.12: Loss = 0.749527
Epoch 3.13: Loss = 0.664978
Epoch 3.14: Loss = 0.738907
Epoch 3.15: Loss = 0.709213
Epoch 3.16: Loss = 0.728516
Epoch 3.17: Loss = 0.699997
Epoch 3.18: Loss = 0.776886
Epoch 3.19: Loss = 0.775421
Epoch 3.20: Loss = 0.774841
Epoch 3.21: Loss = 0.79541
Epoch 3.22: Loss = 0.863602
Epoch 3.23: Loss = 0.829163
Epoch 3.24: Loss = 0.673096
Epoch 3.25: Loss = 0.71582
Epoch 3.26: Loss = 0.774551
Epoch 3.27: Loss = 0.717697
Epoch 3.28: Loss = 0.678421
Epoch 3.29: Loss = 0.675568
Epoch 3.30: Loss = 0.675125
TRAIN LOSS = 0.741882
TRAIN ACC = 75.4807 % (45290/60000)
Loss = 0.6353
Loss = 0.7314
Loss = 0.688644
Loss = 0.674011
Loss = 0.68956
TEST LOSS = 0.683783
TEST ACC = 452.899 % (7762/10000)
Reducing learning rate to 0.399994
Epoch 4.1: Loss = 0.63533
Epoch 4.2: Loss = 0.672943
Epoch 4.3: Loss = 0.692215
Epoch 4.4: Loss = 0.696655
Epoch 4.5: Loss = 0.679993
Epoch 4.6: Loss = 0.676483
Epoch 4.7: Loss = 0.637711
Epoch 4.8: Loss = 0.632141
Epoch 4.9: Loss = 0.691605
Epoch 4.10: Loss = 0.720703
Epoch 4.11: Loss = 0.717819
Epoch 4.12: Loss = 0.655884
Epoch 4.13: Loss = 0.732834
Epoch 4.14: Loss = 0.693512
Epoch 4.15: Loss = 0.747406
Epoch 4.16: Loss = 0.767441
Epoch 4.17: Loss = 0.759796
Epoch 4.18: Loss = 0.744751
Epoch 4.19: Loss = 0.711151
Epoch 4.20: Loss = 0.650574
Epoch 4.21: Loss = 0.718185
Epoch 4.22: Loss = 0.684494
Epoch 4.23: Loss = 0.770142
Epoch 4.24: Loss = 0.690796
Epoch 4.25: Loss = 0.720245
Epoch 4.26: Loss = 0.75148
Epoch 4.27: Loss = 0.821869
Epoch 4.28: Loss = 0.77243
Epoch 4.29: Loss = 0.721222
Epoch 4.30: Loss = 0.689209
TRAIN LOSS = 0.708572
TRAIN ACC = 77.6794 % (46610/60000)
Loss = 0.685974
Loss = 0.796005
Loss = 0.758499
Loss = 0.745209
Loss = 0.747025
TEST LOSS = 0.746542
TEST ACC = 466.1 % (7726/10000)
Reducing learning rate to 0.399994
Epoch 5.1: Loss = 0.724075
Epoch 5.2: Loss = 0.654007
Epoch 5.3: Loss = 0.75325
Epoch 5.4: Loss = 0.6689
Epoch 5.5: Loss = 0.721924
Epoch 5.6: Loss = 0.723541
Epoch 5.7: Loss = 0.754181
Epoch 5.8: Loss = 0.714523
Epoch 5.9: Loss = 0.684937
Epoch 5.10: Loss = 0.779861
Epoch 5.11: Loss = 0.74118
Epoch 5.12: Loss = 0.741653
Epoch 5.13: Loss = 0.662735
Epoch 5.14: Loss = 0.735764
Epoch 5.15: Loss = 0.743973
Epoch 5.16: Loss = 0.65036
Epoch 5.17: Loss = 0.687988
Epoch 5.18: Loss = 0.669968
Epoch 5.19: Loss = 0.681824
Epoch 5.20: Loss = 0.658401
Epoch 5.21: Loss = 0.717865
Epoch 5.22: Loss = 0.68811
Epoch 5.23: Loss = 0.804886
Epoch 5.24: Loss = 0.747314
Epoch 5.25: Loss = 0.751404
Epoch 5.26: Loss = 0.730423
Epoch 5.27: Loss = 0.694397
Epoch 5.28: Loss = 0.706879
Epoch 5.29: Loss = 0.789169
Epoch 5.30: Loss = 0.727219
TRAIN LOSS = 0.717026
TRAIN ACC = 78.154 % (46895/60000)
Loss = 0.782242
Loss = 0.881805
Loss = 0.86348
Loss = 0.844238
Loss = 0.835373
TEST LOSS = 0.841427
TEST ACC = 468.95 % (7600/10000)
Reducing learning rate to 0.399994
Epoch 6.1: Loss = 0.795074
Epoch 6.2: Loss = 0.680939
Epoch 6.3: Loss = 0.796692
Epoch 6.4: Loss = 0.677353
Epoch 6.5: Loss = 0.771271
Epoch 6.6: Loss = 0.762955
Epoch 6.7: Loss = 0.794601
Epoch 6.8: Loss = 0.805206
Epoch 6.9: Loss = 0.767395
Epoch 6.10: Loss = 0.663422
Epoch 6.11: Loss = 0.620941
Epoch 6.12: Loss = 0.654587
Epoch 6.13: Loss = 0.698868
Epoch 6.14: Loss = 0.704102
Epoch 6.15: Loss = 0.628204
Epoch 6.16: Loss = 0.572784
Epoch 6.17: Loss = 0.640274
Epoch 6.18: Loss = 0.641571
Epoch 6.19: Loss = 0.619064
Epoch 6.20: Loss = 0.594742
Epoch 6.21: Loss = 0.688583
Epoch 6.22: Loss = 0.683411
Epoch 6.23: Loss = 0.749893
Epoch 6.24: Loss = 0.643036
Epoch 6.25: Loss = 0.673355
Epoch 6.26: Loss = 0.64386
Epoch 6.27: Loss = 0.778793
Epoch 6.28: Loss = 0.621429
Epoch 6.29: Loss = 0.700043
Epoch 6.30: Loss = 0.690674
TRAIN LOSS = 0.692123
TRAIN ACC = 79.1763 % (47508/60000)
Loss = 0.641083
Loss = 0.75856
Loss = 0.746689
Loss = 0.71196
Loss = 0.730057
TEST LOSS = 0.717669
TEST ACC = 475.079 % (7911/10000)
Reducing learning rate to 0.399994
Epoch 7.1: Loss = 0.660797
Epoch 7.2: Loss = 0.603058
Epoch 7.3: Loss = 0.741364
Epoch 7.4: Loss = 0.740677
Epoch 7.5: Loss = 0.626633
Epoch 7.6: Loss = 0.669205
Epoch 7.7: Loss = 0.679916
Epoch 7.8: Loss = 0.717819
Epoch 7.9: Loss = 0.64006
Epoch 7.10: Loss = 0.721329
Epoch 7.11: Loss = 0.632645
Epoch 7.12: Loss = 0.63385
Epoch 7.13: Loss = 0.771744
Epoch 7.14: Loss = 0.688782
Epoch 7.15: Loss = 0.729065
Epoch 7.16: Loss = 0.660675
Epoch 7.17: Loss = 0.645096
Epoch 7.18: Loss = 0.636719
Epoch 7.19: Loss = 0.807709
Epoch 7.20: Loss = 0.555756
Epoch 7.21: Loss = 0.694733
Epoch 7.22: Loss = 0.612656
Epoch 7.23: Loss = 0.666748
Epoch 7.24: Loss = 0.637527
Epoch 7.25: Loss = 0.916824
Epoch 7.26: Loss = 0.663681
Epoch 7.27: Loss = 0.71875
Epoch 7.28: Loss = 0.748962
Epoch 7.29: Loss = 0.848694
Epoch 7.30: Loss = 0.643494
TRAIN LOSS = 0.690506
TRAIN ACC = 79.7409 % (47846/60000)
Loss = 0.741776
Loss = 0.876099
Loss = 0.862061
Loss = 0.844025
Loss = 0.838867
TEST LOSS = 0.832565
TEST ACC = 478.459 % (7843/10000)
Reducing learning rate to 0.399994
Epoch 8.1: Loss = 0.819962
Epoch 8.2: Loss = 0.722061
Epoch 8.3: Loss = 0.758179
Epoch 8.4: Loss = 0.643372
Epoch 8.5: Loss = 0.633728
Epoch 8.6: Loss = 0.602448
Epoch 8.7: Loss = 0.644974
Epoch 8.8: Loss = 0.626938
Epoch 8.9: Loss = 0.641022
Epoch 8.10: Loss = 0.634232
Epoch 8.11: Loss = 0.617249
Epoch 8.12: Loss = 0.595215
Epoch 8.13: Loss = 0.615204
Epoch 8.14: Loss = 0.596603
Epoch 8.15: Loss = 0.660782
Epoch 8.16: Loss = 0.677643
Epoch 8.17: Loss = 0.650711
Epoch 8.18: Loss = 0.601929
Epoch 8.19: Loss = 0.663849
Epoch 8.20: Loss = 0.588745
Epoch 8.21: Loss = 0.733734
Epoch 8.22: Loss = 0.702591
Epoch 8.23: Loss = 0.745392
Epoch 8.24: Loss = 0.86348
Epoch 8.25: Loss = 0.772491
Epoch 8.26: Loss = 0.606369
Epoch 8.27: Loss = 0.725418
Epoch 8.28: Loss = 0.617523
Epoch 8.29: Loss = 0.738205
Epoch 8.30: Loss = 0.649429
TRAIN LOSS = 0.671661
TRAIN ACC = 80.5664 % (48342/60000)
Loss = 0.616135
Loss = 0.73024
Loss = 0.735489
Loss = 0.696121
Loss = 0.711594
TEST LOSS = 0.697915
TEST ACC = 483.42 % (8050/10000)
Reducing learning rate to 0.399994
Epoch 9.1: Loss = 0.68158
Epoch 9.2: Loss = 0.585464
Epoch 9.3: Loss = 0.67749
Epoch 9.4: Loss = 0.701309
Epoch 9.5: Loss = 0.7052
Epoch 9.6: Loss = 0.618607
Epoch 9.7: Loss = 0.695618
Epoch 9.8: Loss = 0.615387
Epoch 9.9: Loss = 0.622849
Epoch 9.10: Loss = 0.638596
Epoch 9.11: Loss = 0.750793
Epoch 9.12: Loss = 0.657684
Epoch 9.13: Loss = 0.680603
Epoch 9.14: Loss = 0.641495
Epoch 9.15: Loss = 0.80188
Epoch 9.16: Loss = 0.580643
Epoch 9.17: Loss = 0.805649
Epoch 9.18: Loss = 0.592697
Epoch 9.19: Loss = 0.696442
Epoch 9.20: Loss = 0.616455
Epoch 9.21: Loss = 0.734497
Epoch 9.22: Loss = 0.570084
Epoch 9.23: Loss = 0.679047
Epoch 9.24: Loss = 0.555344
Epoch 9.25: Loss = 0.584717
Epoch 9.26: Loss = 0.651382
Epoch 9.27: Loss = 0.682098
Epoch 9.28: Loss = 0.638321
Epoch 9.29: Loss = 0.629959
Epoch 9.30: Loss = 0.654831
TRAIN LOSS = 0.658249
TRAIN ACC = 81.0364 % (48624/60000)
Loss = 0.680557
Loss = 0.806671
Loss = 0.822052
Loss = 0.764954
Loss = 0.781998
TEST LOSS = 0.771246
TEST ACC = 486.24 % (7948/10000)
Reducing learning rate to 0.399994
Epoch 10.1: Loss = 0.688232
Epoch 10.2: Loss = 0.720978
Epoch 10.3: Loss = 0.632904
Epoch 10.4: Loss = 0.680695
Epoch 10.5: Loss = 0.703018
Epoch 10.6: Loss = 0.659409
Epoch 10.7: Loss = 0.64389
Epoch 10.8: Loss = 0.771851
Epoch 10.9: Loss = 0.655746
Epoch 10.10: Loss = 0.652832
Epoch 10.11: Loss = 0.720093
Epoch 10.12: Loss = 0.692566
Epoch 10.13: Loss = 0.690643
Epoch 10.14: Loss = 0.655273
Epoch 10.15: Loss = 0.758682
Epoch 10.16: Loss = 0.735168
Epoch 10.17: Loss = 0.660599
Epoch 10.18: Loss = 0.710968
Epoch 10.19: Loss = 0.651871
Epoch 10.20: Loss = 0.719971
Epoch 10.21: Loss = 0.700409
Epoch 10.22: Loss = 0.69429
Epoch 10.23: Loss = 0.694382
Epoch 10.24: Loss = 0.664932
Epoch 10.25: Loss = 0.677612
Epoch 10.26: Loss = 0.727493
Epoch 10.27: Loss = 0.658752
Epoch 10.28: Loss = 0.743164
Epoch 10.29: Loss = 0.766312
Epoch 10.30: Loss = 0.647079
TRAIN LOSS = 0.692673
TRAIN ACC = 80.5984 % (48361/60000)
Loss = 0.633728
Loss = 0.748367
Loss = 0.760437
Loss = 0.721146
Loss = 0.73761
TEST LOSS = 0.720257
TEST ACC = 483.609 % (8085/10000)
