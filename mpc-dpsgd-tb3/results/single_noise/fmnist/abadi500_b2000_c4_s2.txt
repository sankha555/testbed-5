Setting up connection 0
***********************************************************
Training MNIST
Model: Dense([60000, 1, 500]) => Dense([60000, 1, 10]) => MultiOutput([60000, 10]) => 
Train Examples: 60000
Batch Size: 2000
Num Epochs: 10
Learning Rate: 0.4 to 0.4 over 10 epochs
Clipping Factor: 4
Sigma: 2
***********************************************************
Epoch 1.1: Loss = 2.43594
Epoch 1.2: Loss = 2.04129
Epoch 1.3: Loss = 1.78796
Epoch 1.4: Loss = 1.59395
Epoch 1.5: Loss = 1.43867
Epoch 1.6: Loss = 1.32469
Epoch 1.7: Loss = 1.23668
Epoch 1.8: Loss = 1.18971
Epoch 1.9: Loss = 1.10048
Epoch 1.10: Loss = 1.04822
Epoch 1.11: Loss = 0.970505
Epoch 1.12: Loss = 0.984741
Epoch 1.13: Loss = 0.930923
Epoch 1.14: Loss = 0.928085
Epoch 1.15: Loss = 0.877869
Epoch 1.16: Loss = 0.893051
Epoch 1.17: Loss = 0.874176
Epoch 1.18: Loss = 0.858444
Epoch 1.19: Loss = 0.821075
Epoch 1.20: Loss = 0.831421
Epoch 1.21: Loss = 0.804886
Epoch 1.22: Loss = 0.833725
Epoch 1.23: Loss = 0.743637
Epoch 1.24: Loss = 0.798752
Epoch 1.25: Loss = 0.790131
Epoch 1.26: Loss = 0.775223
Epoch 1.27: Loss = 0.789734
Epoch 1.28: Loss = 0.717529
Epoch 1.29: Loss = 0.712372
Epoch 1.30: Loss = 0.737213
TRAIN LOSS = 1.06238
TRAIN ACC = 64.5523 % (38733/60000)
Loss = 0.741714
Loss = 0.802872
Loss = 0.752853
Loss = 0.773361
Loss = 0.756012
TEST LOSS = 0.765362
TEST ACC = 387.329 % (7249/10000)
Reducing learning rate to 0.399994
Epoch 2.1: Loss = 0.743378
Epoch 2.2: Loss = 0.732239
Epoch 2.3: Loss = 0.714294
Epoch 2.4: Loss = 0.71344
Epoch 2.5: Loss = 0.723038
Epoch 2.6: Loss = 0.704086
Epoch 2.7: Loss = 0.720627
Epoch 2.8: Loss = 0.714417
Epoch 2.9: Loss = 0.757263
Epoch 2.10: Loss = 0.696762
Epoch 2.11: Loss = 0.678513
Epoch 2.12: Loss = 0.692032
Epoch 2.13: Loss = 0.702011
Epoch 2.14: Loss = 0.681091
Epoch 2.15: Loss = 0.703629
Epoch 2.16: Loss = 0.693771
Epoch 2.17: Loss = 0.73642
Epoch 2.18: Loss = 0.671036
Epoch 2.19: Loss = 0.67511
Epoch 2.20: Loss = 0.665833
Epoch 2.21: Loss = 0.643066
Epoch 2.22: Loss = 0.69754
Epoch 2.23: Loss = 0.634201
Epoch 2.24: Loss = 0.719391
Epoch 2.25: Loss = 0.628754
Epoch 2.26: Loss = 0.688141
Epoch 2.27: Loss = 0.622345
Epoch 2.28: Loss = 0.669617
Epoch 2.29: Loss = 0.648529
Epoch 2.30: Loss = 0.68782
TRAIN LOSS = 0.691956
TRAIN ACC = 76.2497 % (45752/60000)
Loss = 0.644714
Loss = 0.718002
Loss = 0.676224
Loss = 0.681091
Loss = 0.66983
TEST LOSS = 0.677972
TEST ACC = 457.52 % (7651/10000)
Reducing learning rate to 0.399994
Epoch 3.1: Loss = 0.647049
Epoch 3.2: Loss = 0.64534
Epoch 3.3: Loss = 0.666794
Epoch 3.4: Loss = 0.620132
Epoch 3.5: Loss = 0.656662
Epoch 3.6: Loss = 0.629196
Epoch 3.7: Loss = 0.682678
Epoch 3.8: Loss = 0.670914
Epoch 3.9: Loss = 0.625565
Epoch 3.10: Loss = 0.663803
Epoch 3.11: Loss = 0.638779
Epoch 3.12: Loss = 0.628036
Epoch 3.13: Loss = 0.628448
Epoch 3.14: Loss = 0.614319
Epoch 3.15: Loss = 0.635086
Epoch 3.16: Loss = 0.652634
Epoch 3.17: Loss = 0.647156
Epoch 3.18: Loss = 0.625412
Epoch 3.19: Loss = 0.642624
Epoch 3.20: Loss = 0.580017
Epoch 3.21: Loss = 0.672089
Epoch 3.22: Loss = 0.622925
Epoch 3.23: Loss = 0.668915
Epoch 3.24: Loss = 0.642197
Epoch 3.25: Loss = 0.685501
Epoch 3.26: Loss = 0.615829
Epoch 3.27: Loss = 0.630249
Epoch 3.28: Loss = 0.615204
Epoch 3.29: Loss = 0.624741
Epoch 3.30: Loss = 0.655396
TRAIN LOSS = 0.641129
TRAIN ACC = 78.6377 % (47185/60000)
Loss = 0.602814
Loss = 0.68103
Loss = 0.652344
Loss = 0.641861
Loss = 0.63327
TEST LOSS = 0.642264
TEST ACC = 471.849 % (7818/10000)
Reducing learning rate to 0.399994
Epoch 4.1: Loss = 0.614029
Epoch 4.2: Loss = 0.597763
Epoch 4.3: Loss = 0.650681
Epoch 4.4: Loss = 0.66391
Epoch 4.5: Loss = 0.606598
Epoch 4.6: Loss = 0.645462
Epoch 4.7: Loss = 0.616302
Epoch 4.8: Loss = 0.612701
Epoch 4.9: Loss = 0.627853
Epoch 4.10: Loss = 0.637955
Epoch 4.11: Loss = 0.603653
Epoch 4.12: Loss = 0.643173
Epoch 4.13: Loss = 0.634857
Epoch 4.14: Loss = 0.629639
Epoch 4.15: Loss = 0.615799
Epoch 4.16: Loss = 0.579544
Epoch 4.17: Loss = 0.646851
Epoch 4.18: Loss = 0.660629
Epoch 4.19: Loss = 0.631958
Epoch 4.20: Loss = 0.625397
Epoch 4.21: Loss = 0.557434
Epoch 4.22: Loss = 0.646545
Epoch 4.23: Loss = 0.571716
Epoch 4.24: Loss = 0.612732
Epoch 4.25: Loss = 0.552719
Epoch 4.26: Loss = 0.673401
Epoch 4.27: Loss = 0.676315
Epoch 4.28: Loss = 0.661911
Epoch 4.29: Loss = 0.558823
Epoch 4.30: Loss = 0.673386
TRAIN LOSS = 0.624344
TRAIN ACC = 79.5746 % (47747/60000)
Loss = 0.59108
Loss = 0.676239
Loss = 0.644089
Loss = 0.630539
Loss = 0.623444
TEST LOSS = 0.633078
TEST ACC = 477.469 % (7864/10000)
Reducing learning rate to 0.399994
Epoch 5.1: Loss = 0.593979
Epoch 5.2: Loss = 0.640884
Epoch 5.3: Loss = 0.640701
Epoch 5.4: Loss = 0.572021
Epoch 5.5: Loss = 0.614883
Epoch 5.6: Loss = 0.574081
Epoch 5.7: Loss = 0.59613
Epoch 5.8: Loss = 0.576828
Epoch 5.9: Loss = 0.617737
Epoch 5.10: Loss = 0.538193
Epoch 5.11: Loss = 0.607452
Epoch 5.12: Loss = 0.625931
Epoch 5.13: Loss = 0.697205
Epoch 5.14: Loss = 0.629776
Epoch 5.15: Loss = 0.655121
Epoch 5.16: Loss = 0.563812
Epoch 5.17: Loss = 0.579178
Epoch 5.18: Loss = 0.633499
Epoch 5.19: Loss = 0.647202
Epoch 5.20: Loss = 0.603577
Epoch 5.21: Loss = 0.596878
Epoch 5.22: Loss = 0.609818
Epoch 5.23: Loss = 0.618317
Epoch 5.24: Loss = 0.596527
Epoch 5.25: Loss = 0.615891
Epoch 5.26: Loss = 0.605087
Epoch 5.27: Loss = 0.612
Epoch 5.28: Loss = 0.600632
Epoch 5.29: Loss = 0.625351
Epoch 5.30: Loss = 0.619827
TRAIN LOSS = 0.610306
TRAIN ACC = 80.3146 % (48191/60000)
Loss = 0.576324
Loss = 0.675323
Loss = 0.652496
Loss = 0.636414
Loss = 0.631454
TEST LOSS = 0.634402
TEST ACC = 481.909 % (7970/10000)
Reducing learning rate to 0.399994
Epoch 6.1: Loss = 0.603073
Epoch 6.2: Loss = 0.58609
Epoch 6.3: Loss = 0.630661
Epoch 6.4: Loss = 0.578186
Epoch 6.5: Loss = 0.632553
Epoch 6.6: Loss = 0.606674
Epoch 6.7: Loss = 0.601501
Epoch 6.8: Loss = 0.579361
Epoch 6.9: Loss = 0.598846
Epoch 6.10: Loss = 0.612885
Epoch 6.11: Loss = 0.576614
Epoch 6.12: Loss = 0.619202
Epoch 6.13: Loss = 0.563354
Epoch 6.14: Loss = 0.586517
Epoch 6.15: Loss = 0.566193
Epoch 6.16: Loss = 0.591171
Epoch 6.17: Loss = 0.58577
Epoch 6.18: Loss = 0.631912
Epoch 6.19: Loss = 0.621811
Epoch 6.20: Loss = 0.580048
Epoch 6.21: Loss = 0.653992
Epoch 6.22: Loss = 0.559692
Epoch 6.23: Loss = 0.650818
Epoch 6.24: Loss = 0.591095
Epoch 6.25: Loss = 0.596085
Epoch 6.26: Loss = 0.615845
Epoch 6.27: Loss = 0.614822
Epoch 6.28: Loss = 0.716492
Epoch 6.29: Loss = 0.595215
Epoch 6.30: Loss = 0.592834
TRAIN LOSS = 0.60466
TRAIN ACC = 80.8746 % (48527/60000)
Loss = 0.570587
Loss = 0.663376
Loss = 0.653687
Loss = 0.628326
Loss = 0.620071
TEST LOSS = 0.627209
TEST ACC = 485.269 % (8021/10000)
Reducing learning rate to 0.399994
Epoch 7.1: Loss = 0.59111
Epoch 7.2: Loss = 0.570404
Epoch 7.3: Loss = 0.588516
Epoch 7.4: Loss = 0.615891
Epoch 7.5: Loss = 0.543472
Epoch 7.6: Loss = 0.634491
Epoch 7.7: Loss = 0.65242
Epoch 7.8: Loss = 0.587494
Epoch 7.9: Loss = 0.570663
Epoch 7.10: Loss = 0.613251
Epoch 7.11: Loss = 0.511765
Epoch 7.12: Loss = 0.568008
Epoch 7.13: Loss = 0.538574
Epoch 7.14: Loss = 0.636185
Epoch 7.15: Loss = 0.597198
Epoch 7.16: Loss = 0.575989
Epoch 7.17: Loss = 0.601288
Epoch 7.18: Loss = 0.590805
Epoch 7.19: Loss = 0.603043
Epoch 7.20: Loss = 0.593903
Epoch 7.21: Loss = 0.606796
Epoch 7.22: Loss = 0.595123
Epoch 7.23: Loss = 0.618515
Epoch 7.24: Loss = 0.646835
Epoch 7.25: Loss = 0.643967
Epoch 7.26: Loss = 0.581528
Epoch 7.27: Loss = 0.565781
Epoch 7.28: Loss = 0.588882
Epoch 7.29: Loss = 0.572601
Epoch 7.30: Loss = 0.570206
TRAIN LOSS = 0.592499
TRAIN ACC = 81.2897 % (48776/60000)
Loss = 0.558777
Loss = 0.648407
Loss = 0.637909
Loss = 0.608292
Loss = 0.599426
TEST LOSS = 0.610562
TEST ACC = 487.759 % (8042/10000)
Reducing learning rate to 0.399994
Epoch 8.1: Loss = 0.595016
Epoch 8.2: Loss = 0.583603
Epoch 8.3: Loss = 0.536301
Epoch 8.4: Loss = 0.601929
Epoch 8.5: Loss = 0.589981
Epoch 8.6: Loss = 0.598572
Epoch 8.7: Loss = 0.572205
Epoch 8.8: Loss = 0.599182
Epoch 8.9: Loss = 0.553436
Epoch 8.10: Loss = 0.599701
Epoch 8.11: Loss = 0.536377
Epoch 8.12: Loss = 0.628662
Epoch 8.13: Loss = 0.592972
Epoch 8.14: Loss = 0.581512
Epoch 8.15: Loss = 0.594696
Epoch 8.16: Loss = 0.57576
Epoch 8.17: Loss = 0.641785
Epoch 8.18: Loss = 0.534714
Epoch 8.19: Loss = 0.569138
Epoch 8.20: Loss = 0.59993
Epoch 8.21: Loss = 0.541916
Epoch 8.22: Loss = 0.540894
Epoch 8.23: Loss = 0.621872
Epoch 8.24: Loss = 0.594971
Epoch 8.25: Loss = 0.55632
Epoch 8.26: Loss = 0.579758
Epoch 8.27: Loss = 0.589386
Epoch 8.28: Loss = 0.610046
Epoch 8.29: Loss = 0.629364
Epoch 8.30: Loss = 0.652771
TRAIN LOSS = 0.586761
TRAIN ACC = 81.6483 % (48992/60000)
Loss = 0.55043
Loss = 0.645386
Loss = 0.63179
Loss = 0.604782
Loss = 0.595413
TEST LOSS = 0.60556
TEST ACC = 489.919 % (8075/10000)
Reducing learning rate to 0.399994
Epoch 9.1: Loss = 0.551498
Epoch 9.2: Loss = 0.579269
Epoch 9.3: Loss = 0.571014
Epoch 9.4: Loss = 0.620026
Epoch 9.5: Loss = 0.543533
Epoch 9.6: Loss = 0.557877
Epoch 9.7: Loss = 0.589432
Epoch 9.8: Loss = 0.609619
Epoch 9.9: Loss = 0.555069
Epoch 9.10: Loss = 0.597412
Epoch 9.11: Loss = 0.580521
Epoch 9.12: Loss = 0.656204
Epoch 9.13: Loss = 0.543564
Epoch 9.14: Loss = 0.540054
Epoch 9.15: Loss = 0.539703
Epoch 9.16: Loss = 0.647675
Epoch 9.17: Loss = 0.533707
Epoch 9.18: Loss = 0.585342
Epoch 9.19: Loss = 0.556
Epoch 9.20: Loss = 0.54393
Epoch 9.21: Loss = 0.656357
Epoch 9.22: Loss = 0.557693
Epoch 9.23: Loss = 0.619064
Epoch 9.24: Loss = 0.51886
Epoch 9.25: Loss = 0.591721
Epoch 9.26: Loss = 0.609848
Epoch 9.27: Loss = 0.628113
Epoch 9.28: Loss = 0.585464
Epoch 9.29: Loss = 0.577072
Epoch 9.30: Loss = 0.595749
TRAIN LOSS = 0.58139
TRAIN ACC = 81.9412 % (49167/60000)
Loss = 0.551819
Loss = 0.644928
Loss = 0.63208
Loss = 0.606262
Loss = 0.597061
TEST LOSS = 0.60643
TEST ACC = 491.669 % (8129/10000)
Reducing learning rate to 0.399994
Epoch 10.1: Loss = 0.639481
Epoch 10.2: Loss = 0.557281
Epoch 10.3: Loss = 0.54454
Epoch 10.4: Loss = 0.656815
Epoch 10.5: Loss = 0.525055
Epoch 10.6: Loss = 0.578293
Epoch 10.7: Loss = 0.581085
Epoch 10.8: Loss = 0.579254
Epoch 10.9: Loss = 0.573135
Epoch 10.10: Loss = 0.557236
Epoch 10.11: Loss = 0.596252
Epoch 10.12: Loss = 0.603333
Epoch 10.13: Loss = 0.551819
Epoch 10.14: Loss = 0.612656
Epoch 10.15: Loss = 0.577408
Epoch 10.16: Loss = 0.515991
Epoch 10.17: Loss = 0.622604
Epoch 10.18: Loss = 0.576645
Epoch 10.19: Loss = 0.608582
Epoch 10.20: Loss = 0.592484
Epoch 10.21: Loss = 0.547241
Epoch 10.22: Loss = 0.54071
Epoch 10.23: Loss = 0.59436
Epoch 10.24: Loss = 0.56395
Epoch 10.25: Loss = 0.528793
Epoch 10.26: Loss = 0.612228
Epoch 10.27: Loss = 0.598175
Epoch 10.28: Loss = 0.552063
Epoch 10.29: Loss = 0.566864
Epoch 10.30: Loss = 0.576569
TRAIN LOSS = 0.577713
TRAIN ACC = 82.3822 % (49431/60000)
Loss = 0.548676
Loss = 0.649017
Loss = 0.628433
Loss = 0.608047
Loss = 0.599045
TEST LOSS = 0.606644
TEST ACC = 494.308 % (8130/10000)
