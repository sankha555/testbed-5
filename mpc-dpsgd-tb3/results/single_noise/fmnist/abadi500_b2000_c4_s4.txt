Setting up connection 0
***********************************************************
Training MNIST
Model: Dense([60000, 1, 500]) => Dense([60000, 1, 10]) => MultiOutput([60000, 10]) => 
Train Examples: 60000
Batch Size: 2000
Num Epochs: 10
Learning Rate: 0.4 to 0.4 over 10 epochs
Clipping Factor: 4
Sigma: 4
***********************************************************
Epoch 1.1: Loss = 2.43581
Epoch 1.2: Loss = 2.05859
Epoch 1.3: Loss = 1.81725
Epoch 1.4: Loss = 1.63185
Epoch 1.5: Loss = 1.47197
Epoch 1.6: Loss = 1.35678
Epoch 1.7: Loss = 1.2485
Epoch 1.8: Loss = 1.23131
Epoch 1.9: Loss = 1.13411
Epoch 1.10: Loss = 1.10707
Epoch 1.11: Loss = 1.04507
Epoch 1.12: Loss = 1.01294
Epoch 1.13: Loss = 0.954056
Epoch 1.14: Loss = 0.975677
Epoch 1.15: Loss = 0.936203
Epoch 1.16: Loss = 0.918762
Epoch 1.17: Loss = 0.866852
Epoch 1.18: Loss = 0.907394
Epoch 1.19: Loss = 0.868423
Epoch 1.20: Loss = 0.806396
Epoch 1.21: Loss = 0.851227
Epoch 1.22: Loss = 0.798309
Epoch 1.23: Loss = 0.835846
Epoch 1.24: Loss = 0.820313
Epoch 1.25: Loss = 0.818085
Epoch 1.26: Loss = 0.850739
Epoch 1.27: Loss = 0.843597
Epoch 1.28: Loss = 0.796188
Epoch 1.29: Loss = 0.739609
Epoch 1.30: Loss = 0.705444
TRAIN LOSS = 1.09483
TRAIN ACC = 62.6404 % (37586/60000)
Loss = 0.753357
Loss = 0.82225
Loss = 0.766312
Loss = 0.779251
Loss = 0.762421
TEST LOSS = 0.776718
TEST ACC = 375.859 % (7195/10000)
Reducing learning rate to 0.399994
Epoch 2.1: Loss = 0.795166
Epoch 2.2: Loss = 0.757645
Epoch 2.3: Loss = 0.712036
Epoch 2.4: Loss = 0.765045
Epoch 2.5: Loss = 0.76828
Epoch 2.6: Loss = 0.697861
Epoch 2.7: Loss = 0.75592
Epoch 2.8: Loss = 0.720016
Epoch 2.9: Loss = 0.673615
Epoch 2.10: Loss = 0.639343
Epoch 2.11: Loss = 0.726624
Epoch 2.12: Loss = 0.679031
Epoch 2.13: Loss = 0.756027
Epoch 2.14: Loss = 0.651398
Epoch 2.15: Loss = 0.792084
Epoch 2.16: Loss = 0.667267
Epoch 2.17: Loss = 0.77272
Epoch 2.18: Loss = 0.733414
Epoch 2.19: Loss = 0.716888
Epoch 2.20: Loss = 0.750305
Epoch 2.21: Loss = 0.679611
Epoch 2.22: Loss = 0.676117
Epoch 2.23: Loss = 0.722839
Epoch 2.24: Loss = 0.686508
Epoch 2.25: Loss = 0.69281
Epoch 2.26: Loss = 0.735718
Epoch 2.27: Loss = 0.667099
Epoch 2.28: Loss = 0.705429
Epoch 2.29: Loss = 0.668365
Epoch 2.30: Loss = 0.662842
TRAIN LOSS = 0.714279
TRAIN ACC = 75.8148 % (45491/60000)
Loss = 0.660645
Loss = 0.754044
Loss = 0.69841
Loss = 0.702957
Loss = 0.697876
TEST LOSS = 0.702786
TEST ACC = 454.909 % (7643/10000)
Reducing learning rate to 0.399994
Epoch 3.1: Loss = 0.683731
Epoch 3.2: Loss = 0.654297
Epoch 3.3: Loss = 0.631638
Epoch 3.4: Loss = 0.667999
Epoch 3.5: Loss = 0.700912
Epoch 3.6: Loss = 0.638199
Epoch 3.7: Loss = 0.660309
Epoch 3.8: Loss = 0.625534
Epoch 3.9: Loss = 0.673309
Epoch 3.10: Loss = 0.607529
Epoch 3.11: Loss = 0.755341
Epoch 3.12: Loss = 0.661835
Epoch 3.13: Loss = 0.724808
Epoch 3.14: Loss = 0.616714
Epoch 3.15: Loss = 0.705231
Epoch 3.16: Loss = 0.677948
Epoch 3.17: Loss = 0.729813
Epoch 3.18: Loss = 0.647797
Epoch 3.19: Loss = 0.656311
Epoch 3.20: Loss = 0.679443
Epoch 3.21: Loss = 0.634567
Epoch 3.22: Loss = 0.683578
Epoch 3.23: Loss = 0.639114
Epoch 3.24: Loss = 0.605606
Epoch 3.25: Loss = 0.691635
Epoch 3.26: Loss = 0.648361
Epoch 3.27: Loss = 0.676453
Epoch 3.28: Loss = 0.624802
Epoch 3.29: Loss = 0.662445
Epoch 3.30: Loss = 0.622406
TRAIN LOSS = 0.662949
TRAIN ACC = 78.212 % (46930/60000)
Loss = 0.633759
Loss = 0.737381
Loss = 0.691818
Loss = 0.678741
Loss = 0.677139
TEST LOSS = 0.683768
TEST ACC = 469.299 % (7786/10000)
Reducing learning rate to 0.399994
Epoch 4.1: Loss = 0.683426
Epoch 4.2: Loss = 0.586029
Epoch 4.3: Loss = 0.667999
Epoch 4.4: Loss = 0.619675
Epoch 4.5: Loss = 0.646805
Epoch 4.6: Loss = 0.673706
Epoch 4.7: Loss = 0.604874
Epoch 4.8: Loss = 0.624207
Epoch 4.9: Loss = 0.606979
Epoch 4.10: Loss = 0.695404
Epoch 4.11: Loss = 0.649567
Epoch 4.12: Loss = 0.696274
Epoch 4.13: Loss = 0.649673
Epoch 4.14: Loss = 0.699524
Epoch 4.15: Loss = 0.656387
Epoch 4.16: Loss = 0.703506
Epoch 4.17: Loss = 0.616302
Epoch 4.18: Loss = 0.700485
Epoch 4.19: Loss = 0.567169
Epoch 4.20: Loss = 0.674316
Epoch 4.21: Loss = 0.611588
Epoch 4.22: Loss = 0.62146
Epoch 4.23: Loss = 0.621826
Epoch 4.24: Loss = 0.662476
Epoch 4.25: Loss = 0.665024
Epoch 4.26: Loss = 0.605225
Epoch 4.27: Loss = 0.608307
Epoch 4.28: Loss = 0.599899
Epoch 4.29: Loss = 0.632385
Epoch 4.30: Loss = 0.664932
TRAIN LOSS = 0.64386
TRAIN ACC = 79.3243 % (47596/60000)
Loss = 0.57901
Loss = 0.679581
Loss = 0.643219
Loss = 0.621506
Loss = 0.618652
TEST LOSS = 0.628393
TEST ACC = 475.96 % (7930/10000)
Reducing learning rate to 0.399994
Epoch 5.1: Loss = 0.622314
Epoch 5.2: Loss = 0.622574
Epoch 5.3: Loss = 0.640106
Epoch 5.4: Loss = 0.618668
Epoch 5.5: Loss = 0.569519
Epoch 5.6: Loss = 0.622253
Epoch 5.7: Loss = 0.622208
Epoch 5.8: Loss = 0.621933
Epoch 5.9: Loss = 0.619827
Epoch 5.10: Loss = 0.594528
Epoch 5.11: Loss = 0.600555
Epoch 5.12: Loss = 0.617432
Epoch 5.13: Loss = 0.585785
Epoch 5.14: Loss = 0.634872
Epoch 5.15: Loss = 0.635788
Epoch 5.16: Loss = 0.57312
Epoch 5.17: Loss = 0.669098
Epoch 5.18: Loss = 0.57605
Epoch 5.19: Loss = 0.636047
Epoch 5.20: Loss = 0.560745
Epoch 5.21: Loss = 0.59407
Epoch 5.22: Loss = 0.644806
Epoch 5.23: Loss = 0.633484
Epoch 5.24: Loss = 0.574814
Epoch 5.25: Loss = 0.65448
Epoch 5.26: Loss = 0.622375
Epoch 5.27: Loss = 0.635803
Epoch 5.28: Loss = 0.602295
Epoch 5.29: Loss = 0.619995
Epoch 5.30: Loss = 0.633026
TRAIN LOSS = 0.615311
TRAIN ACC = 80.4062 % (48246/60000)
Loss = 0.572678
Loss = 0.686859
Loss = 0.645065
Loss = 0.623215
Loss = 0.622025
TEST LOSS = 0.629968
TEST ACC = 482.458 % (7984/10000)
Reducing learning rate to 0.399994
Epoch 6.1: Loss = 0.59491
Epoch 6.2: Loss = 0.624161
Epoch 6.3: Loss = 0.58374
Epoch 6.4: Loss = 0.621445
Epoch 6.5: Loss = 0.699249
Epoch 6.6: Loss = 0.627121
Epoch 6.7: Loss = 0.652649
Epoch 6.8: Loss = 0.730316
Epoch 6.9: Loss = 0.64653
Epoch 6.10: Loss = 0.626312
Epoch 6.11: Loss = 0.547287
Epoch 6.12: Loss = 0.637878
Epoch 6.13: Loss = 0.690598
Epoch 6.14: Loss = 0.575058
Epoch 6.15: Loss = 0.698685
Epoch 6.16: Loss = 0.571991
Epoch 6.17: Loss = 0.645584
Epoch 6.18: Loss = 0.595261
Epoch 6.19: Loss = 0.582214
Epoch 6.20: Loss = 0.57756
Epoch 6.21: Loss = 0.631775
Epoch 6.22: Loss = 0.610748
Epoch 6.23: Loss = 0.560669
Epoch 6.24: Loss = 0.565811
Epoch 6.25: Loss = 0.626785
Epoch 6.26: Loss = 0.594589
Epoch 6.27: Loss = 0.631897
Epoch 6.28: Loss = 0.63678
Epoch 6.29: Loss = 0.609863
Epoch 6.30: Loss = 0.642548
TRAIN LOSS = 0.621353
TRAIN ACC = 80.5328 % (48322/60000)
Loss = 0.593918
Loss = 0.706833
Loss = 0.673828
Loss = 0.653702
Loss = 0.652115
TEST LOSS = 0.656079
TEST ACC = 483.22 % (8019/10000)
Reducing learning rate to 0.399994
Epoch 7.1: Loss = 0.698929
Epoch 7.2: Loss = 0.585739
Epoch 7.3: Loss = 0.625702
Epoch 7.4: Loss = 0.593979
Epoch 7.5: Loss = 0.581268
Epoch 7.6: Loss = 0.647888
Epoch 7.7: Loss = 0.61557
Epoch 7.8: Loss = 0.619263
Epoch 7.9: Loss = 0.604248
Epoch 7.10: Loss = 0.593887
Epoch 7.11: Loss = 0.621552
Epoch 7.12: Loss = 0.619278
Epoch 7.13: Loss = 0.614578
Epoch 7.14: Loss = 0.633102
Epoch 7.15: Loss = 0.544861
Epoch 7.16: Loss = 0.610214
Epoch 7.17: Loss = 0.566238
Epoch 7.18: Loss = 0.657898
Epoch 7.19: Loss = 0.611176
Epoch 7.20: Loss = 0.573624
Epoch 7.21: Loss = 0.60257
Epoch 7.22: Loss = 0.598114
Epoch 7.23: Loss = 0.533463
Epoch 7.24: Loss = 0.658752
Epoch 7.25: Loss = 0.585892
Epoch 7.26: Loss = 0.563141
Epoch 7.27: Loss = 0.574158
Epoch 7.28: Loss = 0.59761
Epoch 7.29: Loss = 0.621445
Epoch 7.30: Loss = 0.651077
TRAIN LOSS = 0.606857
TRAIN ACC = 81.2439 % (48748/60000)
Loss = 0.576111
Loss = 0.674667
Loss = 0.644363
Loss = 0.617355
Loss = 0.610596
TEST LOSS = 0.624618
TEST ACC = 487.479 % (8056/10000)
Reducing learning rate to 0.399994
Epoch 8.1: Loss = 0.593918
Epoch 8.2: Loss = 0.696396
Epoch 8.3: Loss = 0.591599
Epoch 8.4: Loss = 0.664276
Epoch 8.5: Loss = 0.61734
Epoch 8.6: Loss = 0.605316
Epoch 8.7: Loss = 0.607101
Epoch 8.8: Loss = 0.628403
Epoch 8.9: Loss = 0.614716
Epoch 8.10: Loss = 0.546844
Epoch 8.11: Loss = 0.587402
Epoch 8.12: Loss = 0.565933
Epoch 8.13: Loss = 0.667343
Epoch 8.14: Loss = 0.608856
Epoch 8.15: Loss = 0.574692
Epoch 8.16: Loss = 0.673203
Epoch 8.17: Loss = 0.65062
Epoch 8.18: Loss = 0.540405
Epoch 8.19: Loss = 0.573181
Epoch 8.20: Loss = 0.552216
Epoch 8.21: Loss = 0.583252
Epoch 8.22: Loss = 0.606079
Epoch 8.23: Loss = 0.592743
Epoch 8.24: Loss = 0.542404
Epoch 8.25: Loss = 0.533508
Epoch 8.26: Loss = 0.624222
Epoch 8.27: Loss = 0.593979
Epoch 8.28: Loss = 0.61264
Epoch 8.29: Loss = 0.570953
Epoch 8.30: Loss = 0.631287
TRAIN LOSS = 0.601715
TRAIN ACC = 81.5292 % (48920/60000)
Loss = 0.589981
Loss = 0.690155
Loss = 0.665115
Loss = 0.636353
Loss = 0.62619
TEST LOSS = 0.641559
TEST ACC = 489.2 % (8075/10000)
Reducing learning rate to 0.399994
Epoch 9.1: Loss = 0.560135
Epoch 9.2: Loss = 0.637268
Epoch 9.3: Loss = 0.61145
Epoch 9.4: Loss = 0.681778
Epoch 9.5: Loss = 0.561462
Epoch 9.6: Loss = 0.660645
Epoch 9.7: Loss = 0.627106
Epoch 9.8: Loss = 0.621887
Epoch 9.9: Loss = 0.606979
Epoch 9.10: Loss = 0.59465
Epoch 9.11: Loss = 0.589951
Epoch 9.12: Loss = 0.60788
Epoch 9.13: Loss = 0.657089
Epoch 9.14: Loss = 0.641296
Epoch 9.15: Loss = 0.593689
Epoch 9.16: Loss = 0.54747
Epoch 9.17: Loss = 0.641464
Epoch 9.18: Loss = 0.565704
Epoch 9.19: Loss = 0.65889
Epoch 9.20: Loss = 0.585114
Epoch 9.21: Loss = 0.632965
Epoch 9.22: Loss = 0.559326
Epoch 9.23: Loss = 0.55246
Epoch 9.24: Loss = 0.585617
Epoch 9.25: Loss = 0.617859
Epoch 9.26: Loss = 0.631058
Epoch 9.27: Loss = 0.631104
Epoch 9.28: Loss = 0.654587
Epoch 9.29: Loss = 0.528732
Epoch 9.30: Loss = 0.614624
TRAIN LOSS = 0.608688
TRAIN ACC = 81.6223 % (48976/60000)
Loss = 0.600296
Loss = 0.707169
Loss = 0.695389
Loss = 0.645203
Loss = 0.650925
TEST LOSS = 0.659796
TEST ACC = 489.76 % (8036/10000)
Reducing learning rate to 0.399994
Epoch 10.1: Loss = 0.590042
Epoch 10.2: Loss = 0.594131
Epoch 10.3: Loss = 0.650009
Epoch 10.4: Loss = 0.581848
Epoch 10.5: Loss = 0.670547
Epoch 10.6: Loss = 0.588318
Epoch 10.7: Loss = 0.643448
Epoch 10.8: Loss = 0.55101
Epoch 10.9: Loss = 0.605133
Epoch 10.10: Loss = 0.56871
Epoch 10.11: Loss = 0.6138
Epoch 10.12: Loss = 0.593765
Epoch 10.13: Loss = 0.593674
Epoch 10.14: Loss = 0.571304
Epoch 10.15: Loss = 0.574615
Epoch 10.16: Loss = 0.547241
Epoch 10.17: Loss = 0.53006
Epoch 10.18: Loss = 0.571823
Epoch 10.19: Loss = 0.531174
Epoch 10.20: Loss = 0.631775
Epoch 10.21: Loss = 0.590134
Epoch 10.22: Loss = 0.648666
Epoch 10.23: Loss = 0.602753
Epoch 10.24: Loss = 0.568176
Epoch 10.25: Loss = 0.589844
Epoch 10.26: Loss = 0.51622
Epoch 10.27: Loss = 0.649826
Epoch 10.28: Loss = 0.537643
Epoch 10.29: Loss = 0.613037
Epoch 10.30: Loss = 0.637405
TRAIN LOSS = 0.591873
TRAIN ACC = 82.0694 % (49244/60000)
Loss = 0.557632
Loss = 0.671799
Loss = 0.640747
Loss = 0.598419
Loss = 0.600494
TEST LOSS = 0.613818
TEST ACC = 492.439 % (8170/10000)
