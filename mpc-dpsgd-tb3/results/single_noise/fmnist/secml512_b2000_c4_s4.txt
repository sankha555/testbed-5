Setting up connection 0
***********************************************************
Training FMNIST
Model: Dense([60000, 1, 512]) => Dense([60000, 1, 512]) => Dense([60000, 1, 10]) => MultiOutput([60000, 10]) => 
Train Examples: 60000
Batch Size: 2000
Num Epochs: 10
Learning Rate: 0.4 to 0.4 over 10 epochs
Clipping Factor: 4
Sigma: 4
***********************************************************
Epoch 1.1: Loss = 2.32657
Epoch 1.2: Loss = 2.06041
Epoch 1.3: Loss = 1.8546
Epoch 1.4: Loss = 1.65433
Epoch 1.5: Loss = 1.50938
Epoch 1.6: Loss = 1.35886
Epoch 1.7: Loss = 1.25368
Epoch 1.8: Loss = 1.18143
Epoch 1.9: Loss = 1.08694
Epoch 1.10: Loss = 1.09625
Epoch 1.11: Loss = 1.02782
Epoch 1.12: Loss = 1.02295
Epoch 1.13: Loss = 0.944122
Epoch 1.14: Loss = 1.0065
Epoch 1.15: Loss = 0.929291
Epoch 1.16: Loss = 0.964417
Epoch 1.17: Loss = 0.855713
Epoch 1.18: Loss = 0.869614
Epoch 1.19: Loss = 0.823364
Epoch 1.20: Loss = 0.861923
Epoch 1.21: Loss = 0.869537
Epoch 1.22: Loss = 0.93808
Epoch 1.23: Loss = 0.843369
Epoch 1.24: Loss = 0.899918
Epoch 1.25: Loss = 0.876953
Epoch 1.26: Loss = 0.90065
Epoch 1.27: Loss = 0.838165
Epoch 1.28: Loss = 0.8181
Epoch 1.29: Loss = 0.734467
Epoch 1.30: Loss = 0.731506
TRAIN LOSS = 1.10464
TRAIN ACC = 63.1454 % (37889/60000)
Loss = 0.743164
Loss = 0.795761
Loss = 0.756958
Loss = 0.76178
Loss = 0.763336
TEST LOSS = 0.7642
TEST ACC = 378.889 % (7232/10000)
Reducing learning rate to 0.399994
Epoch 2.1: Loss = 0.768204
Epoch 2.2: Loss = 0.795547
Epoch 2.3: Loss = 0.74408
Epoch 2.4: Loss = 0.767929
Epoch 2.5: Loss = 0.724731
Epoch 2.6: Loss = 0.787155
Epoch 2.7: Loss = 0.794067
Epoch 2.8: Loss = 0.880493
Epoch 2.9: Loss = 0.72995
Epoch 2.10: Loss = 0.722885
Epoch 2.11: Loss = 0.734863
Epoch 2.12: Loss = 0.854416
Epoch 2.13: Loss = 0.815018
Epoch 2.14: Loss = 0.958008
Epoch 2.15: Loss = 0.82106
Epoch 2.16: Loss = 0.755829
Epoch 2.17: Loss = 0.632187
Epoch 2.18: Loss = 0.725845
Epoch 2.19: Loss = 0.658188
Epoch 2.20: Loss = 0.829498
Epoch 2.21: Loss = 0.775314
Epoch 2.22: Loss = 0.924408
Epoch 2.23: Loss = 0.742401
Epoch 2.24: Loss = 0.765579
Epoch 2.25: Loss = 0.677689
Epoch 2.26: Loss = 0.767075
Epoch 2.27: Loss = 0.714157
Epoch 2.28: Loss = 0.820755
Epoch 2.29: Loss = 0.698105
Epoch 2.30: Loss = 0.737579
TRAIN LOSS = 0.770782
TRAIN ACC = 74.5712 % (44744/60000)
Loss = 0.647675
Loss = 0.71312
Loss = 0.678162
Loss = 0.670273
Loss = 0.67012
TEST LOSS = 0.67587
TEST ACC = 447.44 % (7683/10000)
Reducing learning rate to 0.399994
Epoch 3.1: Loss = 0.683029
Epoch 3.2: Loss = 0.832748
Epoch 3.3: Loss = 0.818573
Epoch 3.4: Loss = 0.843231
Epoch 3.5: Loss = 0.726761
Epoch 3.6: Loss = 0.856079
Epoch 3.7: Loss = 0.73584
Epoch 3.8: Loss = 0.720459
Epoch 3.9: Loss = 0.659256
Epoch 3.10: Loss = 0.757721
Epoch 3.11: Loss = 0.688324
Epoch 3.12: Loss = 0.772308
Epoch 3.13: Loss = 0.676468
Epoch 3.14: Loss = 0.796005
Epoch 3.15: Loss = 0.664017
Epoch 3.16: Loss = 0.656036
Epoch 3.17: Loss = 0.664856
Epoch 3.18: Loss = 0.788223
Epoch 3.19: Loss = 0.689224
Epoch 3.20: Loss = 0.698517
Epoch 3.21: Loss = 0.661697
Epoch 3.22: Loss = 0.728928
Epoch 3.23: Loss = 0.597137
Epoch 3.24: Loss = 0.710251
Epoch 3.25: Loss = 0.625595
Epoch 3.26: Loss = 0.725739
Epoch 3.27: Loss = 0.732391
Epoch 3.28: Loss = 0.729767
Epoch 3.29: Loss = 0.728271
Epoch 3.30: Loss = 0.723755
TRAIN LOSS = 0.723068
TRAIN ACC = 77.0096 % (46208/60000)
Loss = 0.649933
Loss = 0.732498
Loss = 0.707474
Loss = 0.682785
Loss = 0.691315
TEST LOSS = 0.692801
TEST ACC = 462.079 % (7762/10000)
Reducing learning rate to 0.399994
Epoch 4.1: Loss = 0.657913
Epoch 4.2: Loss = 0.759277
Epoch 4.3: Loss = 0.749847
Epoch 4.4: Loss = 0.755203
Epoch 4.5: Loss = 0.704941
Epoch 4.6: Loss = 0.756424
Epoch 4.7: Loss = 0.737274
Epoch 4.8: Loss = 0.797745
Epoch 4.9: Loss = 0.643921
Epoch 4.10: Loss = 0.718781
Epoch 4.11: Loss = 0.661346
Epoch 4.12: Loss = 0.700317
Epoch 4.13: Loss = 0.757141
Epoch 4.14: Loss = 0.812805
Epoch 4.15: Loss = 0.703415
Epoch 4.16: Loss = 0.698273
Epoch 4.17: Loss = 0.710632
Epoch 4.18: Loss = 0.738068
Epoch 4.19: Loss = 0.843643
Epoch 4.20: Loss = 0.881516
Epoch 4.21: Loss = 0.733368
Epoch 4.22: Loss = 0.693451
Epoch 4.23: Loss = 0.683441
Epoch 4.24: Loss = 0.871887
Epoch 4.25: Loss = 0.705856
Epoch 4.26: Loss = 0.790924
Epoch 4.27: Loss = 0.734741
Epoch 4.28: Loss = 0.819641
Epoch 4.29: Loss = 0.680954
Epoch 4.30: Loss = 0.715927
TRAIN LOSS = 0.740646
TRAIN ACC = 77.7786 % (46670/60000)
Loss = 0.675156
Loss = 0.769424
Loss = 0.752136
Loss = 0.735458
Loss = 0.738083
TEST LOSS = 0.734051
TEST ACC = 466.699 % (7853/10000)
Reducing learning rate to 0.399994
Epoch 5.1: Loss = 0.696426
Epoch 5.2: Loss = 0.615829
Epoch 5.3: Loss = 0.776367
Epoch 5.4: Loss = 0.647888
Epoch 5.5: Loss = 0.88002
Epoch 5.6: Loss = 0.631104
Epoch 5.7: Loss = 0.803925
Epoch 5.8: Loss = 0.743607
Epoch 5.9: Loss = 0.761078
Epoch 5.10: Loss = 0.69812
Epoch 5.11: Loss = 0.805511
Epoch 5.12: Loss = 0.720779
Epoch 5.13: Loss = 0.906662
Epoch 5.14: Loss = 0.718399
Epoch 5.15: Loss = 0.810516
Epoch 5.16: Loss = 0.747528
Epoch 5.17: Loss = 0.764191
Epoch 5.18: Loss = 0.660583
Epoch 5.19: Loss = 0.780365
Epoch 5.20: Loss = 0.671936
Epoch 5.21: Loss = 0.650558
Epoch 5.22: Loss = 0.696594
Epoch 5.23: Loss = 0.715347
Epoch 5.24: Loss = 0.619553
Epoch 5.25: Loss = 0.740784
Epoch 5.26: Loss = 0.650925
Epoch 5.27: Loss = 0.710083
Epoch 5.28: Loss = 0.630249
Epoch 5.29: Loss = 0.711761
Epoch 5.30: Loss = 0.664352
TRAIN LOSS = 0.721054
TRAIN ACC = 79.1351 % (47483/60000)
Loss = 0.645111
Loss = 0.752609
Loss = 0.734833
Loss = 0.714951
Loss = 0.715271
TEST LOSS = 0.712555
TEST ACC = 474.829 % (7956/10000)
Reducing learning rate to 0.399994
Epoch 6.1: Loss = 0.62085
Epoch 6.2: Loss = 0.648605
Epoch 6.3: Loss = 0.823486
Epoch 6.4: Loss = 0.726044
Epoch 6.5: Loss = 0.871002
Epoch 6.6: Loss = 0.683975
Epoch 6.7: Loss = 0.875381
Epoch 6.8: Loss = 0.638351
Epoch 6.9: Loss = 0.714813
Epoch 6.10: Loss = 0.718536
Epoch 6.11: Loss = 0.808746
Epoch 6.12: Loss = 0.914185
Epoch 6.13: Loss = 0.647736
Epoch 6.14: Loss = 0.687576
Epoch 6.15: Loss = 0.643631
Epoch 6.16: Loss = 0.748199
Epoch 6.17: Loss = 0.751251
Epoch 6.18: Loss = 0.720779
Epoch 6.19: Loss = 0.725494
Epoch 6.20: Loss = 0.694504
Epoch 6.21: Loss = 0.817139
Epoch 6.22: Loss = 0.792206
Epoch 6.23: Loss = 0.756561
Epoch 6.24: Loss = 0.66777
Epoch 6.25: Loss = 0.7202
Epoch 6.26: Loss = 0.849228
Epoch 6.27: Loss = 0.732574
Epoch 6.28: Loss = 0.794205
Epoch 6.29: Loss = 0.719467
Epoch 6.30: Loss = 0.801559
TRAIN LOSS = 0.74382
TRAIN ACC = 78.9886 % (47395/60000)
Loss = 0.607452
Loss = 0.696594
Loss = 0.692139
Loss = 0.648499
Loss = 0.651245
TEST LOSS = 0.659186
TEST ACC = 473.949 % (7995/10000)
Reducing learning rate to 0.399994
Epoch 7.1: Loss = 0.61644
Epoch 7.2: Loss = 0.710922
Epoch 7.3: Loss = 0.680786
Epoch 7.4: Loss = 0.703781
Epoch 7.5: Loss = 0.647354
Epoch 7.6: Loss = 0.653625
Epoch 7.7: Loss = 0.626022
Epoch 7.8: Loss = 0.809311
Epoch 7.9: Loss = 0.653442
Epoch 7.10: Loss = 0.618973
Epoch 7.11: Loss = 0.657959
Epoch 7.12: Loss = 0.727448
Epoch 7.13: Loss = 0.760681
Epoch 7.14: Loss = 0.751144
Epoch 7.15: Loss = 0.753922
Epoch 7.16: Loss = 0.747742
Epoch 7.17: Loss = 0.693207
Epoch 7.18: Loss = 0.679245
Epoch 7.19: Loss = 0.662537
Epoch 7.20: Loss = 0.687958
Epoch 7.21: Loss = 0.712265
Epoch 7.22: Loss = 0.782349
Epoch 7.23: Loss = 0.740204
Epoch 7.24: Loss = 0.754379
Epoch 7.25: Loss = 0.744812
Epoch 7.26: Loss = 0.753174
Epoch 7.27: Loss = 0.761215
Epoch 7.28: Loss = 0.758865
Epoch 7.29: Loss = 0.787262
Epoch 7.30: Loss = 0.797256
TRAIN LOSS = 0.714478
TRAIN ACC = 80.1483 % (48092/60000)
Loss = 0.745178
Loss = 0.84198
Loss = 0.863541
Loss = 0.775055
Loss = 0.793121
TEST LOSS = 0.803775
TEST ACC = 480.919 % (7879/10000)
Reducing learning rate to 0.399994
Epoch 8.1: Loss = 0.78978
Epoch 8.2: Loss = 0.685837
Epoch 8.3: Loss = 0.720779
Epoch 8.4: Loss = 0.726303
Epoch 8.5: Loss = 0.654755
Epoch 8.6: Loss = 0.679199
Epoch 8.7: Loss = 0.70224
Epoch 8.8: Loss = 0.749832
Epoch 8.9: Loss = 0.701447
Epoch 8.10: Loss = 0.661148
Epoch 8.11: Loss = 0.664352
Epoch 8.12: Loss = 0.646667
Epoch 8.13: Loss = 0.671478
Epoch 8.14: Loss = 0.692078
Epoch 8.15: Loss = 0.660294
Epoch 8.16: Loss = 0.628845
Epoch 8.17: Loss = 0.690048
Epoch 8.18: Loss = 0.719299
Epoch 8.19: Loss = 0.72316
Epoch 8.20: Loss = 0.737991
Epoch 8.21: Loss = 0.684479
Epoch 8.22: Loss = 0.754898
Epoch 8.23: Loss = 0.691956
Epoch 8.24: Loss = 0.763474
Epoch 8.25: Loss = 0.777145
Epoch 8.26: Loss = 0.759964
Epoch 8.27: Loss = 0.624207
Epoch 8.28: Loss = 0.601547
Epoch 8.29: Loss = 0.623108
Epoch 8.30: Loss = 0.570663
TRAIN LOSS = 0.69191
TRAIN ACC = 80.7755 % (48468/60000)
Loss = 0.609024
Loss = 0.708649
Loss = 0.708817
Loss = 0.655823
Loss = 0.669647
TEST LOSS = 0.670392
TEST ACC = 484.679 % (8122/10000)
Reducing learning rate to 0.399994
Epoch 9.1: Loss = 0.636032
Epoch 9.2: Loss = 0.592484
Epoch 9.3: Loss = 0.623764
Epoch 9.4: Loss = 0.702942
Epoch 9.5: Loss = 0.775879
Epoch 9.6: Loss = 0.647369
Epoch 9.7: Loss = 0.872803
Epoch 9.8: Loss = 0.64621
Epoch 9.9: Loss = 0.613388
Epoch 9.10: Loss = 0.608185
Epoch 9.11: Loss = 0.745132
Epoch 9.12: Loss = 0.768097
Epoch 9.13: Loss = 0.741562
Epoch 9.14: Loss = 0.701706
Epoch 9.15: Loss = 0.678482
Epoch 9.16: Loss = 0.72731
Epoch 9.17: Loss = 0.684418
Epoch 9.18: Loss = 0.786453
Epoch 9.19: Loss = 0.754135
Epoch 9.20: Loss = 0.75
Epoch 9.21: Loss = 0.776535
Epoch 9.22: Loss = 0.784653
Epoch 9.23: Loss = 0.759872
Epoch 9.24: Loss = 0.721603
Epoch 9.25: Loss = 0.72438
Epoch 9.26: Loss = 0.691635
Epoch 9.27: Loss = 0.691223
Epoch 9.28: Loss = 0.629028
Epoch 9.29: Loss = 0.9104
Epoch 9.30: Loss = 0.823486
TRAIN LOSS = 0.718994
TRAIN ACC = 80.7129 % (48430/60000)
Loss = 0.736877
Loss = 0.861969
Loss = 0.861206
Loss = 0.81691
Loss = 0.827438
TEST LOSS = 0.82088
TEST ACC = 484.299 % (7994/10000)
Reducing learning rate to 0.399994
Epoch 10.1: Loss = 0.754288
Epoch 10.2: Loss = 0.73735
Epoch 10.3: Loss = 0.705948
Epoch 10.4: Loss = 0.623154
Epoch 10.5: Loss = 0.74971
Epoch 10.6: Loss = 0.743683
Epoch 10.7: Loss = 0.663345
Epoch 10.8: Loss = 0.687897
Epoch 10.9: Loss = 0.714172
Epoch 10.10: Loss = 0.643799
Epoch 10.11: Loss = 0.721451
Epoch 10.12: Loss = 0.740128
Epoch 10.13: Loss = 0.689285
Epoch 10.14: Loss = 0.623505
Epoch 10.15: Loss = 0.722183
Epoch 10.16: Loss = 0.633163
Epoch 10.17: Loss = 0.775497
Epoch 10.18: Loss = 0.747375
Epoch 10.19: Loss = 0.751053
Epoch 10.20: Loss = 0.687958
Epoch 10.21: Loss = 0.749466
Epoch 10.22: Loss = 0.703339
Epoch 10.23: Loss = 0.701096
Epoch 10.24: Loss = 0.774033
Epoch 10.25: Loss = 0.949692
Epoch 10.26: Loss = 0.831482
Epoch 10.27: Loss = 0.734955
Epoch 10.28: Loss = 0.719818
Epoch 10.29: Loss = 0.636734
Epoch 10.30: Loss = 0.725693
TRAIN LOSS = 0.72139
TRAIN ACC = 81.311 % (48789/60000)
Loss = 0.636749
Loss = 0.748795
Loss = 0.759262
Loss = 0.679916
Loss = 0.691711
TEST LOSS = 0.703287
TEST ACC = 487.889 % (8077/10000)
