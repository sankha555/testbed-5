Using statistical security parameter 40
Trying to run 64-bit computation
Setting up connection 0
***********************************************************
Training MNIST
Model: Dense([60000, 1, 1000]) => Dense([60000, 1, 10]) => MultiOutput([60000, 10]) => 
Train Examples: 60000
Batch Size: 600
Num Epochs: 20
Learning Rate: 0.1 to 0.05 over 10 epochs
Clipping Factor: 4
Sigma: 2.5
***********************************************************
Epoch 1.1: Loss = 2.34547
Epoch 1.2: Loss = 2.3047
Epoch 1.3: Loss = 2.23788
Epoch 1.4: Loss = 2.19299
Epoch 1.5: Loss = 2.1485
Epoch 1.6: Loss = 2.10461
Epoch 1.7: Loss = 2.06288
Epoch 1.8: Loss = 2.02208
Epoch 1.9: Loss = 1.97032
Epoch 1.10: Loss = 1.94319
Epoch 1.11: Loss = 1.87825
Epoch 1.12: Loss = 1.86713
Epoch 1.13: Loss = 1.81557
Epoch 1.14: Loss = 1.78488
Epoch 1.15: Loss = 1.77206
Epoch 1.16: Loss = 1.68542
Epoch 1.17: Loss = 1.67308
Epoch 1.18: Loss = 1.65143
Epoch 1.19: Loss = 1.60094
Epoch 1.20: Loss = 1.58607
Epoch 1.21: Loss = 1.55902
Epoch 1.22: Loss = 1.51385
Epoch 1.23: Loss = 1.43626
Epoch 1.24: Loss = 1.43625
Epoch 1.25: Loss = 1.41162
Epoch 1.26: Loss = 1.37891
Epoch 1.27: Loss = 1.3909
Epoch 1.28: Loss = 1.36388
Epoch 1.29: Loss = 1.32344
Epoch 1.30: Loss = 1.32234
Epoch 1.31: Loss = 1.2484
Epoch 1.32: Loss = 1.27025
Epoch 1.33: Loss = 1.23245
Epoch 1.34: Loss = 1.18425
Epoch 1.35: Loss = 1.22089
Epoch 1.36: Loss = 1.14986
Epoch 1.37: Loss = 1.16107
Epoch 1.38: Loss = 1.14482
Epoch 1.39: Loss = 1.04054
Epoch 1.40: Loss = 1.0733
Epoch 1.41: Loss = 1.05785
Epoch 1.42: Loss = 0.997543
Epoch 1.43: Loss = 1.03256
Epoch 1.44: Loss = 0.993988
Epoch 1.45: Loss = 1.0007
Epoch 1.46: Loss = 0.949707
Epoch 1.47: Loss = 0.98291
Epoch 1.48: Loss = 0.968796
Epoch 1.49: Loss = 0.876572
Epoch 1.50: Loss = 0.930344
Epoch 1.51: Loss = 0.929916
Epoch 1.52: Loss = 0.92363
Epoch 1.53: Loss = 0.865143
Epoch 1.54: Loss = 0.87294
Epoch 1.55: Loss = 0.858627
Epoch 1.56: Loss = 0.820435
Epoch 1.57: Loss = 0.839661
Epoch 1.58: Loss = 0.819916
Epoch 1.59: Loss = 0.77504
Epoch 1.60: Loss = 0.807953
Epoch 1.61: Loss = 0.752991
Epoch 1.62: Loss = 0.795181
Epoch 1.63: Loss = 0.805984
Epoch 1.64: Loss = 0.840942
Epoch 1.65: Loss = 0.756516
Epoch 1.66: Loss = 0.727005
Epoch 1.67: Loss = 0.714783
Epoch 1.68: Loss = 0.783401
Epoch 1.69: Loss = 0.734558
Epoch 1.70: Loss = 0.702499
Epoch 1.71: Loss = 0.758133
Epoch 1.72: Loss = 0.722412
Epoch 1.73: Loss = 0.772171
Epoch 1.74: Loss = 0.708939
Epoch 1.75: Loss = 0.711044
Epoch 1.76: Loss = 0.717834
Epoch 1.77: Loss = 0.680893
Epoch 1.78: Loss = 0.65274
Epoch 1.79: Loss = 0.638123
Epoch 1.80: Loss = 0.687866
Epoch 1.81: Loss = 0.653427
Epoch 1.82: Loss = 0.660095
Epoch 1.83: Loss = 0.673721
Epoch 1.84: Loss = 0.705597
Epoch 1.85: Loss = 0.59758
Epoch 1.86: Loss = 0.629822
Epoch 1.87: Loss = 0.630661
Epoch 1.88: Loss = 0.630676
Epoch 1.89: Loss = 0.603973
Epoch 1.90: Loss = 0.563995
Epoch 1.91: Loss = 0.666199
Epoch 1.92: Loss = 0.670929
Epoch 1.93: Loss = 0.577835
Epoch 1.94: Loss = 0.687439
Epoch 1.95: Loss = 0.607147
Epoch 1.96: Loss = 0.633865
Epoch 1.97: Loss = 0.618927
Epoch 1.98: Loss = 0.617523
Epoch 1.99: Loss = 0.630203
Epoch 1.100: Loss = 0.616913
TRAIN LOSS = 1.10156
TRAIN ACC = 72.583 % (43552/60000)
Loss = 0.624664
Loss = 0.643341
Loss = 0.754654
Loss = 0.699936
Loss = 0.629364
Loss = 0.622757
Loss = 0.7108
Loss = 0.690079
Loss = 0.508438
Loss = 0.459305
Loss = 0.401642
Loss = 0.485123
Loss = 0.452194
Loss = 0.434647
Loss = 0.271561
Loss = 0.419189
Loss = 0.73288
TEST LOSS = 0.557777
TEST ACC = 435.519 % (8481/10000)
Reducing learning rate to 0.0944519
Epoch 2.1: Loss = 0.633835
Epoch 2.2: Loss = 0.623306
Epoch 2.3: Loss = 0.596298
Epoch 2.4: Loss = 0.594269
Epoch 2.5: Loss = 0.578369
Epoch 2.6: Loss = 0.611588
Epoch 2.7: Loss = 0.551468
Epoch 2.8: Loss = 0.558411
Epoch 2.9: Loss = 0.553772
Epoch 2.10: Loss = 0.557098
Epoch 2.11: Loss = 0.497467
Epoch 2.12: Loss = 0.543564
Epoch 2.13: Loss = 0.576248
Epoch 2.14: Loss = 0.531876
Epoch 2.15: Loss = 0.57222
Epoch 2.16: Loss = 0.582565
Epoch 2.17: Loss = 0.538483
Epoch 2.18: Loss = 0.524323
Epoch 2.19: Loss = 0.567123
Epoch 2.20: Loss = 0.514786
Epoch 2.21: Loss = 0.579803
Epoch 2.22: Loss = 0.550781
Epoch 2.23: Loss = 0.555542
Epoch 2.24: Loss = 0.478867
Epoch 2.25: Loss = 0.526428
Epoch 2.26: Loss = 0.535751
Epoch 2.27: Loss = 0.503342
Epoch 2.28: Loss = 0.535339
Epoch 2.29: Loss = 0.477158
Epoch 2.30: Loss = 0.550278
Epoch 2.31: Loss = 0.478073
Epoch 2.32: Loss = 0.570099
Epoch 2.33: Loss = 0.530548
Epoch 2.34: Loss = 0.449615
Epoch 2.35: Loss = 0.476334
Epoch 2.36: Loss = 0.501114
Epoch 2.37: Loss = 0.511505
Epoch 2.38: Loss = 0.499207
Epoch 2.39: Loss = 0.501419
Epoch 2.40: Loss = 0.515945
Epoch 2.41: Loss = 0.517807
Epoch 2.42: Loss = 0.532959
Epoch 2.43: Loss = 0.511841
Epoch 2.44: Loss = 0.529266
Epoch 2.45: Loss = 0.470093
Epoch 2.46: Loss = 0.520432
Epoch 2.47: Loss = 0.56514
Epoch 2.48: Loss = 0.505737
Epoch 2.49: Loss = 0.500168
Epoch 2.50: Loss = 0.456085
Epoch 2.51: Loss = 0.440521
Epoch 2.52: Loss = 0.592361
Epoch 2.53: Loss = 0.445724
Epoch 2.54: Loss = 0.496506
Epoch 2.55: Loss = 0.494766
Epoch 2.56: Loss = 0.463974
Epoch 2.57: Loss = 0.490768
Epoch 2.58: Loss = 0.500656
Epoch 2.59: Loss = 0.527954
Epoch 2.60: Loss = 0.485596
Epoch 2.61: Loss = 0.478455
Epoch 2.62: Loss = 0.495117
Epoch 2.63: Loss = 0.445541
Epoch 2.64: Loss = 0.504013
Epoch 2.65: Loss = 0.449615
Epoch 2.66: Loss = 0.460114
Epoch 2.67: Loss = 0.492935
Epoch 2.68: Loss = 0.480606
Epoch 2.69: Loss = 0.521652
Epoch 2.70: Loss = 0.398605
Epoch 2.71: Loss = 0.475296
Epoch 2.72: Loss = 0.38765
Epoch 2.73: Loss = 0.501083
Epoch 2.74: Loss = 0.442184
Epoch 2.75: Loss = 0.482483
Epoch 2.76: Loss = 0.444168
Epoch 2.77: Loss = 0.475739
Epoch 2.78: Loss = 0.446945
Epoch 2.79: Loss = 0.447769
Epoch 2.80: Loss = 0.450089
Epoch 2.81: Loss = 0.47998
Epoch 2.82: Loss = 0.479691
Epoch 2.83: Loss = 0.446182
Epoch 2.84: Loss = 0.410187
Epoch 2.85: Loss = 0.418503
Epoch 2.86: Loss = 0.489624
Epoch 2.87: Loss = 0.533447
Epoch 2.88: Loss = 0.387939
Epoch 2.89: Loss = 0.425354
Epoch 2.90: Loss = 0.500702
Epoch 2.91: Loss = 0.411224
Epoch 2.92: Loss = 0.463715
Epoch 2.93: Loss = 0.449371
Epoch 2.94: Loss = 0.499557
Epoch 2.95: Loss = 0.458664
Epoch 2.96: Loss = 0.415604
Epoch 2.97: Loss = 0.454742
Epoch 2.98: Loss = 0.425461
Epoch 2.99: Loss = 0.447037
Epoch 2.100: Loss = 0.436371
TRAIN LOSS = 0.499954
TRAIN ACC = 85.5545 % (51334/60000)
Loss = 0.462784
Loss = 0.497757
Loss = 0.610352
Loss = 0.560867
Loss = 0.46167
Loss = 0.463455
Loss = 0.574448
Loss = 0.539627
Loss = 0.382416
Loss = 0.324432
Loss = 0.310333
Loss = 0.33551
Loss = 0.298126
Loss = 0.320953
Loss = 0.148422
Loss = 0.277878
Loss = 0.611801
TEST LOSS = 0.418614
TEST ACC = 513.339 % (8766/10000)
Reducing learning rate to 0.0888977
Epoch 3.1: Loss = 0.515823
Epoch 3.2: Loss = 0.438446
Epoch 3.3: Loss = 0.484421
Epoch 3.4: Loss = 0.448212
Epoch 3.5: Loss = 0.342117
Epoch 3.6: Loss = 0.449448
Epoch 3.7: Loss = 0.428833
Epoch 3.8: Loss = 0.459473
Epoch 3.9: Loss = 0.423981
Epoch 3.10: Loss = 0.430145
Epoch 3.11: Loss = 0.439651
Epoch 3.12: Loss = 0.494949
Epoch 3.13: Loss = 0.358429
Epoch 3.14: Loss = 0.417908
Epoch 3.15: Loss = 0.420822
Epoch 3.16: Loss = 0.451279
Epoch 3.17: Loss = 0.403534
Epoch 3.18: Loss = 0.466385
Epoch 3.19: Loss = 0.439087
Epoch 3.20: Loss = 0.462875
Epoch 3.21: Loss = 0.421585
Epoch 3.22: Loss = 0.468842
Epoch 3.23: Loss = 0.382843
Epoch 3.24: Loss = 0.417892
Epoch 3.25: Loss = 0.452911
Epoch 3.26: Loss = 0.389435
Epoch 3.27: Loss = 0.482925
Epoch 3.28: Loss = 0.416122
Epoch 3.29: Loss = 0.496857
Epoch 3.30: Loss = 0.346329
Epoch 3.31: Loss = 0.446014
Epoch 3.32: Loss = 0.408936
Epoch 3.33: Loss = 0.442001
Epoch 3.34: Loss = 0.442535
Epoch 3.35: Loss = 0.41362
Epoch 3.36: Loss = 0.42041
Epoch 3.37: Loss = 0.418915
Epoch 3.38: Loss = 0.435059
Epoch 3.39: Loss = 0.411362
Epoch 3.40: Loss = 0.405975
Epoch 3.41: Loss = 0.426178
Epoch 3.42: Loss = 0.421631
Epoch 3.43: Loss = 0.362442
Epoch 3.44: Loss = 0.429214
Epoch 3.45: Loss = 0.322021
Epoch 3.46: Loss = 0.394012
Epoch 3.47: Loss = 0.511887
Epoch 3.48: Loss = 0.3909
Epoch 3.49: Loss = 0.418884
Epoch 3.50: Loss = 0.420013
Epoch 3.51: Loss = 0.378876
Epoch 3.52: Loss = 0.397278
Epoch 3.53: Loss = 0.3853
Epoch 3.54: Loss = 0.413208
Epoch 3.55: Loss = 0.42746
Epoch 3.56: Loss = 0.3974
Epoch 3.57: Loss = 0.439789
Epoch 3.58: Loss = 0.479767
Epoch 3.59: Loss = 0.436478
Epoch 3.60: Loss = 0.404236
Epoch 3.61: Loss = 0.422668
Epoch 3.62: Loss = 0.393356
Epoch 3.63: Loss = 0.331787
Epoch 3.64: Loss = 0.419968
Epoch 3.65: Loss = 0.444458
Epoch 3.66: Loss = 0.422729
Epoch 3.67: Loss = 0.471237
Epoch 3.68: Loss = 0.373779
Epoch 3.69: Loss = 0.379776
Epoch 3.70: Loss = 0.369293
Epoch 3.71: Loss = 0.457657
Epoch 3.72: Loss = 0.460327
Epoch 3.73: Loss = 0.39946
Epoch 3.74: Loss = 0.34201
Epoch 3.75: Loss = 0.438553
Epoch 3.76: Loss = 0.415497
Epoch 3.77: Loss = 0.453049
Epoch 3.78: Loss = 0.434647
Epoch 3.79: Loss = 0.417038
Epoch 3.80: Loss = 0.425949
Epoch 3.81: Loss = 0.442581
Epoch 3.82: Loss = 0.37355
Epoch 3.83: Loss = 0.412201
Epoch 3.84: Loss = 0.413239
Epoch 3.85: Loss = 0.36377
Epoch 3.86: Loss = 0.34877
Epoch 3.87: Loss = 0.416931
Epoch 3.88: Loss = 0.455917
Epoch 3.89: Loss = 0.401123
Epoch 3.90: Loss = 0.351974
Epoch 3.91: Loss = 0.439453
Epoch 3.92: Loss = 0.406326
Epoch 3.93: Loss = 0.425888
Epoch 3.94: Loss = 0.430206
Epoch 3.95: Loss = 0.404099
Epoch 3.96: Loss = 0.44194
Epoch 3.97: Loss = 0.391815
Epoch 3.98: Loss = 0.404678
Epoch 3.99: Loss = 0.444748
Epoch 3.100: Loss = 0.395752
TRAIN LOSS = 0.419922
TRAIN ACC = 87.4847 % (52494/60000)
Loss = 0.414474
Loss = 0.445999
Loss = 0.572495
Loss = 0.522049
Loss = 0.409775
Loss = 0.412521
Loss = 0.543411
Loss = 0.487518
Loss = 0.344193
Loss = 0.272629
Loss = 0.290482
Loss = 0.291153
Loss = 0.239304
Loss = 0.288269
Loss = 0.106674
Loss = 0.228775
Loss = 0.558624
TEST LOSS = 0.374528
TEST ACC = 524.939 % (8884/10000)
Reducing learning rate to 0.0833435
Epoch 4.1: Loss = 0.403183
Epoch 4.2: Loss = 0.398743
Epoch 4.3: Loss = 0.373505
Epoch 4.4: Loss = 0.389618
Epoch 4.5: Loss = 0.424683
Epoch 4.6: Loss = 0.416199
Epoch 4.7: Loss = 0.446335
Epoch 4.8: Loss = 0.440872
Epoch 4.9: Loss = 0.33931
Epoch 4.10: Loss = 0.372726
Epoch 4.11: Loss = 0.362854
Epoch 4.12: Loss = 0.413559
Epoch 4.13: Loss = 0.406815
Epoch 4.14: Loss = 0.324646
Epoch 4.15: Loss = 0.417786
Epoch 4.16: Loss = 0.474365
Epoch 4.17: Loss = 0.344101
Epoch 4.18: Loss = 0.369888
Epoch 4.19: Loss = 0.411926
Epoch 4.20: Loss = 0.401352
Epoch 4.21: Loss = 0.382034
Epoch 4.22: Loss = 0.424194
Epoch 4.23: Loss = 0.435867
Epoch 4.24: Loss = 0.350388
Epoch 4.25: Loss = 0.381134
Epoch 4.26: Loss = 0.402359
Epoch 4.27: Loss = 0.423019
Epoch 4.28: Loss = 0.382645
Epoch 4.29: Loss = 0.338135
Epoch 4.30: Loss = 0.381943
Epoch 4.31: Loss = 0.423782
Epoch 4.32: Loss = 0.410965
Epoch 4.33: Loss = 0.344315
Epoch 4.34: Loss = 0.351913
Epoch 4.35: Loss = 0.349869
Epoch 4.36: Loss = 0.395126
Epoch 4.37: Loss = 0.356812
Epoch 4.38: Loss = 0.411621
Epoch 4.39: Loss = 0.420425
Epoch 4.40: Loss = 0.451416
Epoch 4.41: Loss = 0.40387
Epoch 4.42: Loss = 0.433823
Epoch 4.43: Loss = 0.354477
Epoch 4.44: Loss = 0.397827
Epoch 4.45: Loss = 0.489365
Epoch 4.46: Loss = 0.395386
Epoch 4.47: Loss = 0.422165
Epoch 4.48: Loss = 0.362717
Epoch 4.49: Loss = 0.393372
Epoch 4.50: Loss = 0.435486
Epoch 4.51: Loss = 0.411713
Epoch 4.52: Loss = 0.404114
Epoch 4.53: Loss = 0.39859
Epoch 4.54: Loss = 0.391891
Epoch 4.55: Loss = 0.381775
Epoch 4.56: Loss = 0.391327
Epoch 4.57: Loss = 0.328751
Epoch 4.58: Loss = 0.399338
Epoch 4.59: Loss = 0.327316
Epoch 4.60: Loss = 0.460785
Epoch 4.61: Loss = 0.370163
Epoch 4.62: Loss = 0.414124
Epoch 4.63: Loss = 0.303452
Epoch 4.64: Loss = 0.476486
Epoch 4.65: Loss = 0.372574
Epoch 4.66: Loss = 0.358276
Epoch 4.67: Loss = 0.384735
Epoch 4.68: Loss = 0.376221
Epoch 4.69: Loss = 0.354767
Epoch 4.70: Loss = 0.407364
Epoch 4.71: Loss = 0.448517
Epoch 4.72: Loss = 0.424393
Epoch 4.73: Loss = 0.413193
Epoch 4.74: Loss = 0.343857
Epoch 4.75: Loss = 0.309906
Epoch 4.76: Loss = 0.349625
Epoch 4.77: Loss = 0.340134
Epoch 4.78: Loss = 0.359985
Epoch 4.79: Loss = 0.355942
Epoch 4.80: Loss = 0.377823
Epoch 4.81: Loss = 0.447968
Epoch 4.82: Loss = 0.370316
Epoch 4.83: Loss = 0.37381
Epoch 4.84: Loss = 0.330704
Epoch 4.85: Loss = 0.346527
Epoch 4.86: Loss = 0.415512
Epoch 4.87: Loss = 0.344879
Epoch 4.88: Loss = 0.424988
Epoch 4.89: Loss = 0.357498
Epoch 4.90: Loss = 0.388611
Epoch 4.91: Loss = 0.358582
Epoch 4.92: Loss = 0.348099
Epoch 4.93: Loss = 0.338669
Epoch 4.94: Loss = 0.40715
Epoch 4.95: Loss = 0.362152
Epoch 4.96: Loss = 0.396027
Epoch 4.97: Loss = 0.398087
Epoch 4.98: Loss = 0.387024
Epoch 4.99: Loss = 0.367599
Epoch 4.100: Loss = 0.426682
TRAIN LOSS = 0.388687
TRAIN ACC = 88.4216 % (53055/60000)
Loss = 0.389954
Loss = 0.429825
Loss = 0.550003
Loss = 0.507065
Loss = 0.379913
Loss = 0.381363
Loss = 0.529709
Loss = 0.472076
Loss = 0.326172
Loss = 0.250031
Loss = 0.286743
Loss = 0.265289
Loss = 0.211914
Loss = 0.277557
Loss = 0.0886383
Loss = 0.207504
Loss = 0.531189
TEST LOSS = 0.354473
TEST ACC = 530.55 % (8952/10000)
Reducing learning rate to 0.0777893
Epoch 5.1: Loss = 0.373444
Epoch 5.2: Loss = 0.391968
Epoch 5.3: Loss = 0.365677
Epoch 5.4: Loss = 0.427872
Epoch 5.5: Loss = 0.33493
Epoch 5.6: Loss = 0.355667
Epoch 5.7: Loss = 0.370544
Epoch 5.8: Loss = 0.434601
Epoch 5.9: Loss = 0.347061
Epoch 5.10: Loss = 0.355072
Epoch 5.11: Loss = 0.379654
Epoch 5.12: Loss = 0.396149
Epoch 5.13: Loss = 0.40712
Epoch 5.14: Loss = 0.355637
Epoch 5.15: Loss = 0.311264
Epoch 5.16: Loss = 0.383057
Epoch 5.17: Loss = 0.342346
Epoch 5.18: Loss = 0.35025
Epoch 5.19: Loss = 0.36702
Epoch 5.20: Loss = 0.373688
Epoch 5.21: Loss = 0.36615
Epoch 5.22: Loss = 0.408646
Epoch 5.23: Loss = 0.403366
Epoch 5.24: Loss = 0.389191
Epoch 5.25: Loss = 0.410858
Epoch 5.26: Loss = 0.448685
Epoch 5.27: Loss = 0.399918
Epoch 5.28: Loss = 0.316711
Epoch 5.29: Loss = 0.358994
Epoch 5.30: Loss = 0.380966
Epoch 5.31: Loss = 0.322571
Epoch 5.32: Loss = 0.378799
Epoch 5.33: Loss = 0.277649
Epoch 5.34: Loss = 0.354095
Epoch 5.35: Loss = 0.465973
Epoch 5.36: Loss = 0.387802
Epoch 5.37: Loss = 0.385147
Epoch 5.38: Loss = 0.356918
Epoch 5.39: Loss = 0.397873
Epoch 5.40: Loss = 0.361435
Epoch 5.41: Loss = 0.358978
Epoch 5.42: Loss = 0.361115
Epoch 5.43: Loss = 0.36322
Epoch 5.44: Loss = 0.417542
Epoch 5.45: Loss = 0.396194
Epoch 5.46: Loss = 0.444153
Epoch 5.47: Loss = 0.396851
Epoch 5.48: Loss = 0.303253
Epoch 5.49: Loss = 0.343628
Epoch 5.50: Loss = 0.301651
Epoch 5.51: Loss = 0.37265
Epoch 5.52: Loss = 0.40744
Epoch 5.53: Loss = 0.391449
Epoch 5.54: Loss = 0.353806
Epoch 5.55: Loss = 0.396149
Epoch 5.56: Loss = 0.390091
Epoch 5.57: Loss = 0.375107
Epoch 5.58: Loss = 0.355286
Epoch 5.59: Loss = 0.362961
Epoch 5.60: Loss = 0.368591
Epoch 5.61: Loss = 0.335327
Epoch 5.62: Loss = 0.369308
Epoch 5.63: Loss = 0.354019
Epoch 5.64: Loss = 0.348816
Epoch 5.65: Loss = 0.348907
Epoch 5.66: Loss = 0.311432
Epoch 5.67: Loss = 0.373596
Epoch 5.68: Loss = 0.329803
Epoch 5.69: Loss = 0.42514
Epoch 5.70: Loss = 0.33197
Epoch 5.71: Loss = 0.376587
Epoch 5.72: Loss = 0.364304
Epoch 5.73: Loss = 0.431244
Epoch 5.74: Loss = 0.355881
Epoch 5.75: Loss = 0.392349
Epoch 5.76: Loss = 0.315247
Epoch 5.77: Loss = 0.414474
Epoch 5.78: Loss = 0.426025
Epoch 5.79: Loss = 0.365082
Epoch 5.80: Loss = 0.332977
Epoch 5.81: Loss = 0.319138
Epoch 5.82: Loss = 0.352814
Epoch 5.83: Loss = 0.40448
Epoch 5.84: Loss = 0.338409
Epoch 5.85: Loss = 0.374878
Epoch 5.86: Loss = 0.382767
Epoch 5.87: Loss = 0.412247
Epoch 5.88: Loss = 0.359344
Epoch 5.89: Loss = 0.42363
Epoch 5.90: Loss = 0.377899
Epoch 5.91: Loss = 0.376434
Epoch 5.92: Loss = 0.352509
Epoch 5.93: Loss = 0.363831
Epoch 5.94: Loss = 0.370895
Epoch 5.95: Loss = 0.340088
Epoch 5.96: Loss = 0.321884
Epoch 5.97: Loss = 0.395111
Epoch 5.98: Loss = 0.380859
Epoch 5.99: Loss = 0.403854
Epoch 5.100: Loss = 0.356247
TRAIN LOSS = 0.371643
TRAIN ACC = 88.9664 % (53382/60000)
Loss = 0.372543
Loss = 0.414948
Loss = 0.536453
Loss = 0.486679
Loss = 0.362259
Loss = 0.361496
Loss = 0.509781
Loss = 0.448547
Loss = 0.312546
Loss = 0.233704
Loss = 0.289291
Loss = 0.252014
Loss = 0.191818
Loss = 0.283005
Loss = 0.072876
Loss = 0.20253
Loss = 0.516342
TEST LOSS = 0.340483
TEST ACC = 533.82 % (8986/10000)
Reducing learning rate to 0.0722351
Epoch 6.1: Loss = 0.314514
Epoch 6.2: Loss = 0.285431
Epoch 6.3: Loss = 0.359711
Epoch 6.4: Loss = 0.337708
Epoch 6.5: Loss = 0.269089
Epoch 6.6: Loss = 0.385101
Epoch 6.7: Loss = 0.380707
Epoch 6.8: Loss = 0.333878
Epoch 6.9: Loss = 0.379089
Epoch 6.10: Loss = 0.368164
Epoch 6.11: Loss = 0.414169
Epoch 6.12: Loss = 0.322357
Epoch 6.13: Loss = 0.397964
Epoch 6.14: Loss = 0.351898
Epoch 6.15: Loss = 0.400421
Epoch 6.16: Loss = 0.414658
Epoch 6.17: Loss = 0.362534
Epoch 6.18: Loss = 0.372147
Epoch 6.19: Loss = 0.386581
Epoch 6.20: Loss = 0.411575
Epoch 6.21: Loss = 0.340698
Epoch 6.22: Loss = 0.316605
Epoch 6.23: Loss = 0.316925
Epoch 6.24: Loss = 0.411057
Epoch 6.25: Loss = 0.426132
Epoch 6.26: Loss = 0.476563
Epoch 6.27: Loss = 0.415176
Epoch 6.28: Loss = 0.397903
Epoch 6.29: Loss = 0.366074
Epoch 6.30: Loss = 0.429214
Epoch 6.31: Loss = 0.384872
Epoch 6.32: Loss = 0.380005
Epoch 6.33: Loss = 0.316727
Epoch 6.34: Loss = 0.283859
Epoch 6.35: Loss = 0.38765
Epoch 6.36: Loss = 0.324097
Epoch 6.37: Loss = 0.271912
Epoch 6.38: Loss = 0.309555
Epoch 6.39: Loss = 0.3638
Epoch 6.40: Loss = 0.392868
Epoch 6.41: Loss = 0.40033
Epoch 6.42: Loss = 0.316833
Epoch 6.43: Loss = 0.384216
Epoch 6.44: Loss = 0.356476
Epoch 6.45: Loss = 0.352234
Epoch 6.46: Loss = 0.335052
Epoch 6.47: Loss = 0.265839
Epoch 6.48: Loss = 0.39534
Epoch 6.49: Loss = 0.448425
Epoch 6.50: Loss = 0.317734
Epoch 6.51: Loss = 0.365799
Epoch 6.52: Loss = 0.392944
Epoch 6.53: Loss = 0.446152
Epoch 6.54: Loss = 0.311676
Epoch 6.55: Loss = 0.365036
Epoch 6.56: Loss = 0.389847
Epoch 6.57: Loss = 0.375687
Epoch 6.58: Loss = 0.365906
Epoch 6.59: Loss = 0.406952
Epoch 6.60: Loss = 0.376694
Epoch 6.61: Loss = 0.299103
Epoch 6.62: Loss = 0.36937
Epoch 6.63: Loss = 0.465042
Epoch 6.64: Loss = 0.419083
Epoch 6.65: Loss = 0.414276
Epoch 6.66: Loss = 0.326187
Epoch 6.67: Loss = 0.304398
Epoch 6.68: Loss = 0.285309
Epoch 6.69: Loss = 0.322357
Epoch 6.70: Loss = 0.38826
Epoch 6.71: Loss = 0.296509
Epoch 6.72: Loss = 0.360779
Epoch 6.73: Loss = 0.350967
Epoch 6.74: Loss = 0.409332
Epoch 6.75: Loss = 0.38945
Epoch 6.76: Loss = 0.333008
Epoch 6.77: Loss = 0.40506
Epoch 6.78: Loss = 0.308228
Epoch 6.79: Loss = 0.31575
Epoch 6.80: Loss = 0.373322
Epoch 6.81: Loss = 0.35675
Epoch 6.82: Loss = 0.33519
Epoch 6.83: Loss = 0.368271
Epoch 6.84: Loss = 0.33873
Epoch 6.85: Loss = 0.323746
Epoch 6.86: Loss = 0.395264
Epoch 6.87: Loss = 0.342392
Epoch 6.88: Loss = 0.335846
Epoch 6.89: Loss = 0.2724
Epoch 6.90: Loss = 0.427444
Epoch 6.91: Loss = 0.332565
Epoch 6.92: Loss = 0.354446
Epoch 6.93: Loss = 0.365036
Epoch 6.94: Loss = 0.327881
Epoch 6.95: Loss = 0.401932
Epoch 6.96: Loss = 0.371552
Epoch 6.97: Loss = 0.330597
Epoch 6.98: Loss = 0.340454
Epoch 6.99: Loss = 0.390396
Epoch 6.100: Loss = 0.342407
TRAIN LOSS = 0.361191
TRAIN ACC = 89.3951 % (53640/60000)
Loss = 0.36084
Loss = 0.410156
Loss = 0.529587
Loss = 0.490707
Loss = 0.351089
Loss = 0.357834
Loss = 0.505966
Loss = 0.442215
Loss = 0.302841
Loss = 0.232483
Loss = 0.288712
Loss = 0.238312
Loss = 0.173752
Loss = 0.261551
Loss = 0.0676727
Loss = 0.189819
Loss = 0.516602
TEST LOSS = 0.332876
TEST ACC = 536.4 % (9031/10000)
Reducing learning rate to 0.0666809
Epoch 7.1: Loss = 0.411819
Epoch 7.2: Loss = 0.311035
Epoch 7.3: Loss = 0.284088
Epoch 7.4: Loss = 0.411011
Epoch 7.5: Loss = 0.331009
Epoch 7.6: Loss = 0.299805
Epoch 7.7: Loss = 0.364273
Epoch 7.8: Loss = 0.377335
Epoch 7.9: Loss = 0.33345
Epoch 7.10: Loss = 0.291214
Epoch 7.11: Loss = 0.336365
Epoch 7.12: Loss = 0.381546
Epoch 7.13: Loss = 0.370117
Epoch 7.14: Loss = 0.424225
Epoch 7.15: Loss = 0.358841
Epoch 7.16: Loss = 0.31868
Epoch 7.17: Loss = 0.387772
Epoch 7.18: Loss = 0.332565
Epoch 7.19: Loss = 0.365982
Epoch 7.20: Loss = 0.291107
Epoch 7.21: Loss = 0.352493
Epoch 7.22: Loss = 0.316254
Epoch 7.23: Loss = 0.304001
Epoch 7.24: Loss = 0.311371
Epoch 7.25: Loss = 0.337891
Epoch 7.26: Loss = 0.329117
Epoch 7.27: Loss = 0.300797
Epoch 7.28: Loss = 0.377914
Epoch 7.29: Loss = 0.329666
Epoch 7.30: Loss = 0.347778
Epoch 7.31: Loss = 0.326538
Epoch 7.32: Loss = 0.287476
Epoch 7.33: Loss = 0.407333
Epoch 7.34: Loss = 0.338989
Epoch 7.35: Loss = 0.373108
Epoch 7.36: Loss = 0.368408
Epoch 7.37: Loss = 0.384232
Epoch 7.38: Loss = 0.360413
Epoch 7.39: Loss = 0.38652
Epoch 7.40: Loss = 0.369553
Epoch 7.41: Loss = 0.381317
Epoch 7.42: Loss = 0.36261
Epoch 7.43: Loss = 0.368958
Epoch 7.44: Loss = 0.346008
Epoch 7.45: Loss = 0.344193
Epoch 7.46: Loss = 0.358765
Epoch 7.47: Loss = 0.32692
Epoch 7.48: Loss = 0.368179
Epoch 7.49: Loss = 0.324997
Epoch 7.50: Loss = 0.347977
Epoch 7.51: Loss = 0.293259
Epoch 7.52: Loss = 0.374069
Epoch 7.53: Loss = 0.327484
Epoch 7.54: Loss = 0.286346
Epoch 7.55: Loss = 0.348862
Epoch 7.56: Loss = 0.393494
Epoch 7.57: Loss = 0.433914
Epoch 7.58: Loss = 0.307236
Epoch 7.59: Loss = 0.348846
Epoch 7.60: Loss = 0.360306
Epoch 7.61: Loss = 0.303391
Epoch 7.62: Loss = 0.485718
Epoch 7.63: Loss = 0.374725
Epoch 7.64: Loss = 0.37384
Epoch 7.65: Loss = 0.433838
Epoch 7.66: Loss = 0.373199
Epoch 7.67: Loss = 0.316269
Epoch 7.68: Loss = 0.451447
Epoch 7.69: Loss = 0.265045
Epoch 7.70: Loss = 0.3629
Epoch 7.71: Loss = 0.343491
Epoch 7.72: Loss = 0.350983
Epoch 7.73: Loss = 0.332596
Epoch 7.74: Loss = 0.285492
Epoch 7.75: Loss = 0.382309
Epoch 7.76: Loss = 0.324005
Epoch 7.77: Loss = 0.332733
Epoch 7.78: Loss = 0.338699
Epoch 7.79: Loss = 0.430847
Epoch 7.80: Loss = 0.307053
Epoch 7.81: Loss = 0.335709
Epoch 7.82: Loss = 0.299728
Epoch 7.83: Loss = 0.376694
Epoch 7.84: Loss = 0.371078
Epoch 7.85: Loss = 0.387894
Epoch 7.86: Loss = 0.365997
Epoch 7.87: Loss = 0.325577
Epoch 7.88: Loss = 0.454727
Epoch 7.89: Loss = 0.369049
Epoch 7.90: Loss = 0.336594
Epoch 7.91: Loss = 0.303558
Epoch 7.92: Loss = 0.352829
Epoch 7.93: Loss = 0.354263
Epoch 7.94: Loss = 0.307159
Epoch 7.95: Loss = 0.280746
Epoch 7.96: Loss = 0.365173
Epoch 7.97: Loss = 0.423538
Epoch 7.98: Loss = 0.36351
Epoch 7.99: Loss = 0.34288
Epoch 7.100: Loss = 0.361206
TRAIN LOSS = 0.351425
TRAIN ACC = 89.7202 % (53834/60000)
Loss = 0.348206
Loss = 0.394867
Loss = 0.522324
Loss = 0.482986
Loss = 0.338776
Loss = 0.347717
Loss = 0.50798
Loss = 0.438202
Loss = 0.300934
Loss = 0.21965
Loss = 0.292374
Loss = 0.234299
Loss = 0.168793
Loss = 0.258286
Loss = 0.0664825
Loss = 0.181488
Loss = 0.501389
TEST LOSS = 0.326257
TEST ACC = 538.339 % (9059/10000)
Reducing learning rate to 0.0611267
Epoch 8.1: Loss = 0.350693
Epoch 8.2: Loss = 0.333237
Epoch 8.3: Loss = 0.307358
Epoch 8.4: Loss = 0.363525
Epoch 8.5: Loss = 0.344467
Epoch 8.6: Loss = 0.281021
Epoch 8.7: Loss = 0.348618
Epoch 8.8: Loss = 0.350006
Epoch 8.9: Loss = 0.32782
Epoch 8.10: Loss = 0.342331
Epoch 8.11: Loss = 0.382874
Epoch 8.12: Loss = 0.425751
Epoch 8.13: Loss = 0.477264
Epoch 8.14: Loss = 0.344803
Epoch 8.15: Loss = 0.371216
Epoch 8.16: Loss = 0.29953
Epoch 8.17: Loss = 0.311142
Epoch 8.18: Loss = 0.336823
Epoch 8.19: Loss = 0.348724
Epoch 8.20: Loss = 0.365402
Epoch 8.21: Loss = 0.347427
Epoch 8.22: Loss = 0.279343
Epoch 8.23: Loss = 0.424118
Epoch 8.24: Loss = 0.344391
Epoch 8.25: Loss = 0.335785
Epoch 8.26: Loss = 0.371521
Epoch 8.27: Loss = 0.332047
Epoch 8.28: Loss = 0.370865
Epoch 8.29: Loss = 0.322983
Epoch 8.30: Loss = 0.339737
Epoch 8.31: Loss = 0.246124
Epoch 8.32: Loss = 0.339722
Epoch 8.33: Loss = 0.323288
Epoch 8.34: Loss = 0.395844
Epoch 8.35: Loss = 0.353271
Epoch 8.36: Loss = 0.357086
Epoch 8.37: Loss = 0.388992
Epoch 8.38: Loss = 0.26384
Epoch 8.39: Loss = 0.337982
Epoch 8.40: Loss = 0.249695
Epoch 8.41: Loss = 0.345932
Epoch 8.42: Loss = 0.351471
Epoch 8.43: Loss = 0.473816
Epoch 8.44: Loss = 0.393494
Epoch 8.45: Loss = 0.319031
Epoch 8.46: Loss = 0.399826
Epoch 8.47: Loss = 0.341446
Epoch 8.48: Loss = 0.36171
Epoch 8.49: Loss = 0.346802
Epoch 8.50: Loss = 0.339188
Epoch 8.51: Loss = 0.350357
Epoch 8.52: Loss = 0.35762
Epoch 8.53: Loss = 0.384338
Epoch 8.54: Loss = 0.331665
Epoch 8.55: Loss = 0.396805
Epoch 8.56: Loss = 0.413712
Epoch 8.57: Loss = 0.349365
Epoch 8.58: Loss = 0.380692
Epoch 8.59: Loss = 0.308975
Epoch 8.60: Loss = 0.402496
Epoch 8.61: Loss = 0.395966
Epoch 8.62: Loss = 0.293701
Epoch 8.63: Loss = 0.365219
Epoch 8.64: Loss = 0.356384
Epoch 8.65: Loss = 0.346954
Epoch 8.66: Loss = 0.293533
Epoch 8.67: Loss = 0.308044
Epoch 8.68: Loss = 0.302368
Epoch 8.69: Loss = 0.290421
Epoch 8.70: Loss = 0.36377
Epoch 8.71: Loss = 0.275665
Epoch 8.72: Loss = 0.347961
Epoch 8.73: Loss = 0.299194
Epoch 8.74: Loss = 0.307816
Epoch 8.75: Loss = 0.312515
Epoch 8.76: Loss = 0.299133
Epoch 8.77: Loss = 0.318359
Epoch 8.78: Loss = 0.34465
Epoch 8.79: Loss = 0.433243
Epoch 8.80: Loss = 0.357407
Epoch 8.81: Loss = 0.355759
Epoch 8.82: Loss = 0.394577
Epoch 8.83: Loss = 0.353317
Epoch 8.84: Loss = 0.361832
Epoch 8.85: Loss = 0.31665
Epoch 8.86: Loss = 0.385147
Epoch 8.87: Loss = 0.296921
Epoch 8.88: Loss = 0.420898
Epoch 8.89: Loss = 0.25499
Epoch 8.90: Loss = 0.446533
Epoch 8.91: Loss = 0.344894
Epoch 8.92: Loss = 0.362045
Epoch 8.93: Loss = 0.306885
Epoch 8.94: Loss = 0.345795
Epoch 8.95: Loss = 0.343781
Epoch 8.96: Loss = 0.338791
Epoch 8.97: Loss = 0.27504
Epoch 8.98: Loss = 0.341064
Epoch 8.99: Loss = 0.353317
Epoch 8.100: Loss = 0.339386
TRAIN LOSS = 0.346375
TRAIN ACC = 89.9612 % (53979/60000)
Loss = 0.344971
Loss = 0.390518
Loss = 0.516449
Loss = 0.479431
Loss = 0.334869
Loss = 0.339813
Loss = 0.504776
Loss = 0.43071
Loss = 0.294281
Loss = 0.215683
Loss = 0.285919
Loss = 0.23056
Loss = 0.166656
Loss = 0.256149
Loss = 0.0611877
Loss = 0.179947
Loss = 0.502502
TEST LOSS = 0.322015
TEST ACC = 539.789 % (9075/10000)
Reducing learning rate to 0.0555725
Epoch 9.1: Loss = 0.3461
Epoch 9.2: Loss = 0.272141
Epoch 9.3: Loss = 0.350189
Epoch 9.4: Loss = 0.298203
Epoch 9.5: Loss = 0.326141
Epoch 9.6: Loss = 0.335373
Epoch 9.7: Loss = 0.409164
Epoch 9.8: Loss = 0.303101
Epoch 9.9: Loss = 0.352112
Epoch 9.10: Loss = 0.322495
Epoch 9.11: Loss = 0.426224
Epoch 9.12: Loss = 0.305038
Epoch 9.13: Loss = 0.376328
Epoch 9.14: Loss = 0.317993
Epoch 9.15: Loss = 0.339142
Epoch 9.16: Loss = 0.344788
Epoch 9.17: Loss = 0.397751
Epoch 9.18: Loss = 0.393967
Epoch 9.19: Loss = 0.391068
Epoch 9.20: Loss = 0.35022
Epoch 9.21: Loss = 0.297318
Epoch 9.22: Loss = 0.395142
Epoch 9.23: Loss = 0.320206
Epoch 9.24: Loss = 0.320282
Epoch 9.25: Loss = 0.316895
Epoch 9.26: Loss = 0.372757
Epoch 9.27: Loss = 0.341797
Epoch 9.28: Loss = 0.294785
Epoch 9.29: Loss = 0.369781
Epoch 9.30: Loss = 0.399551
Epoch 9.31: Loss = 0.333984
Epoch 9.32: Loss = 0.336716
Epoch 9.33: Loss = 0.346893
Epoch 9.34: Loss = 0.417694
Epoch 9.35: Loss = 0.340042
Epoch 9.36: Loss = 0.393265
Epoch 9.37: Loss = 0.251556
Epoch 9.38: Loss = 0.282654
Epoch 9.39: Loss = 0.341354
Epoch 9.40: Loss = 0.389633
Epoch 9.41: Loss = 0.347488
Epoch 9.42: Loss = 0.35643
Epoch 9.43: Loss = 0.319717
Epoch 9.44: Loss = 0.305603
Epoch 9.45: Loss = 0.382706
Epoch 9.46: Loss = 0.292084
Epoch 9.47: Loss = 0.351212
Epoch 9.48: Loss = 0.360901
Epoch 9.49: Loss = 0.339233
Epoch 9.50: Loss = 0.33374
Epoch 9.51: Loss = 0.352371
Epoch 9.52: Loss = 0.367386
Epoch 9.53: Loss = 0.348923
Epoch 9.54: Loss = 0.35791
Epoch 9.55: Loss = 0.412216
Epoch 9.56: Loss = 0.382843
Epoch 9.57: Loss = 0.360397
Epoch 9.58: Loss = 0.361923
Epoch 9.59: Loss = 0.341751
Epoch 9.60: Loss = 0.322678
Epoch 9.61: Loss = 0.361893
Epoch 9.62: Loss = 0.332291
Epoch 9.63: Loss = 0.302505
Epoch 9.64: Loss = 0.343246
Epoch 9.65: Loss = 0.292099
Epoch 9.66: Loss = 0.345398
Epoch 9.67: Loss = 0.308762
Epoch 9.68: Loss = 0.259918
Epoch 9.69: Loss = 0.420929
Epoch 9.70: Loss = 0.291275
Epoch 9.71: Loss = 0.323776
Epoch 9.72: Loss = 0.30368
Epoch 9.73: Loss = 0.339432
Epoch 9.74: Loss = 0.412857
Epoch 9.75: Loss = 0.28476
Epoch 9.76: Loss = 0.30864
Epoch 9.77: Loss = 0.318558
Epoch 9.78: Loss = 0.451599
Epoch 9.79: Loss = 0.284576
Epoch 9.80: Loss = 0.395065
Epoch 9.81: Loss = 0.358963
Epoch 9.82: Loss = 0.350388
Epoch 9.83: Loss = 0.387619
Epoch 9.84: Loss = 0.366013
Epoch 9.85: Loss = 0.341415
Epoch 9.86: Loss = 0.352554
Epoch 9.87: Loss = 0.359268
Epoch 9.88: Loss = 0.322525
Epoch 9.89: Loss = 0.334549
Epoch 9.90: Loss = 0.355759
Epoch 9.91: Loss = 0.294159
Epoch 9.92: Loss = 0.286133
Epoch 9.93: Loss = 0.283752
Epoch 9.94: Loss = 0.341797
Epoch 9.95: Loss = 0.340347
Epoch 9.96: Loss = 0.415039
Epoch 9.97: Loss = 0.308502
Epoch 9.98: Loss = 0.292969
Epoch 9.99: Loss = 0.329971
Epoch 9.100: Loss = 0.268753
TRAIN LOSS = 0.341904
TRAIN ACC = 90.1566 % (54096/60000)
Loss = 0.335983
Loss = 0.388901
Loss = 0.510895
Loss = 0.473892
Loss = 0.331177
Loss = 0.337189
Loss = 0.50148
Loss = 0.426743
Loss = 0.288727
Loss = 0.216949
Loss = 0.288055
Loss = 0.218689
Loss = 0.156693
Loss = 0.253967
Loss = 0.0555725
Loss = 0.176727
Loss = 0.502579
TEST LOSS = 0.317801
TEST ACC = 540.959 % (9082/10000)
Reducing learning rate to 0.0500183
Epoch 10.1: Loss = 0.259338
Epoch 10.2: Loss = 0.277908
Epoch 10.3: Loss = 0.378967
Epoch 10.4: Loss = 0.333511
Epoch 10.5: Loss = 0.384567
Epoch 10.6: Loss = 0.308243
Epoch 10.7: Loss = 0.33931
Epoch 10.8: Loss = 0.308273
Epoch 10.9: Loss = 0.375336
Epoch 10.10: Loss = 0.276199
Epoch 10.11: Loss = 0.352921
Epoch 10.12: Loss = 0.336029
Epoch 10.13: Loss = 0.34938
Epoch 10.14: Loss = 0.274368
Epoch 10.15: Loss = 0.327209
Epoch 10.16: Loss = 0.267517
Epoch 10.17: Loss = 0.326996
Epoch 10.18: Loss = 0.343933
Epoch 10.19: Loss = 0.338562
Epoch 10.20: Loss = 0.334503
Epoch 10.21: Loss = 0.362747
Epoch 10.22: Loss = 0.343185
Epoch 10.23: Loss = 0.315979
Epoch 10.24: Loss = 0.403687
Epoch 10.25: Loss = 0.362167
Epoch 10.26: Loss = 0.427261
Epoch 10.27: Loss = 0.273346
Epoch 10.28: Loss = 0.369278
Epoch 10.29: Loss = 0.284576
Epoch 10.30: Loss = 0.361938
Epoch 10.31: Loss = 0.384323
Epoch 10.32: Loss = 0.253174
Epoch 10.33: Loss = 0.276993
Epoch 10.34: Loss = 0.419662
Epoch 10.35: Loss = 0.333542
Epoch 10.36: Loss = 0.397903
Epoch 10.37: Loss = 0.372498
Epoch 10.38: Loss = 0.380295
Epoch 10.39: Loss = 0.331421
Epoch 10.40: Loss = 0.309113
Epoch 10.41: Loss = 0.403824
Epoch 10.42: Loss = 0.411102
Epoch 10.43: Loss = 0.424362
Epoch 10.44: Loss = 0.29364
Epoch 10.45: Loss = 0.252258
Epoch 10.46: Loss = 0.401367
Epoch 10.47: Loss = 0.328369
Epoch 10.48: Loss = 0.330719
Epoch 10.49: Loss = 0.336105
Epoch 10.50: Loss = 0.313644
Epoch 10.51: Loss = 0.263382
Epoch 10.52: Loss = 0.298782
Epoch 10.53: Loss = 0.306686
Epoch 10.54: Loss = 0.298965
Epoch 10.55: Loss = 0.331711
Epoch 10.56: Loss = 0.390793
Epoch 10.57: Loss = 0.312408
Epoch 10.58: Loss = 0.384949
Epoch 10.59: Loss = 0.370621
Epoch 10.60: Loss = 0.368805
Epoch 10.61: Loss = 0.277817
Epoch 10.62: Loss = 0.332062
Epoch 10.63: Loss = 0.297638
Epoch 10.64: Loss = 0.329498
Epoch 10.65: Loss = 0.325821
Epoch 10.66: Loss = 0.334091
Epoch 10.67: Loss = 0.267426
Epoch 10.68: Loss = 0.345932
Epoch 10.69: Loss = 0.397919
Epoch 10.70: Loss = 0.406357
Epoch 10.71: Loss = 0.285889
Epoch 10.72: Loss = 0.375336
Epoch 10.73: Loss = 0.331573
Epoch 10.74: Loss = 0.359833
Epoch 10.75: Loss = 0.338989
Epoch 10.76: Loss = 0.383698
Epoch 10.77: Loss = 0.309143
Epoch 10.78: Loss = 0.293365
Epoch 10.79: Loss = 0.394073
Epoch 10.80: Loss = 0.378235
Epoch 10.81: Loss = 0.373886
Epoch 10.82: Loss = 0.32193
Epoch 10.83: Loss = 0.3228
Epoch 10.84: Loss = 0.436432
Epoch 10.85: Loss = 0.351715
Epoch 10.86: Loss = 0.316147
Epoch 10.87: Loss = 0.261383
Epoch 10.88: Loss = 0.371552
Epoch 10.89: Loss = 0.358948
Epoch 10.90: Loss = 0.315964
Epoch 10.91: Loss = 0.313919
Epoch 10.92: Loss = 0.314529
Epoch 10.93: Loss = 0.312637
Epoch 10.94: Loss = 0.346497
Epoch 10.95: Loss = 0.37178
Epoch 10.96: Loss = 0.339676
Epoch 10.97: Loss = 0.397522
Epoch 10.98: Loss = 0.340744
Epoch 10.99: Loss = 0.272858
Epoch 10.100: Loss = 0.327209
TRAIN LOSS = 0.338104
TRAIN ACC = 90.3183 % (54193/60000)
Loss = 0.335739
Loss = 0.385056
Loss = 0.511719
Loss = 0.476974
Loss = 0.3302
Loss = 0.334442
Loss = 0.504868
Loss = 0.425507
Loss = 0.290253
Loss = 0.215164
Loss = 0.285934
Loss = 0.218658
Loss = 0.151047
Loss = 0.248657
Loss = 0.0553284
Loss = 0.176224
Loss = 0.494659
TEST LOSS = 0.316533
TEST ACC = 541.93 % (9098/10000)
Epoch 11.1: Loss = 0.363373
Epoch 11.2: Loss = 0.322556
Epoch 11.3: Loss = 0.334244
Epoch 11.4: Loss = 0.311096
Epoch 11.5: Loss = 0.371078
Epoch 11.6: Loss = 0.282883
Epoch 11.7: Loss = 0.272018
Epoch 11.8: Loss = 0.336044
Epoch 11.9: Loss = 0.291183
Epoch 11.10: Loss = 0.320068
Epoch 11.11: Loss = 0.362549
Epoch 11.12: Loss = 0.279022
Epoch 11.13: Loss = 0.392517
Epoch 11.14: Loss = 0.321854
Epoch 11.15: Loss = 0.306305
Epoch 11.16: Loss = 0.412628
Epoch 11.17: Loss = 0.387268
Epoch 11.18: Loss = 0.282745
Epoch 11.19: Loss = 0.332169
Epoch 11.20: Loss = 0.380676
Epoch 11.21: Loss = 0.297211
Epoch 11.22: Loss = 0.343323
Epoch 11.23: Loss = 0.347458
Epoch 11.24: Loss = 0.300583
Epoch 11.25: Loss = 0.351166
Epoch 11.26: Loss = 0.309967
Epoch 11.27: Loss = 0.341721
Epoch 11.28: Loss = 0.395325
Epoch 11.29: Loss = 0.389038
Epoch 11.30: Loss = 0.399445
Epoch 11.31: Loss = 0.30574
Epoch 11.32: Loss = 0.296616
Epoch 11.33: Loss = 0.340332
Epoch 11.34: Loss = 0.310852
Epoch 11.35: Loss = 0.305725
Epoch 11.36: Loss = 0.341324
Epoch 11.37: Loss = 0.316116
Epoch 11.38: Loss = 0.339676
Epoch 11.39: Loss = 0.305618
Epoch 11.40: Loss = 0.312393
Epoch 11.41: Loss = 0.346313
Epoch 11.42: Loss = 0.281662
Epoch 11.43: Loss = 0.371277
Epoch 11.44: Loss = 0.406326
Epoch 11.45: Loss = 0.31076
Epoch 11.46: Loss = 0.338257
Epoch 11.47: Loss = 0.397675
Epoch 11.48: Loss = 0.380386
Epoch 11.49: Loss = 0.299881
Epoch 11.50: Loss = 0.372177
Epoch 11.51: Loss = 0.33522
Epoch 11.52: Loss = 0.298553
Epoch 11.53: Loss = 0.370453
Epoch 11.54: Loss = 0.382095
Epoch 11.55: Loss = 0.286072
Epoch 11.56: Loss = 0.27774
Epoch 11.57: Loss = 0.276581
Epoch 11.58: Loss = 0.4021
Epoch 11.59: Loss = 0.39386
Epoch 11.60: Loss = 0.369049
Epoch 11.61: Loss = 0.281494
Epoch 11.62: Loss = 0.32402
Epoch 11.63: Loss = 0.342331
Epoch 11.64: Loss = 0.420776
Epoch 11.65: Loss = 0.331696
Epoch 11.66: Loss = 0.368103
Epoch 11.67: Loss = 0.314957
Epoch 11.68: Loss = 0.303116
Epoch 11.69: Loss = 0.291
Epoch 11.70: Loss = 0.29808
Epoch 11.71: Loss = 0.319901
Epoch 11.72: Loss = 0.252869
Epoch 11.73: Loss = 0.403397
Epoch 11.74: Loss = 0.366364
Epoch 11.75: Loss = 0.316223
Epoch 11.76: Loss = 0.34642
Epoch 11.77: Loss = 0.285187
Epoch 11.78: Loss = 0.289246
Epoch 11.79: Loss = 0.338165
Epoch 11.80: Loss = 0.370895
Epoch 11.81: Loss = 0.298462
Epoch 11.82: Loss = 0.261444
Epoch 11.83: Loss = 0.358047
Epoch 11.84: Loss = 0.325974
Epoch 11.85: Loss = 0.353455
Epoch 11.86: Loss = 0.405914
Epoch 11.87: Loss = 0.375748
Epoch 11.88: Loss = 0.413315
Epoch 11.89: Loss = 0.33696
Epoch 11.90: Loss = 0.288162
Epoch 11.91: Loss = 0.383499
Epoch 11.92: Loss = 0.356018
Epoch 11.93: Loss = 0.303421
Epoch 11.94: Loss = 0.331131
Epoch 11.95: Loss = 0.324265
Epoch 11.96: Loss = 0.299484
Epoch 11.97: Loss = 0.337173
Epoch 11.98: Loss = 0.370346
Epoch 11.99: Loss = 0.323349
Epoch 11.100: Loss = 0.330338
TRAIN LOSS = 0.33548
TRAIN ACC = 90.4495 % (54272/60000)
Loss = 0.328995
Loss = 0.379547
Loss = 0.502991
Loss = 0.47226
Loss = 0.325165
Loss = 0.332169
Loss = 0.499359
Loss = 0.418442
Loss = 0.287933
Loss = 0.209259
Loss = 0.289352
Loss = 0.215637
Loss = 0.145508
Loss = 0.243164
Loss = 0.0512238
Loss = 0.179062
Loss = 0.496918
TEST LOSS = 0.312681
TEST ACC = 542.719 % (9118/10000)
Epoch 12.1: Loss = 0.385574
Epoch 12.2: Loss = 0.32312
Epoch 12.3: Loss = 0.317474
Epoch 12.4: Loss = 0.336426
Epoch 12.5: Loss = 0.326187
Epoch 12.6: Loss = 0.320999
Epoch 12.7: Loss = 0.32724
Epoch 12.8: Loss = 0.376968
Epoch 12.9: Loss = 0.334213
Epoch 12.10: Loss = 0.278976
Epoch 12.11: Loss = 0.324905
Epoch 12.12: Loss = 0.288925
Epoch 12.13: Loss = 0.333786
Epoch 12.14: Loss = 0.31163
Epoch 12.15: Loss = 0.344925
Epoch 12.16: Loss = 0.344742
Epoch 12.17: Loss = 0.381393
Epoch 12.18: Loss = 0.369125
Epoch 12.19: Loss = 0.30899
Epoch 12.20: Loss = 0.267349
Epoch 12.21: Loss = 0.315491
Epoch 12.22: Loss = 0.306976
Epoch 12.23: Loss = 0.341583
Epoch 12.24: Loss = 0.316696
Epoch 12.25: Loss = 0.370987
Epoch 12.26: Loss = 0.343399
Epoch 12.27: Loss = 0.398895
Epoch 12.28: Loss = 0.247086
Epoch 12.29: Loss = 0.363327
Epoch 12.30: Loss = 0.275284
Epoch 12.31: Loss = 0.29834
Epoch 12.32: Loss = 0.347656
Epoch 12.33: Loss = 0.340454
Epoch 12.34: Loss = 0.32309
Epoch 12.35: Loss = 0.318787
Epoch 12.36: Loss = 0.255142
Epoch 12.37: Loss = 0.295609
Epoch 12.38: Loss = 0.38295
Epoch 12.39: Loss = 0.348999
Epoch 12.40: Loss = 0.368393
Epoch 12.41: Loss = 0.384201
Epoch 12.42: Loss = 0.299347
Epoch 12.43: Loss = 0.329956
Epoch 12.44: Loss = 0.302704
Epoch 12.45: Loss = 0.331802
Epoch 12.46: Loss = 0.362717
Epoch 12.47: Loss = 0.352249
Epoch 12.48: Loss = 0.365143
Epoch 12.49: Loss = 0.292313
Epoch 12.50: Loss = 0.343628
Epoch 12.51: Loss = 0.355423
Epoch 12.52: Loss = 0.343536
Epoch 12.53: Loss = 0.319641
Epoch 12.54: Loss = 0.419144
Epoch 12.55: Loss = 0.323715
Epoch 12.56: Loss = 0.341812
Epoch 12.57: Loss = 0.30069
Epoch 12.58: Loss = 0.319534
Epoch 12.59: Loss = 0.348938
Epoch 12.60: Loss = 0.263153
Epoch 12.61: Loss = 0.273926
Epoch 12.62: Loss = 0.304474
Epoch 12.63: Loss = 0.340591
Epoch 12.64: Loss = 0.326813
Epoch 12.65: Loss = 0.306396
Epoch 12.66: Loss = 0.355972
Epoch 12.67: Loss = 0.315674
Epoch 12.68: Loss = 0.395187
Epoch 12.69: Loss = 0.364792
Epoch 12.70: Loss = 0.350815
Epoch 12.71: Loss = 0.33522
Epoch 12.72: Loss = 0.320221
Epoch 12.73: Loss = 0.310471
Epoch 12.74: Loss = 0.33017
Epoch 12.75: Loss = 0.424835
Epoch 12.76: Loss = 0.340317
Epoch 12.77: Loss = 0.336578
Epoch 12.78: Loss = 0.340683
Epoch 12.79: Loss = 0.313293
Epoch 12.80: Loss = 0.279617
Epoch 12.81: Loss = 0.393646
Epoch 12.82: Loss = 0.382156
Epoch 12.83: Loss = 0.330353
Epoch 12.84: Loss = 0.315094
Epoch 12.85: Loss = 0.264679
Epoch 12.86: Loss = 0.306061
Epoch 12.87: Loss = 0.347778
Epoch 12.88: Loss = 0.277908
Epoch 12.89: Loss = 0.313049
Epoch 12.90: Loss = 0.394928
Epoch 12.91: Loss = 0.2789
Epoch 12.92: Loss = 0.271347
Epoch 12.93: Loss = 0.259766
Epoch 12.94: Loss = 0.382629
Epoch 12.95: Loss = 0.370316
Epoch 12.96: Loss = 0.320038
Epoch 12.97: Loss = 0.352539
Epoch 12.98: Loss = 0.438416
Epoch 12.99: Loss = 0.293091
Epoch 12.100: Loss = 0.413879
TRAIN LOSS = 0.332352
TRAIN ACC = 90.5701 % (54345/60000)
Loss = 0.332733
Loss = 0.38028
Loss = 0.501572
Loss = 0.469559
Loss = 0.324493
Loss = 0.32782
Loss = 0.502014
Loss = 0.416275
Loss = 0.284485
Loss = 0.209305
Loss = 0.287735
Loss = 0.211639
Loss = 0.143799
Loss = 0.239548
Loss = 0.0506439
Loss = 0.174332
Loss = 0.495193
TEST LOSS = 0.311182
TEST ACC = 543.449 % (9118/10000)
Epoch 13.1: Loss = 0.319138
Epoch 13.2: Loss = 0.331818
Epoch 13.3: Loss = 0.315048
Epoch 13.4: Loss = 0.325562
Epoch 13.5: Loss = 0.28894
Epoch 13.6: Loss = 0.259384
Epoch 13.7: Loss = 0.259369
Epoch 13.8: Loss = 0.246948
Epoch 13.9: Loss = 0.394928
Epoch 13.10: Loss = 0.272003
Epoch 13.11: Loss = 0.395691
Epoch 13.12: Loss = 0.342133
Epoch 13.13: Loss = 0.335754
Epoch 13.14: Loss = 0.307877
Epoch 13.15: Loss = 0.2892
Epoch 13.16: Loss = 0.384598
Epoch 13.17: Loss = 0.336472
Epoch 13.18: Loss = 0.389618
Epoch 13.19: Loss = 0.349106
Epoch 13.20: Loss = 0.345398
Epoch 13.21: Loss = 0.43309
Epoch 13.22: Loss = 0.397491
Epoch 13.23: Loss = 0.308334
Epoch 13.24: Loss = 0.26178
Epoch 13.25: Loss = 0.371552
Epoch 13.26: Loss = 0.323837
Epoch 13.27: Loss = 0.299011
Epoch 13.28: Loss = 0.299042
Epoch 13.29: Loss = 0.34082
Epoch 13.30: Loss = 0.308121
Epoch 13.31: Loss = 0.352982
Epoch 13.32: Loss = 0.353577
Epoch 13.33: Loss = 0.370132
Epoch 13.34: Loss = 0.35289
Epoch 13.35: Loss = 0.401276
Epoch 13.36: Loss = 0.246414
Epoch 13.37: Loss = 0.326385
Epoch 13.38: Loss = 0.405273
Epoch 13.39: Loss = 0.348053
Epoch 13.40: Loss = 0.341019
Epoch 13.41: Loss = 0.34082
Epoch 13.42: Loss = 0.279633
Epoch 13.43: Loss = 0.321793
Epoch 13.44: Loss = 0.366852
Epoch 13.45: Loss = 0.290375
Epoch 13.46: Loss = 0.302231
Epoch 13.47: Loss = 0.371597
Epoch 13.48: Loss = 0.381805
Epoch 13.49: Loss = 0.34758
Epoch 13.50: Loss = 0.281143
Epoch 13.51: Loss = 0.326675
Epoch 13.52: Loss = 0.32695
Epoch 13.53: Loss = 0.352081
Epoch 13.54: Loss = 0.291672
Epoch 13.55: Loss = 0.375992
Epoch 13.56: Loss = 0.307281
Epoch 13.57: Loss = 0.282379
Epoch 13.58: Loss = 0.336731
Epoch 13.59: Loss = 0.327057
Epoch 13.60: Loss = 0.299713
Epoch 13.61: Loss = 0.389526
Epoch 13.62: Loss = 0.313354
Epoch 13.63: Loss = 0.367188
Epoch 13.64: Loss = 0.387253
Epoch 13.65: Loss = 0.333359
Epoch 13.66: Loss = 0.316971
Epoch 13.67: Loss = 0.302719
Epoch 13.68: Loss = 0.320267
Epoch 13.69: Loss = 0.226318
Epoch 13.70: Loss = 0.325592
Epoch 13.71: Loss = 0.394135
Epoch 13.72: Loss = 0.320068
Epoch 13.73: Loss = 0.394089
Epoch 13.74: Loss = 0.364761
Epoch 13.75: Loss = 0.356384
Epoch 13.76: Loss = 0.325272
Epoch 13.77: Loss = 0.316193
Epoch 13.78: Loss = 0.258667
Epoch 13.79: Loss = 0.349304
Epoch 13.80: Loss = 0.271179
Epoch 13.81: Loss = 0.296097
Epoch 13.82: Loss = 0.335831
Epoch 13.83: Loss = 0.302307
Epoch 13.84: Loss = 0.340195
Epoch 13.85: Loss = 0.298294
Epoch 13.86: Loss = 0.307907
Epoch 13.87: Loss = 0.433899
Epoch 13.88: Loss = 0.246674
Epoch 13.89: Loss = 0.350723
Epoch 13.90: Loss = 0.329926
Epoch 13.91: Loss = 0.374619
Epoch 13.92: Loss = 0.34761
Epoch 13.93: Loss = 0.369751
Epoch 13.94: Loss = 0.314636
Epoch 13.95: Loss = 0.302063
Epoch 13.96: Loss = 0.29715
Epoch 13.97: Loss = 0.248932
Epoch 13.98: Loss = 0.318726
Epoch 13.99: Loss = 0.350739
Epoch 13.100: Loss = 0.332214
TRAIN LOSS = 0.329742
TRAIN ACC = 90.6921 % (54418/60000)
Loss = 0.328827
Loss = 0.384048
Loss = 0.494232
Loss = 0.465149
Loss = 0.329605
Loss = 0.324036
Loss = 0.496719
Loss = 0.410202
Loss = 0.279358
Loss = 0.206207
Loss = 0.291794
Loss = 0.207474
Loss = 0.140152
Loss = 0.236618
Loss = 0.0484009
Loss = 0.17424
Loss = 0.50116
TEST LOSS = 0.30907
TEST ACC = 544.179 % (9137/10000)
Epoch 14.1: Loss = 0.387177
Epoch 14.2: Loss = 0.354553
Epoch 14.3: Loss = 0.345383
Epoch 14.4: Loss = 0.321198
Epoch 14.5: Loss = 0.31102
Epoch 14.6: Loss = 0.276169
Epoch 14.7: Loss = 0.331696
Epoch 14.8: Loss = 0.344894
Epoch 14.9: Loss = 0.404266
Epoch 14.10: Loss = 0.289276
Epoch 14.11: Loss = 0.350647
Epoch 14.12: Loss = 0.304733
Epoch 14.13: Loss = 0.314102
Epoch 14.14: Loss = 0.339828
Epoch 14.15: Loss = 0.30069
Epoch 14.16: Loss = 0.318832
Epoch 14.17: Loss = 0.360916
Epoch 14.18: Loss = 0.407898
Epoch 14.19: Loss = 0.268692
Epoch 14.20: Loss = 0.30127
Epoch 14.21: Loss = 0.385696
Epoch 14.22: Loss = 0.254349
Epoch 14.23: Loss = 0.328766
Epoch 14.24: Loss = 0.34433
Epoch 14.25: Loss = 0.329681
Epoch 14.26: Loss = 0.398361
Epoch 14.27: Loss = 0.366577
Epoch 14.28: Loss = 0.331268
Epoch 14.29: Loss = 0.387054
Epoch 14.30: Loss = 0.400421
Epoch 14.31: Loss = 0.325638
Epoch 14.32: Loss = 0.346024
Epoch 14.33: Loss = 0.330551
Epoch 14.34: Loss = 0.323776
Epoch 14.35: Loss = 0.277512
Epoch 14.36: Loss = 0.307343
Epoch 14.37: Loss = 0.318634
Epoch 14.38: Loss = 0.348038
Epoch 14.39: Loss = 0.431091
Epoch 14.40: Loss = 0.333969
Epoch 14.41: Loss = 0.33136
Epoch 14.42: Loss = 0.257172
Epoch 14.43: Loss = 0.25618
Epoch 14.44: Loss = 0.321106
Epoch 14.45: Loss = 0.344193
Epoch 14.46: Loss = 0.332169
Epoch 14.47: Loss = 0.312225
Epoch 14.48: Loss = 0.353836
Epoch 14.49: Loss = 0.303818
Epoch 14.50: Loss = 0.279617
Epoch 14.51: Loss = 0.407684
Epoch 14.52: Loss = 0.405579
Epoch 14.53: Loss = 0.27948
Epoch 14.54: Loss = 0.329453
Epoch 14.55: Loss = 0.290268
Epoch 14.56: Loss = 0.369629
Epoch 14.57: Loss = 0.257919
Epoch 14.58: Loss = 0.330292
Epoch 14.59: Loss = 0.336761
Epoch 14.60: Loss = 0.416016
Epoch 14.61: Loss = 0.326797
Epoch 14.62: Loss = 0.336227
Epoch 14.63: Loss = 0.383453
Epoch 14.64: Loss = 0.314682
Epoch 14.65: Loss = 0.381454
Epoch 14.66: Loss = 0.249115
Epoch 14.67: Loss = 0.284393
Epoch 14.68: Loss = 0.410461
Epoch 14.69: Loss = 0.324982
Epoch 14.70: Loss = 0.309647
Epoch 14.71: Loss = 0.308823
Epoch 14.72: Loss = 0.279724
Epoch 14.73: Loss = 0.270691
Epoch 14.74: Loss = 0.361465
Epoch 14.75: Loss = 0.350266
Epoch 14.76: Loss = 0.255295
Epoch 14.77: Loss = 0.405746
Epoch 14.78: Loss = 0.371109
Epoch 14.79: Loss = 0.222504
Epoch 14.80: Loss = 0.345047
Epoch 14.81: Loss = 0.425797
Epoch 14.82: Loss = 0.271469
Epoch 14.83: Loss = 0.325958
Epoch 14.84: Loss = 0.272995
Epoch 14.85: Loss = 0.301804
Epoch 14.86: Loss = 0.327698
Epoch 14.87: Loss = 0.301926
Epoch 14.88: Loss = 0.320862
Epoch 14.89: Loss = 0.360672
Epoch 14.90: Loss = 0.35704
Epoch 14.91: Loss = 0.322128
Epoch 14.92: Loss = 0.302963
Epoch 14.93: Loss = 0.412521
Epoch 14.94: Loss = 0.214859
Epoch 14.95: Loss = 0.347427
Epoch 14.96: Loss = 0.313004
Epoch 14.97: Loss = 0.239502
Epoch 14.98: Loss = 0.32756
Epoch 14.99: Loss = 0.293396
Epoch 14.100: Loss = 0.3349
TRAIN LOSS = 0.328842
TRAIN ACC = 90.7822 % (54472/60000)
Loss = 0.328262
Loss = 0.382858
Loss = 0.492935
Loss = 0.467422
Loss = 0.324081
Loss = 0.323441
Loss = 0.496399
Loss = 0.412689
Loss = 0.278549
Loss = 0.208817
Loss = 0.284729
Loss = 0.204895
Loss = 0.139023
Loss = 0.23436
Loss = 0.0477905
Loss = 0.175247
Loss = 0.49881
TEST LOSS = 0.308042
TEST ACC = 544.719 % (9134/10000)
Epoch 15.1: Loss = 0.373566
Epoch 15.2: Loss = 0.30574
Epoch 15.3: Loss = 0.242645
Epoch 15.4: Loss = 0.316772
Epoch 15.5: Loss = 0.341766
Epoch 15.6: Loss = 0.387619
Epoch 15.7: Loss = 0.335526
Epoch 15.8: Loss = 0.320679
Epoch 15.9: Loss = 0.377625
terminate called after throwing an instance of 'std::runtime_error'
  what():  client 0 already connected
